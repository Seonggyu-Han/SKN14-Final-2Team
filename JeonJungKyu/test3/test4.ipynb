{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0de4044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Query: ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\n",
      "[Device] cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [16:16:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\gbm\\gbtree.cc:359: \n",
      "  Loading from a raw memory buffer (like pickle in Python, RDS in R) on a CPU-only\n",
      "  machine. Consider using `save_model/load_model` instead. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.  Changing `tree_method` to `hist`.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [16:16:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\gbm\\gbtree.cc:384: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [16:16:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [16:16:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  setstate(state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaded model from ./models.pkl]\n",
      "Labels: ['Amber', 'Aromatic', 'Blossom', 'Bouquet', 'Citrus', 'Classical', 'Crisp', 'Dry', 'Floral', 'Flower', 'FougÃ¨re', 'Fresh', 'Fresher', 'Fruity', 'Gourmand', 'Green', 'Iris', 'Jasmine', 'Lily', 'Mossy', 'Musk', 'Orange', 'Rich', 'Richer', 'Rose', 'Soft', 'Spicy', 'Tuberose', 'Valley', 'Violet', 'Water', 'White', 'Woods', 'Woody']\n",
      "[Loaded 26319 perfumes from perfumes.json]\n",
      "[BM25 index built]\n",
      "Router: LLM_parser\n",
      "Parsed: {'brand': 'ì…ìƒë¡œë‘', 'gender': 'Female', 'sizes': 50, 'season_score': 'winter', 'concentration': None, 'day_night_score': None}\n",
      "Filtered: {'brand': 'ì…ìƒë¡œë‘', 'concentration': None, 'day_night_score': None, 'gender': 'Female', 'season_score': 'winter', 'sizes': 50}\n",
      "Response: âŒ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: 'PerfumeRecommender' object has no attribute 'pinecone_index'\n",
      "\n",
      "================================================================================\n",
      "Query: ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\n",
      "Router: LLM_parser\n",
      "Parsed: {'brand': 'ë””ì˜¬', 'gender': None, 'sizes': None, 'season_score': 'fall', 'concentration': 'ì˜¤ ë“œ í¼í“¸', 'day_night_score': 'night'}\n",
      "Filtered: {'brand': 'ë””ì˜¬', 'concentration': 'ì˜¤ ë“œ í¼í“¸', 'day_night_score': 'night', 'gender': None, 'season_score': 'fall', 'sizes': None}\n",
      "Response: âŒ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: 'PerfumeRecommender' object has no attribute 'pinecone_index'\n",
      "\n",
      "================================================================================\n",
      "Query: EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?\n",
      "Router: FAQ_agent\n",
      "Response: ğŸŒŸ **EDP vs EDT ì°¨ì´ì **\n",
      "\n",
      "EDP (Eau de Parfum): í–¥ë£Œ ë†ë„ 15-20%, ì§€ì†ì‹œê°„ 6-8ì‹œê°„\n",
      "EDT (Eau de Toilette): í–¥ë£Œ ë†ë„ 5-15%, ì§€ì†ì‹œê°„ 3-5ì‹œê°„\n",
      "\n",
      "EDPê°€ ë” ì§„í•˜ê³  ì˜¤ë˜ê°€ì§€ë§Œ, EDTê°€ ë” ê°€ë³ê³  ìƒì¾Œí•´ìš”!\n",
      "\n",
      "================================================================================\n",
      "Query: íƒ‘ë…¸íŠ¸Â·ë¯¸ë“¤ë…¸íŠ¸Â·ë² ì´ìŠ¤ë…¸íŠ¸ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì´ì•¼?\n",
      "Router: FAQ_agent\n",
      "Response: ğŸµ **í–¥ìˆ˜ ë…¸íŠ¸ êµ¬ì„±**\n",
      "\n",
      "â€¢ **íƒ‘ë…¸íŠ¸**: ì²« ì¸ìƒ (5-15ë¶„)\n",
      "â€¢ **ë¯¸ë“¤ë…¸íŠ¸**: ë©”ì¸ í–¥ (30ë¶„-2ì‹œê°„)\n",
      "â€¢ **ë² ì´ìŠ¤ë…¸íŠ¸**: ë§ˆë¬´ë¦¬ í–¥ (2ì‹œê°„ ì´ìƒ)\n",
      "\n",
      "ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ í–¥ì´ ë³€í™”í•˜ëŠ” ê²ƒì´ í–¥ìˆ˜ì˜ ë§¤ë ¥ì´ì—ìš”!\n",
      "\n",
      "================================================================================\n",
      "Query: ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?\n",
      "Router: human_fallback\n",
      "Response: â“ í–¥ìˆ˜ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”!\n",
      "\n",
      "ğŸ’¡ ì˜ˆì‹œ:\n",
      "â€¢ í–¥ìˆ˜ ì¶”ì²œ\n",
      "â€¢ í–¥ìˆ˜ ê°€ê²© ë¬¸ì˜\n",
      "â€¢ í–¥ìˆ˜ ì§€ì‹ ë¬¸ë‹µ\n",
      "\n",
      "================================================================================\n",
      "Query: ìƒ¤ë„¬ ë„˜ë²„5 50ml ìµœì €ê°€ ì•Œë ¤ì¤˜.\n",
      "Router: price_agent\n",
      "Response: ğŸ” 'ìƒ¤ë„¬ ë„˜ë²„5 50ml ìµœì €ê°€ ì•Œë ¤ì¤˜.' ê²€ìƒ‰ ê²°ê³¼:\n",
      "\n",
      "ğŸ“¦ 1. CHANEL No.5 ì˜¤ ë“œ í¼í“¸ í”Œë¡œëŸ´í–¥, 50ml, 1ê°œ\n",
      "   ğŸ’° ê°€ê²©: 130,000ì›\n",
      "   ğŸª íŒë§¤ì²˜: ë„¤ì´ë²„\n",
      "   ğŸ”— ë§í¬: https://search.shopping.naver.com/catalog/53015716331\n",
      "\n",
      "ğŸ“¦ 2. [êµ­ë‚´ë°±í™”ì /ì„ ë¬¼í¬ì¥] ìƒ¤ë„¬ ë„˜ë²„5 NO5 LEAU ë¡œ ì˜¤ ë“œ ëšœì™ˆë › ì—¬ì„± í–¥ìˆ˜ 50ml\n",
      "   ğŸ’° ê°€ê²©: 206,000ì›\n",
      "   ğŸª íŒë§¤ì²˜: ë¼ì´í¬ì»´í¼ë‹ˆ\n",
      "   ğŸ”— ë§í¬: https://smartstore.naver.com/main/products/11549357996\n",
      "\n",
      "ğŸ“¦ 3. CHANEL No.5 ìš°ë¨¼ ì˜¤ ë“œ ëšœì™ˆë ›\n",
      "   ğŸ’° ê°€ê²©: 165,990ì›\n",
      "   ğŸª íŒë§¤ì²˜: ë„¤ì´ë²„\n",
      "   ğŸ”— ë§í¬: https://search.shopping.naver.com/catalog/2600028834\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query: ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\n",
      "Router: ML_agent\n",
      "Response: âŒ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: 'PerfumeRecommender' object has no attribute 'pinecone_index'\n",
      "\n",
      "================================================================================\n",
      "Query: ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.\n",
      "Router: ML_agent\n",
      "Response: âŒ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: 'PerfumeRecommender' object has no attribute 'pinecone_index'\n",
      "\n",
      "================================================================================\n",
      "Query: ìƒ¤ë„¬ ì—¬ì„±ìš© ì˜¤ ë“œ í¼í“¸ ì¶”ì²œí•´ì¤˜.\n",
      "Router: ML_agent\n",
      "Response: âŒ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: 'PerfumeRecommender' object has no attribute 'pinecone_index'\n",
      "\n",
      "================================================================================\n",
      "Query: êµ¬ì°Œ ë‚¨ì„±ìš© í–¥ìˆ˜ ì¤‘ì— ë´„ì— ì“¸ ë§Œí•œ ê±° ìˆì–´?\n",
      "Router: ML_agent\n",
      "Response: âŒ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: 'PerfumeRecommender' object has no attribute 'pinecone_index'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain langgraph langchain-openai tiktoken transformers torch rank-bm25 joblib scikit-learn\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import TypedDict, List, Optional, Dict, Any, Tuple\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "# ---------- 0) Config ----------\n",
    "load_dotenv()\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "naver_client_id = os.getenv(\"NAVER_CLIENT_ID\")\n",
    "naver_client_secret = os.getenv(\"NAVER_CLIENT_SECRET\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# ---------- 1) State ----------\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    next: Optional[str]\n",
    "    router_json: Optional[Dict[str, Any]]\n",
    "    parsed: Optional[Dict[str, Any]]  # LLM_parser ê²°ê³¼\n",
    "    filtered: Optional[Dict[str, Any]]  # ë©”íƒ€í•„í„°ë§ ê²°ê³¼\n",
    "    recommendations: Optional[List[Dict]]  # ML_agent ê²°ê³¼\n",
    "    price_info: Optional[str]  # price_agent ê²°ê³¼\n",
    "\n",
    "# ---------- 2) Meta Filtering Functions ----------\n",
    "def filter_brand(brand_value):\n",
    "    \"\"\"ë¸Œëœë“œ í•„í„°ë§ í•¨ìˆ˜\"\"\"\n",
    "    valid_brands = [\n",
    "        'ê²”ë‘', 'êµ¬ì°Œ', 'ëŒë¡œì—', 'ë‚˜ë¥´ì‹œì†Œ ë¡œë“œë¦¬ê²Œì¦ˆ', 'ë‹ˆìƒ¤ë„¤', 'ë„ë¥´ì„¸', 'ë””ì˜¬', 'ë”¥í‹°í¬', 'ë‘ì½¤',\n",
    "        'ë¡œë¼ ë©”ë¥´ì‹œì—', 'ë¡œì—ë² ', 'ë¡ì‹œë•…', 'ë¥´ ë¼ë³´', 'ë©”ëª¨', 'ë©”ì¢… ë§ˆë¥´ì§€ì—˜ë¼', 'ë©”ì¢… í”„ë€ì‹œìŠ¤ ì»¤ì •',\n",
    "        'ë©œë¦°ì•¤ê²Œì¸ ', 'ë¯¸ìš°ë¯¸ìš°', 'ë°”ì´ë ˆë„', 'ë°˜í´ë¦¬í”„ ì•„í ', 'ë²„ë²„ë¦¬', 'ë² ë¥´ì‚¬ì²´', 'ë¶ˆê°€ë¦¬', 'ë¹„ë””ì¼€ì´',\n",
    "        'ì‚°íƒ€ ë§ˆë¦¬ì•„ ë…¸ë²¨ë¼', 'ìƒ¤ë„¬', 'ì„¸ë¥´ì£¼ ë£¨í…', 'ì‹œìŠ¬ë¦¬ ì½”ìŠ¤ë©”í‹±', 'ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ', 'ì—ë”° ë¦¬ë¸Œë¥´ ë„ëŸ‰ì¥¬',\n",
    "        'ì—ë¥´ë©”ìŠ¤', 'ì—ìŠ¤í‹° ë¡œë”', 'ì—‘ìŠ¤ ë‹ˆíë¡œ', 'ì´ë‹ˆì‹œì˜¤ í¼í“¸', 'ì´ì†', 'ì…ìƒë¡œë‘', 'ì œë¥´ì¡°í”„', 'ì¡° ë§ë¡ ',\n",
    "        'ì¡°ë¥´ì§€ì˜¤ ì•„ë¥´ë§ˆë‹ˆ', 'ì¤„ë¦¬ì—£ í—¤ì¦ˆ ì–´ ê±´', 'ì§€ë°©ì‹œ', 'ì§ˆ ìŠ¤íŠœì–´íŠ¸', 'í¬ë¦¬ë“œ', 'í‚¬ë¦¬ì•ˆ', 'í†° í¬ë“œ',\n",
    "        'í‹°íŒŒë‹ˆì•¤ì½”', 'í¼í“¸ ë“œ ë§ë¦¬', 'íœí• ë¦¬ê³¤ìŠ¤', 'í”„ë¼ë‹¤', 'í”„ë ˆë°ë¦­ ë§'\n",
    "    ]\n",
    "    \n",
    "    if brand_value is None:\n",
    "        return None\n",
    "    \n",
    "    return brand_value if brand_value in valid_brands else None\n",
    "\n",
    "\n",
    "def filter_concentration(concentration_value):\n",
    "    \"\"\"ë†ë„ í•„í„°ë§ í•¨ìˆ˜\"\"\"\n",
    "    valid_concentrations = ['ì†”ë¦¬ë“œ í¼í“¸', 'ì—‘ìŠ¤íŠ¸ë ˆ ë“œ í¼í“¸', 'ì˜¤ ë“œ ëšœì™ˆë ›', 'ì˜¤ ë“œ ì½”ë¡±', 'ì˜¤ ë“œ í¼í“¸', 'í¼í“¸']\n",
    "    \n",
    "    if concentration_value is None:\n",
    "        return None\n",
    "    \n",
    "    return concentration_value if concentration_value in valid_concentrations else None\n",
    "\n",
    "\n",
    "def filter_day_night_score(day_night_value):\n",
    "    \"\"\"ì‚¬ìš©ì‹œê°„ í•„í„°ë§ í•¨ìˆ˜\"\"\"\n",
    "    valid_day_night = [\"day\", \"night\"]\n",
    "    \n",
    "    if day_night_value is None:\n",
    "        return None\n",
    "    \n",
    "    # ì‰¼í‘œë¡œ ë¶„ë¦¬ëœ ê°’ë“¤ ì²˜ë¦¬\n",
    "    if isinstance(day_night_value, str) and ',' in day_night_value:\n",
    "        values = [v.strip() for v in day_night_value.split(',')]\n",
    "        filtered_values = [v for v in values if v in valid_day_night]\n",
    "        return ','.join(filtered_values) if filtered_values else None\n",
    "    \n",
    "    return day_night_value if day_night_value in valid_day_night else None\n",
    "\n",
    "\n",
    "def filter_gender(gender_value):\n",
    "    \"\"\"ì„±ë³„ í•„í„°ë§ í•¨ìˆ˜\"\"\"\n",
    "    valid_genders = ['Female', 'Male', 'Unisex', 'unisex ']\n",
    "    \n",
    "    if gender_value is None:\n",
    "        return None\n",
    "    \n",
    "    return gender_value if gender_value in valid_genders else None\n",
    "\n",
    "\n",
    "def filter_season_score(season_value):\n",
    "    \"\"\"ê³„ì ˆ í•„í„°ë§ í•¨ìˆ˜\"\"\"\n",
    "    valid_seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "    \n",
    "    if season_value is None:\n",
    "        return None\n",
    "    \n",
    "    return season_value if season_value in valid_seasons else None\n",
    "\n",
    "\n",
    "def filter_sizes(sizes_value):\n",
    "    \"\"\"ìš©ëŸ‰ í•„í„°ë§ í•¨ìˆ˜\"\"\"\n",
    "    valid_sizes = ['50', '75']\n",
    "    \n",
    "    if sizes_value is None:\n",
    "        return None\n",
    "    \n",
    "    # ìˆ«ìë§Œ ì¶”ì¶œ (ì˜ˆ: \"50ml\" -> \"50\")\n",
    "    if isinstance(sizes_value, str):\n",
    "        import re\n",
    "        numbers = re.findall(r'\\d+', sizes_value)\n",
    "        for num in numbers:\n",
    "            if num in valid_sizes:\n",
    "                return num\n",
    "    \n",
    "    return sizes_value if str(sizes_value) in valid_sizes else None\n",
    "\n",
    "\n",
    "def apply_meta_filters(parsed_json):\n",
    "    \"\"\"ì „ì²´ JSONì— ë©”íƒ€í•„í„°ë§ ì ìš©\"\"\"\n",
    "    if not parsed_json or \"error\" in parsed_json:\n",
    "        return parsed_json\n",
    "    \n",
    "    filtered_result = {\n",
    "        'brand': filter_brand(parsed_json.get('brand')),\n",
    "        'concentration': filter_concentration(parsed_json.get('concentration')),\n",
    "        'day_night_score': filter_day_night_score(parsed_json.get('day_night_score')),\n",
    "        'gender': filter_gender(parsed_json.get('gender')),\n",
    "        'season_score': filter_season_score(parsed_json.get('season_score')),\n",
    "        'sizes': filter_sizes(parsed_json.get('sizes'))\n",
    "    }\n",
    "    \n",
    "    return filtered_result\n",
    "\n",
    "# ---------- 3) PerfumeRecommender Class ----------\n",
    "class PerfumeRecommender:\n",
    "    \"\"\"í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_pkl_path: str = \"./models.pkl\", \n",
    "                 perfume_json_path: str = \"perfumes.json\",\n",
    "                 model_name: str = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "                 max_len: int = 256):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.max_len = max_len\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"[Device] {self.device}\")\n",
    "        \n",
    "        # ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ\n",
    "        self._load_ml_model(model_pkl_path)\n",
    "        self._load_transformer_model()\n",
    "        self._load_perfume_data(perfume_json_path)\n",
    "        self._build_bm25_index()\n",
    "    \n",
    "    def _load_ml_model(self, pkl_path: str):\n",
    "        \"\"\"ì €ì¥ëœ ML ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\"\"\"\n",
    "        try:\n",
    "            data = joblib.load(pkl_path)\n",
    "            self.clf = data[\"classifier\"]\n",
    "            self.mlb = data[\"mlb\"]\n",
    "            self.thresholds = data[\"thresholds\"]\n",
    "            print(f\"[Loaded model from {pkl_path}]\")\n",
    "            print(f\"Labels: {list(self.mlb.classes_)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Could not load ML model: {e}\")\n",
    "            self.clf = None\n",
    "            self.mlb = None\n",
    "            self.thresholds = None\n",
    "    \n",
    "    def _load_transformer_model(self):\n",
    "        \"\"\"Transformer ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "            self.base_model = AutoModel.from_pretrained(self.model_name).to(self.device)\n",
    "            self.base_model.eval()\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Could not load transformer model: {e}\")\n",
    "            self.tokenizer = None\n",
    "            self.base_model = None\n",
    "    \n",
    "    def _load_perfume_data(self, json_path: str):\n",
    "        \"\"\"í–¥ìˆ˜ ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "        try:\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                self.perfumes = json.load(f)\n",
    "            print(f\"[Loaded {len(self.perfumes)} perfumes from {json_path}]\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Could not load perfume data: {e}\")\n",
    "            self.perfumes = []\n",
    "    \n",
    "    def _build_bm25_index(self):\n",
    "        \"\"\"BM25 ì¸ë±ìŠ¤ êµ¬ì¶•\"\"\"\n",
    "        if not self.perfumes:\n",
    "            self.bm25 = None\n",
    "            return\n",
    "        \n",
    "        self.corpus = [item.get(\"fragrances\", \"\") for item in self.perfumes]\n",
    "        tokenized_corpus = [doc.lower().split() for doc in self.corpus]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        print(\"[BM25 index built]\")\n",
    "    \n",
    "    def encode_texts(self, texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
    "        \"\"\"í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "        if not self.tokenizer or not self.base_model:\n",
    "            return np.array([])\n",
    "            \n",
    "        all_embeddings = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            enc = self.tokenizer(\n",
    "                batch, \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                max_length=self.max_len, \n",
    "                return_tensors=\"pt\"\n",
    "            ).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model_out = self.base_model(**enc)\n",
    "                emb = model_out.last_hidden_state.mean(dim=1)\n",
    "            \n",
    "            all_embeddings.append(emb.cpu().numpy())\n",
    "        \n",
    "        return np.vstack(all_embeddings)\n",
    "    \n",
    "    def predict_labels(self, text: str, topk: int = 3, use_thresholds: bool = True) -> List[str]:\n",
    "        \"\"\"í…ìŠ¤íŠ¸ì—ì„œ í–¥ìˆ˜ ë¼ë²¨ ì˜ˆì¸¡\"\"\"\n",
    "        if not self.clf or not self.mlb:\n",
    "            return []\n",
    "            \n",
    "        emb = self.encode_texts([text], batch_size=1)\n",
    "        if emb.size == 0:\n",
    "            return []\n",
    "            \n",
    "        proba = self.clf.predict_proba(emb)[0]\n",
    "        \n",
    "        if use_thresholds and self.thresholds:\n",
    "            pick = [\n",
    "                i for i, p in enumerate(proba) \n",
    "                if p >= self.thresholds.get(self.mlb.classes_[i], 0.5)\n",
    "            ]\n",
    "            if not pick:\n",
    "                pick = np.argsort(-proba)[:topk]\n",
    "        else:\n",
    "            pick = np.argsort(-proba)[:topk]\n",
    "        \n",
    "        return [self.mlb.classes_[i] for i in pick]\n",
    "    \n",
    "    def search_perfumes(self, labels: List[str], top_n: int = 5) -> List[Tuple[int, float, Dict]]:\n",
    "        \"\"\"BM25ë¥¼ ì‚¬ìš©í•´ í–¥ìˆ˜ ê²€ìƒ‰\"\"\"\n",
    "        if not self.bm25 or not labels:\n",
    "            return []\n",
    "            \n",
    "        query = \" \".join(labels)\n",
    "        tokenized_query = query.lower().split()\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        top_idx = np.argsort(scores)[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_idx:\n",
    "            results.append((idx, scores[idx], self.perfumes[idx]))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def filter_perfumes_by_meta(self, perfumes: List[Dict], filters: Dict[str, Any]) -> List[Dict]:\n",
    "        \"\"\"ë©”íƒ€ í•„í„°ë¡œ í–¥ìˆ˜ ë¦¬ìŠ¤íŠ¸ í•„í„°ë§\"\"\"\n",
    "        if not filters or not perfumes:\n",
    "            return perfumes\n",
    "            \n",
    "        filtered = []\n",
    "        for perfume in perfumes:\n",
    "            include = True\n",
    "            \n",
    "            # ê° í•„í„° ì¡°ê±´ í™•ì¸\n",
    "            if filters.get('brand') and perfume.get('brand') != filters['brand']:\n",
    "                include = False\n",
    "            if filters.get('concentration') and perfume.get('concentration') != filters['concentration']:\n",
    "                include = False\n",
    "            if filters.get('gender') and perfume.get('gender') != filters['gender']:\n",
    "                include = False\n",
    "            if filters.get('season_score') and perfume.get('season_score') != filters['season_score']:\n",
    "                include = False\n",
    "            if filters.get('sizes') and str(perfume.get('sizes', '')) != str(filters['sizes']):\n",
    "                include = False\n",
    "            if filters.get('day_night_score'):\n",
    "                perfume_day_night = perfume.get('day_night_score', '')\n",
    "                if filters['day_night_score'] not in str(perfume_day_night):\n",
    "                    include = False\n",
    "            \n",
    "            if include:\n",
    "                filtered.append(perfume)\n",
    "                \n",
    "        return filtered\n",
    "    \n",
    "    \n",
    "    def recommend(self, \n",
    "                  user_text: str, \n",
    "                  meta_filters: Optional[Dict[str, Any]] = None,\n",
    "                  topk_labels: int = 4, \n",
    "                  top_n_perfumes: int = 5,\n",
    "                  use_thresholds: bool = True,\n",
    "                  use_vector_search: bool = True) -> Dict:\n",
    "        \"\"\"ì „ì²´ ì¶”ì²œ íŒŒì´í”„ë¼ì¸ (Vector DB + BM25 í•˜ì´ë¸Œë¦¬ë“œ)\"\"\"\n",
    "        \n",
    "        # 1. ML ëª¨ë¸ë¡œ ë¼ë²¨ ì˜ˆì¸¡\n",
    "        predicted_labels = self.predict_labels(\n",
    "            user_text, \n",
    "            topk=topk_labels, \n",
    "            use_thresholds=use_thresholds\n",
    "        )\n",
    "        \n",
    "        candidate_perfumes = []\n",
    "        \n",
    "        # 2. Vector ê²€ìƒ‰ (Pinecone)\n",
    "        if use_vector_search and self.pinecone_index:\n",
    "            query_embedding = self.encode_texts([user_text])\n",
    "            if query_embedding.size > 0:\n",
    "                vector_results = self.search_perfumes_vector(query_embedding, top_k=top_n_perfumes * 2)\n",
    "                # Vector ê²€ìƒ‰ ê²°ê³¼ë¥¼ perfumes.jsonê³¼ ë§¤ì¹­\n",
    "                for result in vector_results:\n",
    "                    # metadataì—ì„œ í–¥ìˆ˜ ì •ë³´ ì¶”ì¶œ ë˜ëŠ” IDë¡œ ë§¤ì¹­\n",
    "                    # ì—¬ê¸°ì„œ ì–´ë–»ê²Œ vector ê²°ê³¼ë¥¼ perfumes.jsonê³¼ ì—°ê²°í• ì§€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤\n",
    "                    pass\n",
    "        \n",
    "        # 3. BM25 ê²€ìƒ‰ (Fallback ë˜ëŠ” ë³´ì™„)\n",
    "        bm25_results = self.search_perfumes_bm25(predicted_labels, top_n=top_n_perfumes * 2)\n",
    "        bm25_perfumes = [perfume for idx, score, perfume in bm25_results]\n",
    "        candidate_perfumes.extend(bm25_perfumes)\n",
    "        \n",
    "        # 4. ë©”íƒ€í•„í„°ë§ ì ìš©\n",
    "        if meta_filters:\n",
    "            active_filters = {k: v for k, v in meta_filters.items() if v is not None}\n",
    "            if active_filters:\n",
    "                candidate_perfumes = self.filter_perfumes_by_meta(candidate_perfumes, active_filters)\n",
    "        \n",
    "        # 5. ìµœì¢… ê²°ê³¼ ìƒì„±\n",
    "        final_recommendations = candidate_perfumes[:top_n_perfumes]\n",
    "        \n",
    "        return {\n",
    "            \"user_input\": user_text,\n",
    "            \"predicted_labels\": predicted_labels,\n",
    "            \"meta_filters_applied\": meta_filters or {},\n",
    "            \"total_candidates\": len(candidate_perfumes),\n",
    "            \"search_method\": \"hybrid\" if use_vector_search else \"bm25_only\",\n",
    "            \"recommendations\": [\n",
    "                {\n",
    "                    \"rank\": rank,\n",
    "                    \"brand\": perfume.get('brand', 'N/A'),\n",
    "                    \"name\": perfume.get('name_perfume', 'N/A'),\n",
    "                    \"fragrances\": perfume.get('fragrances', 'N/A'),\n",
    "                    \"gender\": perfume.get('gender', 'N/A'),\n",
    "                    \"concentration\": perfume.get('concentration', 'N/A'),\n",
    "                    \"sizes\": perfume.get('sizes', 'N/A'),\n",
    "                    \"season_score\": perfume.get('season_score', 'N/A'),\n",
    "                    \"day_night_score\": perfume.get('day_night_score', 'N/A'),\n",
    "                    \"perfume_data\": perfume\n",
    "                }\n",
    "                for rank, perfume in enumerate(final_recommendations, 1)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "# ---------- 4) Global Instances ----------\n",
    "# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹¤ì œ ì‚¬ìš©ì‹œì—ëŠ” ë” ë‚˜ì€ ë°©ë²•ìœ¼ë¡œ ê´€ë¦¬)\n",
    "perfume_recommender = None\n",
    "\n",
    "def initialize_recommender():\n",
    "    \"\"\"ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\"\"\"\n",
    "    global perfume_recommender\n",
    "    if perfume_recommender is None:\n",
    "        perfume_recommender = PerfumeRecommender()\n",
    "\n",
    "# ---------- 5) Tools ----------\n",
    "@tool\n",
    "def price_tool(user_query: str) -> str:\n",
    "    \"\"\"A tool that uses the Naver Shopping API to look up perfume prices\"\"\"\n",
    "    \n",
    "    url = \"https://openapi.naver.com/v1/search/shop.json\"\n",
    "    headers = {\n",
    "        \"X-Naver-Client-Id\": naver_client_id,\n",
    "        \"X-Naver-Client-Secret\": naver_client_secret\n",
    "    }\n",
    "    params = {\"query\": user_query, \"display\": 5, \"sort\": \"sim\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "    except Exception as e:\n",
    "        return f\"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}\"\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f\"âŒ API ì˜¤ë¥˜: {response.status_code}\"\n",
    "    \n",
    "    data = response.json()\n",
    "    if not data or \"items\" not in data or len(data[\"items\"]) == 0:\n",
    "        return f\"ğŸ˜” '{user_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    def remove_html_tags(text: str) -> str:\n",
    "        return re.sub(r\"<[^>]+>\", \"\", text)\n",
    "    \n",
    "    products = data[\"items\"][:3]\n",
    "    output = f\"ğŸ” '{user_query}' ê²€ìƒ‰ ê²°ê³¼:\\n\\n\"\n",
    "    for i, item in enumerate(products, 1):\n",
    "        title = remove_html_tags(item.get(\"title\", \"\"))\n",
    "        lprice = item.get(\"lprice\", \"0\")\n",
    "        mall = item.get(\"mallName\", \"ì •ë³´ ì—†ìŒ\")\n",
    "        link = item.get(\"link\", \"ì •ë³´ ì—†ìŒ\")\n",
    "        \n",
    "        output += f\"ğŸ“¦ {i}. {title}\\n\"\n",
    "        if lprice != \"0\":\n",
    "            output += f\"   ğŸ’° ê°€ê²©: {int(lprice):,}ì›\\n\"\n",
    "        output += f\"   ğŸª íŒë§¤ì²˜: {mall}\\n\"\n",
    "        output += f\"   ğŸ”— ë§í¬: {link}\\n\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "# ---------- 6) Supervisor (Router) ----------\n",
    "SUPERVISOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are the \"Perfume Recommendation Supervisor (Router)\". Analyze the user's query (Korean or English) and route to exactly ONE agent below.\n",
    "\n",
    "[Agents]\n",
    "- LLM_parser         : Parses/normalizes multi-facet queries (2+ product facets).\n",
    "- FAQ_agent          : Perfume knowledge / definitions / differences / general questions.\n",
    "- human_fallback     : Non-perfume or off-topic queries.\n",
    "- price_agent        : Price-only intents (cheapest, price, buy, discount, etc.).\n",
    "- ML_agent           : Single-preference recommendations (mood/season vibe like \"fresh summer\", \"sweet\", etc.).\n",
    "\n",
    "[Facets to detect (\"product facets\")]\n",
    "- brand            (e.g., Chanel, Dior, Creed)\n",
    "- season           (spring/summer/fall/winter; \"for summer/winter\")\n",
    "- gender           (male/female/unisex)\n",
    "- sizes            (volume in ml: 30/50/100 ml)\n",
    "- day_night_score  (day/night/daily/office/club, etc.)\n",
    "- concentration    (EDT/EDP/Extrait/Parfum/Cologne)\n",
    "\n",
    "[Price intent keywords (not exhaustive)]\n",
    "- Korean: ê°€ê²©, ìµœì €ê°€, ì–¼ë§ˆ, ê°€ê²©ëŒ€, êµ¬ë§¤, íŒë§¤, í• ì¸, ì–´ë””ì„œ ì‚¬, ë°°ì†¡ë¹„\n",
    "- English: price, cost, cheapest, buy, purchase, discount\n",
    "\n",
    "[FAQ examples]\n",
    "- Differences between EDP vs EDT, note definitions, longevity/projection, brand/line info.\n",
    "\n",
    "[Single-preference (ML_agent) examples]\n",
    "- \"Recommend a cool perfume for summer\", \"Recommend a sweet scent\", \"One citrusy fresh pick\"\n",
    "  (= 0â€“1 of the above facets mentioned; primarily taste/mood/situation).\n",
    "\n",
    "[Routing rules (priority)]\n",
    "1) Non-perfume / off-topic â†’ human_fallback\n",
    "2) Clear price-only intent (even if one facet is present as context) â†’ price_agent\n",
    "   e.g., \"Chanel No. 5 50ml cheapest price?\" â†’ price_agent\n",
    "3) Count product facets in the query:\n",
    "   - If facets â‰¥ 2 â†’ LLM_parser\n",
    "4) Otherwise (single-topic queries):\n",
    "   - Perfume knowledge/definitions â†’ FAQ_agent\n",
    "   - Single taste/mood recommendation â†’ ML_agent\n",
    "5) Tie-breakers:\n",
    "   - If price intent is clear â†’ price_agent\n",
    "   - If facets â‰¥ 2 â†’ LLM_parser\n",
    "   - Else: knowledge â†’ FAQ_agent, taste â†’ ML_agent\n",
    "\n",
    "[Output format]\n",
    "Return ONLY this JSON (no extra text):\n",
    "{{\n",
    "  \"next\": \"<LLM_parser|FAQ_agent|human_fallback|price_agent|ML_agent>\",\n",
    "  \"reason\": \"<one short English sentence>\",\n",
    "  \"facet_count\": <integer>,\n",
    "  \"facets\": {{\n",
    "    \"brand\": \"<value or null>\",\n",
    "    \"season\": \"<value or null>\",\n",
    "    \"gender\": \"<value or null>\",\n",
    "    \"sizes\": \"<value or null>\",\n",
    "    \"day_night_score\": \"<value or null>\",\n",
    "    \"concentration\": \"<value or null>\"\n",
    "  }},\n",
    "  \"scent_vibe\": \"<value if detected, else null>\",\n",
    "  \"query_intent\": \"<price|faq|scent_pref|non_perfume|other>\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "router_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SUPERVISOR_SYSTEM_PROMPT),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Call the router LLM and return parsed JSON + routing target.\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    chain = router_prompt | llm\n",
    "    ai = chain.invoke({\"query\": user_query})\n",
    "    text = ai.content\n",
    "\n",
    "    chosen = \"human_fallback\"\n",
    "    parsed: Dict[str, Any] = {}\n",
    "    try:\n",
    "        parsed = json.loads(text)\n",
    "        maybe = parsed.get(\"next\")\n",
    "        if isinstance(maybe, str) and maybe in {\"LLM_parser\",\"FAQ_agent\",\"human_fallback\",\"price_agent\",\"ML_agent\"}:\n",
    "            chosen = maybe\n",
    "    except Exception:\n",
    "        parsed = {\"error\": \"invalid_json\", \"raw\": text}\n",
    "\n",
    "    msgs = state[\"messages\"] + [AIMessage(content=text)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": chosen,\n",
    "        \"router_json\": parsed,\n",
    "        \"parsed\": state.get(\"parsed\"),\n",
    "        \"filtered\": state.get(\"filtered\"),\n",
    "        \"recommendations\": state.get(\"recommendations\"),\n",
    "        \"price_info\": state.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "# ---------- 7) Agent Nodes ----------\n",
    "def llm_parser_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ë³µí•© ì¿¼ë¦¬ íŒŒì‹± ë° ë©”íƒ€í•„í„°ë§\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    \n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    # LangChain LLM ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½\n",
    "    parse_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"ë„ˆëŠ” í–¥ìˆ˜ ì¿¼ë¦¬ íŒŒì„œì•¼.\n",
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜:\n",
    "- brand: ë¸Œëœë“œëª… (ì˜ˆ: ìƒ¤ë„¬, ë””ì˜¬, ì…ìƒë¡œë‘ ë“±)\n",
    "- concentration: ë†ë„ (ì˜¤ ë“œ í¼í“¸, ì˜¤ ë“œ ëšœì™ˆë ›, í¼í“¸, ì½”ë¡± ë“±)\n",
    "- day_night_score: ì‚¬ìš©ì‹œê°„ (day, night ë“±)\n",
    "- gender: ì„±ë³„ (Female, Male, Unisex ë“±)\n",
    "- season_score: ê³„ì ˆ (spring, summer, fall, winter)\n",
    "- sizes: ìš©ëŸ‰ (50, 75 ë“± ìˆ«ìë§Œ)\n",
    "\n",
    "ì—†ëŠ” ê°’ì€ nullë¡œ ë‘ê³ , ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì¤˜.\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "{{\"brand\": \"ìƒ¤ë„¬\", \"gender\": \"Female\", \"sizes\": \"50\", \"season_score\": \"winter\", \"concentration\": null, \"day_night_score\": null}}\"\"\"),\n",
    "        (\"user\", \"{query}\")\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        chain = parse_prompt | llm\n",
    "        ai_response = chain.invoke({\"query\": user_query})\n",
    "        \n",
    "        # JSON íŒŒì‹± ì‹œë„\n",
    "        response_text = ai_response.content.strip()\n",
    "        \n",
    "        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±°)\n",
    "        if \"```json\" in response_text:\n",
    "            response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in response_text:\n",
    "            response_text = response_text.split(\"```\")[1].strip()\n",
    "        \n",
    "        parsed_result = json.loads(response_text)\n",
    "        \n",
    "        # í•„ë“œ ê²€ì¦\n",
    "        expected_fields = [\"brand\", \"concentration\", \"day_night_score\", \"gender\", \"season_score\", \"sizes\"]\n",
    "        for field in expected_fields:\n",
    "            if field not in parsed_result:\n",
    "                parsed_result[field] = None\n",
    "                \n",
    "    except json.JSONDecodeError as e:\n",
    "        parsed_result = {\"error\": f\"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}\", \"raw_response\": response_text}\n",
    "    except Exception as e:\n",
    "        parsed_result = {\"error\": f\"íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(e)}\"}\n",
    "    \n",
    "    # ë©”íƒ€í•„í„°ë§ ì ìš©\n",
    "    if \"error\" not in parsed_result:\n",
    "        filtered_result = apply_meta_filters(parsed_result)\n",
    "    else:\n",
    "        filtered_result = parsed_result\n",
    "    \n",
    "    # ê²°ê³¼ í¬ë§·íŒ… - íŒŒì‹±ë§Œ í•˜ê³  ì¶”ì²œì€ ì•ˆí•¨\n",
    "    result_text = f\"ğŸ” **ì¿¼ë¦¬ ë¶„ì„ ì™„ë£Œ**\\n\\n\"\n",
    "    if \"error\" not in parsed_result:\n",
    "        # ì›ë³¸ íŒŒì‹± ê²°ê³¼ í‘œì‹œ\n",
    "        result_text += \"**ğŸ¯ íŒŒì‹±ëœ ì¡°ê±´:**\\n\"\n",
    "        found_original = False\n",
    "        for key, value in parsed_result.items():\n",
    "            if value and value != \"null\":\n",
    "                korean_labels = {\n",
    "                    \"brand\": \"ë¸Œëœë“œ\",\n",
    "                    \"concentration\": \"ë†ë„\", \n",
    "                    \"day_night_score\": \"ì‚¬ìš©ì‹œê°„\",\n",
    "                    \"gender\": \"ì„±ë³„\",\n",
    "                    \"season_score\": \"ê³„ì ˆ\", \n",
    "                    \"sizes\": \"ìš©ëŸ‰\"\n",
    "                }\n",
    "                result_text += f\"â€¢ {korean_labels.get(key, key)}: {value}\\n\"\n",
    "                found_original = True\n",
    "        \n",
    "        if not found_original:\n",
    "            result_text += \"â€¢ êµ¬ì²´ì ì¸ ì¡°ê±´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\\n\"\n",
    "        \n",
    "        # í•„í„°ë§ëœ ê²°ê³¼ í‘œì‹œ\n",
    "        result_text += \"\\n**âœ… ìœ íš¨í•œ ì¡°ê±´ (ë©”íƒ€í•„í„°ë§ ì ìš©):**\\n\"\n",
    "        found_filtered = False\n",
    "        for key, value in filtered_result.items():\n",
    "            if value and value != \"null\":\n",
    "                korean_labels = {\n",
    "                    \"brand\": \"ë¸Œëœë“œ\",\n",
    "                    \"concentration\": \"ë†ë„\", \n",
    "                    \"day_night_score\": \"ì‚¬ìš©ì‹œê°„\",\n",
    "                    \"gender\": \"ì„±ë³„\",\n",
    "                    \"season_score\": \"ê³„ì ˆ\", \n",
    "                    \"sizes\": \"ìš©ëŸ‰\"\n",
    "                }\n",
    "                result_text += f\"â€¢ {korean_labels.get(key, key)}: {value}\\n\"\n",
    "                found_filtered = True\n",
    "        \n",
    "        if not found_filtered:\n",
    "            result_text += \"â€¢ ìœ íš¨í•œ ì¡°ê±´ì´ ì—†ìŠµë‹ˆë‹¤.\\n\"\n",
    "            \n",
    "    else:\n",
    "        result_text += f\"âŒ íŒŒì‹± ì˜¤ë¥˜: {parsed_result['error']}\"\n",
    "    \n",
    "    msgs = state[\"messages\"] + [AIMessage(content=result_text)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": None,  # LLM_parserëŠ” ë…ë¦½ì ìœ¼ë¡œ ì¢…ë£Œ\n",
    "        \"router_json\": state.get(\"router_json\"),\n",
    "        \"parsed\": parsed_result,\n",
    "        \"filtered\": filtered_result,\n",
    "        \"recommendations\": state.get(\"recommendations\"),\n",
    "        \"price_info\": state.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "def faq_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"í–¥ìˆ˜ FAQ ì²˜ë¦¬\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    \n",
    "    # ê°„ë‹¨í•œ FAQ ë§¤ì¹­\n",
    "    faq_responses = {\n",
    "        \"edp\": \"ğŸŒŸ **EDP vs EDT ì°¨ì´ì **\\n\\nEDP (Eau de Parfum): í–¥ë£Œ ë†ë„ 15-20%, ì§€ì†ì‹œê°„ 6-8ì‹œê°„\\nEDT (Eau de Toilette): í–¥ë£Œ ë†ë„ 5-15%, ì§€ì†ì‹œê°„ 3-5ì‹œê°„\\n\\nEDPê°€ ë” ì§„í•˜ê³  ì˜¤ë˜ê°€ì§€ë§Œ, EDTê°€ ë” ê°€ë³ê³  ìƒì¾Œí•´ìš”!\",\n",
    "        \"ë…¸íŠ¸\": \"ğŸµ **í–¥ìˆ˜ ë…¸íŠ¸ êµ¬ì„±**\\n\\nâ€¢ **íƒ‘ë…¸íŠ¸**: ì²« ì¸ìƒ (5-15ë¶„)\\nâ€¢ **ë¯¸ë“¤ë…¸íŠ¸**: ë©”ì¸ í–¥ (30ë¶„-2ì‹œê°„)\\nâ€¢ **ë² ì´ìŠ¤ë…¸íŠ¸**: ë§ˆë¬´ë¦¬ í–¥ (2ì‹œê°„ ì´ìƒ)\\n\\nì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ í–¥ì´ ë³€í™”í•˜ëŠ” ê²ƒì´ í–¥ìˆ˜ì˜ ë§¤ë ¥ì´ì—ìš”!\",\n",
    "        \"ì§€ì†\": \"â° **í–¥ìˆ˜ ì§€ì†ì‹œê°„**\\n\\nâ€¢ Parfum: 8ì‹œê°„ ì´ìƒ\\nâ€¢ EDP: 6-8ì‹œê°„\\nâ€¢ EDT: 3-5ì‹œê°„\\nâ€¢ EDC: 2-3ì‹œê°„\\n\\ní”¼ë¶€íƒ€ì…ê³¼ ë³´ê´€ìƒíƒœì— ë”°ë¼ ì°¨ì´ê°€ ìˆì–´ìš”!\"\n",
    "    }\n",
    "    \n",
    "    response = \"â“ **í–¥ìˆ˜ ê´€ë ¨ ì§ˆë¬¸**\\n\\nêµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”!\\n\\nğŸ’¡ ì˜ˆì‹œ: EDPì™€ EDT ì°¨ì´, ë…¸íŠ¸ êµ¬ì„±, ì§€ì†ì‹œê°„ ë“±\"\n",
    "    \n",
    "    query_lower = user_query.lower()\n",
    "    for keyword, answer in faq_responses.items():\n",
    "        if keyword in query_lower:\n",
    "            response = answer\n",
    "            break\n",
    "    \n",
    "    msgs = state[\"messages\"] + [AIMessage(content=response)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": None,\n",
    "        \"router_json\": state.get(\"router_json\"),\n",
    "        \"parsed\": state.get(\"parsed\"),\n",
    "        \"filtered\": state.get(\"filtered\"),\n",
    "        \"recommendations\": state.get(\"recommendations\"),\n",
    "        \"price_info\": state.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "def human_fallback_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ì¼ë°˜ì ì¸ í´ë°±\"\"\"\n",
    "    response = \"â“ í–¥ìˆ˜ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”!\\n\\nğŸ’¡ ì˜ˆì‹œ:\\nâ€¢ í–¥ìˆ˜ ì¶”ì²œ\\nâ€¢ í–¥ìˆ˜ ê°€ê²© ë¬¸ì˜\\nâ€¢ í–¥ìˆ˜ ì§€ì‹ ë¬¸ë‹µ\"\n",
    "    \n",
    "    msgs = state[\"messages\"] + [AIMessage(content=response)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": None,\n",
    "        \"router_json\": state.get(\"router_json\"),\n",
    "        \"parsed\": state.get(\"parsed\"),\n",
    "        \"filtered\": state.get(\"filtered\"),\n",
    "        \"recommendations\": state.get(\"recommendations\"),\n",
    "        \"price_info\": state.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "def price_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ê°€ê²© ì¡°íšŒ\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    \n",
    "    if not user_query:\n",
    "        user_query = \"í–¥ìˆ˜\"\n",
    "    \n",
    "    if not naver_client_id or not naver_client_secret:\n",
    "        price_result = \"âŒ ë„¤ì´ë²„ API ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
    "    else:\n",
    "        price_result = price_tool.invoke({\"user_query\": user_query})\n",
    "    \n",
    "    msgs = state[\"messages\"] + [AIMessage(content=price_result)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": None,\n",
    "        \"router_json\": state.get(\"router_json\"),\n",
    "        \"parsed\": state.get(\"parsed\"),\n",
    "        \"filtered\": state.get(\"filtered\"),\n",
    "        \"recommendations\": state.get(\"recommendations\"),\n",
    "        \"price_info\": price_result\n",
    "    }\n",
    "\n",
    "def ml_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ML ê¸°ë°˜ í–¥ìˆ˜ ì¶”ì²œ (ë©”íƒ€í•„í„°ë§ í¬í•¨)\"\"\"\n",
    "    initialize_recommender()\n",
    "    \n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    \n",
    "    if not user_query:\n",
    "        user_query = \"í–¥ìˆ˜ ì¶”ì²œ\"\n",
    "    \n",
    "    # ì´ì „ ë‹¨ê³„ì—ì„œ íŒŒì‹±ëœ í•„í„° ì •ë³´ ê°€ì ¸ì˜¤ê¸° (LLM_parserë¥¼ ê±°ì³ì˜¨ ê²½ìš°)\n",
    "    meta_filters = state.get(\"filtered\")\n",
    "    \n",
    "    if perfume_recommender is None:\n",
    "        response = \"âŒ ì¶”ì²œ ì‹œìŠ¤í…œì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        recommendations = []\n",
    "    else:\n",
    "        try:\n",
    "            result = perfume_recommender.recommend(\n",
    "                user_text=user_query,\n",
    "                meta_filters=meta_filters,\n",
    "                topk_labels=4,\n",
    "                top_n_perfumes=5,\n",
    "                use_thresholds=True\n",
    "            )\n",
    "            \n",
    "            recommendations = result.get(\"recommendations\", [])\n",
    "            predicted_labels = result.get(\"predicted_labels\", [])\n",
    "            meta_filters_applied = result.get(\"meta_filters_applied\", {})\n",
    "            total_candidates = result.get(\"total_candidates\", 0)\n",
    "            \n",
    "            if recommendations:\n",
    "                response = f\"ğŸ¯ **'{user_query}' ì¶”ì²œ ê²°ê³¼**\\n\\n\"\n",
    "                response += f\"ğŸ·ï¸ **ì˜ˆì¸¡ëœ í–¥ íŠ¹ì„±**: {', '.join(predicted_labels)}\\n\"\n",
    "                \n",
    "                # ì ìš©ëœ ë©”íƒ€í•„í„° í‘œì‹œ\n",
    "                if meta_filters_applied and any(v for v in meta_filters_applied.values() if v is not None):\n",
    "                    response += f\"ğŸ” **ì ìš©ëœ í•„í„°**: \"\n",
    "                    active_filters = []\n",
    "                    korean_labels = {\n",
    "                        \"brand\": \"ë¸Œëœë“œ\",\n",
    "                        \"concentration\": \"ë†ë„\",\n",
    "                        \"day_night_score\": \"ì‚¬ìš©ì‹œê°„\", \n",
    "                        \"gender\": \"ì„±ë³„\",\n",
    "                        \"season_score\": \"ê³„ì ˆ\",\n",
    "                        \"sizes\": \"ìš©ëŸ‰\"\n",
    "                    }\n",
    "                    for k, v in meta_filters_applied.items():\n",
    "                        if v is not None:\n",
    "                            active_filters.append(f\"{korean_labels.get(k, k)}={v}\")\n",
    "                    response += \", \".join(active_filters) + \"\\n\"\n",
    "                \n",
    "                response += f\"ğŸ“Š **ì´ í›„ë³´**: {total_candidates}ê°œ í–¥ìˆ˜\\n\\n\"\n",
    "                \n",
    "                for rec in recommendations:\n",
    "                    response += f\"ğŸŒŸ **{rec['rank']}ìœ„**\\n\"\n",
    "                    response += f\"   ë¸Œëœë“œ: {rec['brand']}\\n\"\n",
    "                    response += f\"   ì œí’ˆëª…: {rec['name']}\\n\"\n",
    "                    response += f\"   í–¥ íŠ¹ì„±: {rec['fragrances']}\\n\"\n",
    "                    response += f\"   ì„±ë³„: {rec['gender']}, ë†ë„: {rec['concentration']}\\n\"\n",
    "                    response += f\"   ê³„ì ˆ: {rec['season_score']}, ìš©ëŸ‰: {rec['sizes']}ml\\n\"\n",
    "                    response += f\"   ì‚¬ìš©ì‹œê°„: {rec['day_night_score']}\\n\\n\"\n",
    "            else:\n",
    "                response = \"ğŸ˜” ì¡°ê±´ì— ë§ëŠ” í–¥ìˆ˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\"\n",
    "                if meta_filters_applied:\n",
    "                    response += \"\\nğŸ’¡ í•„í„° ì¡°ê±´ì„ ì™„í™”í•´ ë³´ì‹œê±°ë‚˜, ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            response = f\"âŒ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "            recommendations = []\n",
    "    \n",
    "    msgs = state[\"messages\"] + [AIMessage(content=response)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": None,\n",
    "        \"router_json\": state.get(\"router_json\"),\n",
    "        \"parsed\": state.get(\"parsed\"),\n",
    "        \"filtered\": state.get(\"filtered\"),\n",
    "        \"recommendations\": recommendations,\n",
    "        \"price_info\": state.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "# ---------- 8) Final Answer Node ----------\n",
    "def final_answer_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ìµœì¢… ë‹µë³€ í†µí•©\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    \n",
    "    # ì´ì „ ë‹¨ê³„ë“¤ì˜ ê²°ê³¼ë¥¼ í†µí•©\n",
    "    filtered_data = state.get(\"filtered\")\n",
    "    recommendations = state.get(\"recommendations\")\n",
    "    router_decision = state.get(\"router_json\", {}).get(\"next\", \"unknown\")\n",
    "    \n",
    "    # íŒŒì‹± ê²°ê³¼ê°€ ìˆê³  ì¶”ì²œì´ í•„ìš”í•œ ê²½ìš°\n",
    "    if filtered_data and \"error\" not in filtered_data and not recommendations:\n",
    "        # ML ì¶”ì²œ ì‹¤í–‰\n",
    "        initialize_recommender()\n",
    "        \n",
    "        if perfume_recommender is not None:\n",
    "            try:\n",
    "                result = perfume_recommender.recommend(\n",
    "                    user_text=user_query,\n",
    "                    meta_filters=filtered_data,\n",
    "                    topk_labels=4,\n",
    "                    top_n_perfumes=5,\n",
    "                    use_thresholds=True\n",
    "                )\n",
    "                \n",
    "                recommendations = result.get(\"recommendations\", [])\n",
    "                predicted_labels = result.get(\"predicted_labels\", [])\n",
    "                meta_filters_applied = result.get(\"meta_filters_applied\", {})\n",
    "                total_candidates = result.get(\"total_candidates\", 0)\n",
    "                \n",
    "                if recommendations:\n",
    "                    final_response = f\"ğŸ¯ **'{user_query}' ìµœì¢… ì¶”ì²œ ê²°ê³¼**\\n\\n\"\n",
    "                    final_response += f\"ğŸ·ï¸ **ì˜ˆì¸¡ëœ í–¥ íŠ¹ì„±**: {', '.join(predicted_labels)}\\n\"\n",
    "                    \n",
    "                    # ì ìš©ëœ ë©”íƒ€í•„í„° í‘œì‹œ\n",
    "                    if meta_filters_applied and any(v for v in meta_filters_applied.values() if v is not None):\n",
    "                        final_response += f\"ğŸ” **ì ìš©ëœ í•„í„°**: \"\n",
    "                        active_filters = []\n",
    "                        korean_labels = {\n",
    "                            \"brand\": \"ë¸Œëœë“œ\",\n",
    "                            \"concentration\": \"ë†ë„\",\n",
    "                            \"day_night_score\": \"ì‚¬ìš©ì‹œê°„\", \n",
    "                            \"gender\": \"ì„±ë³„\",\n",
    "                            \"season_score\": \"ê³„ì ˆ\",\n",
    "                            \"sizes\": \"ìš©ëŸ‰\"\n",
    "                        }\n",
    "                        for k, v in meta_filters_applied.items():\n",
    "                            if v is not None:\n",
    "                                active_filters.append(f\"{korean_labels.get(k, k)}={v}\")\n",
    "                        final_response += \", \".join(active_filters) + \"\\n\"\n",
    "                    \n",
    "                    final_response += f\"ğŸ“Š **ì´ í›„ë³´**: {total_candidates}ê°œ í–¥ìˆ˜\\n\\n\"\n",
    "                    \n",
    "                    for rec in recommendations:\n",
    "                        final_response += f\"ğŸŒŸ **{rec['rank']}ìœ„**\\n\"\n",
    "                        final_response += f\"   ë¸Œëœë“œ: {rec['brand']}\\n\"\n",
    "                        final_response += f\"   ì œí’ˆëª…: {rec['name']}\\n\"\n",
    "                        final_response += f\"   í–¥ íŠ¹ì„±: {rec['fragrances']}\\n\"\n",
    "                        final_response += f\"   ì„±ë³„: {rec['gender']}, ë†ë„: {rec['concentration']}\\n\"\n",
    "                        final_response += f\"   ê³„ì ˆ: {rec['season_score']}, ìš©ëŸ‰: {rec['sizes']}ml\\n\"\n",
    "                        final_response += f\"   ì‚¬ìš©ì‹œê°„: {rec['day_night_score']}\\n\\n\"\n",
    "                        \n",
    "                    final_response += \"ğŸ’¡ **ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”!**\"\n",
    "                else:\n",
    "                    final_response = \"ğŸ˜” ì¡°ê±´ì— ë§ëŠ” í–¥ìˆ˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\\nğŸ’¡ í•„í„° ì¡°ê±´ì„ ì™„í™”í•´ ë³´ì‹œê±°ë‚˜, ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.\"\n",
    "                \n",
    "            except Exception as e:\n",
    "                final_response = f\"âŒ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "        else:\n",
    "            final_response = \"âŒ ì¶”ì²œ ì‹œìŠ¤í…œì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    else:\n",
    "        # ê¸°ë³¸ì ìœ¼ë¡œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¥¼ ìµœì¢… ë‹µë³€ìœ¼ë¡œ ì‚¬ìš©\n",
    "        final_response = \"\"\n",
    "        for m in reversed(state[\"messages\"]):\n",
    "            if isinstance(m, AIMessage) and m.content.strip():\n",
    "                final_response = m.content\n",
    "                break\n",
    "        \n",
    "        if not final_response:\n",
    "            final_response = \"ì£„ì†¡í•©ë‹ˆë‹¤. ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    msgs = state[\"messages\"] + [AIMessage(content=final_response)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": None,\n",
    "        \"router_json\": state.get(\"router_json\"),\n",
    "        \"parsed\": state.get(\"parsed\"),\n",
    "        \"filtered\": state.get(\"filtered\"),\n",
    "        \"recommendations\": recommendations,\n",
    "        \"price_info\": state.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "# ---------- 9) Build Graph ----------\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# ëª¨ë“  ë…¸ë“œ ì¶”ê°€\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"LLM_parser\", llm_parser_node)\n",
    "graph.add_node(\"FAQ_agent\", faq_agent_node)\n",
    "graph.add_node(\"human_fallback\", human_fallback_node)\n",
    "graph.add_node(\"price_agent\", price_agent_node)\n",
    "graph.add_node(\"ML_agent\", ml_agent_node)\n",
    "graph.add_node(\"final_answer\", final_answer_node)\n",
    "\n",
    "# ì‹œì‘ì  ì„¤ì •\n",
    "graph.set_entry_point(\"supervisor\")\n",
    "\n",
    "# supervisorì—ì„œ ê° ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…\n",
    "def router_edge(state: AgentState) -> str:\n",
    "    return state[\"next\"] or \"human_fallback\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    router_edge,\n",
    "    {\n",
    "        \"LLM_parser\": \"LLM_parser\",\n",
    "        \"FAQ_agent\": \"FAQ_agent\", \n",
    "        \"human_fallback\": \"human_fallback\",\n",
    "        \"price_agent\": \"price_agent\",\n",
    "        \"ML_agent\": \"ML_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# LLM_parserëŠ” final_answerë¡œ ì´ë™ (ì¶”ì²œ ë¡œì§ì€ final_answerì—ì„œ ì²˜ë¦¬)\n",
    "graph.add_edge(\"LLM_parser\", \"final_answer\")\n",
    "\n",
    "# ë‹¤ë¥¸ ì—ì´ì „íŠ¸ë“¤ì€ ë°”ë¡œ ì¢…ë£Œ\n",
    "graph.add_edge(\"FAQ_agent\", END)\n",
    "graph.add_edge(\"human_fallback\", END) \n",
    "graph.add_edge(\"price_agent\", END)\n",
    "graph.add_edge(\"ML_agent\", END)\n",
    "\n",
    "# final_answerë„ ì¢…ë£Œ\n",
    "graph.add_edge(\"final_answer\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# ---------- 10) Main Function ----------\n",
    "def process_query(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜\"\"\"\n",
    "    init: AgentState = {\n",
    "        \"messages\": [HumanMessage(content=query)],\n",
    "        \"next\": None,\n",
    "        \"router_json\": None,\n",
    "        \"parsed\": None,\n",
    "        \"filtered\": None,\n",
    "        \"recommendations\": None,\n",
    "        \"price_info\": None\n",
    "    }\n",
    "    \n",
    "    result = app.invoke(init)\n",
    "    \n",
    "    # ê²°ê³¼ ì •ë¦¬\n",
    "    final_response = \"\"\n",
    "    for msg in reversed(result[\"messages\"]):\n",
    "        if isinstance(msg, AIMessage):\n",
    "            final_response = msg.content\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": final_response,\n",
    "        \"router_decision\": result.get(\"router_json\", {}),\n",
    "        \"parsed_data\": result.get(\"parsed\"),\n",
    "        \"filtered_data\": result.get(\"filtered\"),\n",
    "        \"recommendations\": result.get(\"recommendations\"),\n",
    "        \"price_info\": result.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "# ---------- 11) Test Function ----------\n",
    "def run_tests():\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "    TEST_QUERIES = [\n",
    "        \"ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\",\n",
    "        \"ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\",\n",
    "        \"EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?\",\n",
    "        \"íƒ‘ë…¸íŠ¸Â·ë¯¸ë“¤ë…¸íŠ¸Â·ë² ì´ìŠ¤ë…¸íŠ¸ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì´ì•¼?\",\n",
    "        \"ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?\",\n",
    "        \"ìƒ¤ë„¬ ë„˜ë²„5 50ml ìµœì €ê°€ ì•Œë ¤ì¤˜.\",\n",
    "        \"ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\",\n",
    "        \"ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.\",\n",
    "        \"ìƒ¤ë„¬ ì—¬ì„±ìš© ì˜¤ ë“œ í¼í“¸ ì¶”ì²œí•´ì¤˜.\",  # ë©”íƒ€í•„í„°ë§ í…ŒìŠ¤íŠ¸\n",
    "        \"êµ¬ì°Œ ë‚¨ì„±ìš© í–¥ìˆ˜ ì¤‘ì— ë´„ì— ì“¸ ë§Œí•œ ê±° ìˆì–´?\",  # ë³µí•© ì¡°ê±´ í…ŒìŠ¤íŠ¸\n",
    "    ]\n",
    "    \n",
    "    for query in TEST_QUERIES:\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Query: {query}\")\n",
    "        result = process_query(query)\n",
    "        print(f\"Router: {result['router_decision'].get('next', 'unknown')}\")\n",
    "        \n",
    "        if result.get('parsed_data'):\n",
    "            print(f\"Parsed: {result['parsed_data']}\")\n",
    "        if result.get('filtered_data'):\n",
    "            print(f\"Filtered: {result['filtered_data']}\")\n",
    "            \n",
    "        print(f\"Response: {result['response']}\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
