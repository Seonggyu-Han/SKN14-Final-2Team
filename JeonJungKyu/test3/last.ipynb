{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0deb2ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ í™˜ê²½ ë³€ìˆ˜ í™•ì¸:\n",
      "OPENAI_API_KEY: âœ… ì„¤ì •ë¨\n",
      "PINECONE_API_KEY: âœ… ì„¤ì •ë¨\n",
      "NAVER_CLIENT_ID: âœ… ì„¤ì •ë¨\n",
      "NAVER_CLIENT_SECRET: âœ… ì„¤ì •ë¨\n",
      "\n",
      "ğŸš€ í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...\n",
      "\n",
      "ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜:\n",
      "- run_tests(): ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰\n",
      "- run_single_query('your query'): ë‹¨ì¼ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain langgraph langchain-openai tiktoken python-dotenv pinecone-client\n",
    "# pip install joblib numpy torch transformers rank-bm25\n",
    "import os, json, re, requests\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import TypedDict, List, Optional, Dict, Any, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain.agents import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from pinecone import Pinecone\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# ---------- 0) Config ----------\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", \"PUT_YOUR_KEY_HERE\")  # or set in env\n",
    "MODEL_NAME = \"gpt-4o-mini\"  # keep it small & fast for routing\n",
    "\n",
    "# Naver API ì„¤ì •\n",
    "naver_client_id = os.getenv(\"NAVER_CLIENT_ID\")\n",
    "naver_client_secret = os.getenv(\"NAVER_CLIENT_SECRET\")\n",
    "\n",
    "SUPERVISOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are the \"Perfume Recommendation Supervisor (Router)\". Analyze the user's query (Korean or English) and route to exactly ONE agent below.\n",
    "\n",
    "[Agents]\n",
    "- LLM_parser         : Parses/normalizes multi-facet queries (2+ product facets).\n",
    "- FAQ_agent          : Perfume knowledge / definitions / differences / general questions.\n",
    "- human_fallback     : Non-perfume or off-topic queries.\n",
    "- price_agent        : Price-only intents (cheapest, price, buy, discount, etc.).\n",
    "- ML_agent           : Single-preference recommendations (mood/season vibe like \"fresh summer\", \"sweet\", etc.).\n",
    "\n",
    "[Facets to detect (\"product facets\")]\n",
    "- brand            (e.g., Chanel, Dior, Creed)\n",
    "- season           (spring/summer/fall/winter; \"for summer/winter\")\n",
    "- gender           (male/female/unisex)\n",
    "- sizes            (volume in ml: 30/50/100 ml)\n",
    "- day_night_score  (day/night/daily/office/club, etc.)\n",
    "- concentration    (EDT/EDP/Extrait/Parfum/Cologne)\n",
    "\n",
    "[Price intent keywords (not exhaustive)]\n",
    "- Korean: ê°€ê²©, ì–¼ë§ˆ, ê°€ê²©ëŒ€, êµ¬ë§¤, íŒë§¤, í• ì¸, ì–´ë””ì„œ ì‚¬, ë°°ì†¡ë¹„\n",
    "- English: price, cost, cheapest, buy, purchase, discount\n",
    "\n",
    "[FAQ examples]\n",
    "- Differences between EDP vs EDT, note definitions, longevity/projection, brand/line info.\n",
    "\n",
    "[Single-preference (ML_agent) examples]\n",
    "- \"Recommend a cool perfume for summer\", \"Recommend a sweet scent\", \"One citrusy fresh pick\"\n",
    "  (= 0â€“1 of the above facets mentioned; primarily taste/mood/situation).\n",
    "\n",
    "\n",
    "[Routing rules (priority)]\n",
    "1) Non-perfume / off-topic â†’ human_fallback\n",
    "2) Pure price-only intent (no product facets mentioned) â†’ price_agent\n",
    "   e.g., \"í–¥ìˆ˜ ê°€ê²© ì•Œë ¤ì¤˜\" â†’ price_agent\n",
    "3) Count product facets in the query:\n",
    "   - If facets â‰¥ 2 â†’ LLM_parser (can handle price intent within multi-facet queries)\n",
    "   - If facets = 1 AND has price intent â†’ LLM_parser (e.g., \"ìƒ¤ë„¬ í–¥ìˆ˜ ê°€ê²©\")\n",
    "4) Otherwise (single-topic queries):\n",
    "   - Pure price query with specific brand/product â†’ price_agent\n",
    "   - Perfume knowledge/definitions â†’ FAQ_agent\n",
    "   - Single taste/mood recommendation â†’ ML_agent\n",
    "5) Tie-breakers:\n",
    "   - If complex query (multiple aspects) â†’ LLM_parser\n",
    "   - If pure price intent â†’ price_agent\n",
    "   - Else: knowledge â†’ FAQ_agent, taste â†’ ML_agent\n",
    "\n",
    "[Output format]\n",
    "Return ONLY this JSON (no extra text):\n",
    "{{\n",
    "  \"next\": \"<LLM_parser|FAQ_agent|human_fallback|price_agent|ML_agent>\",\n",
    "  \"reason\": \"<one short English sentence>\",\n",
    "  \"facet_count\": <integer>,\n",
    "  \"facets\": {{\n",
    "    \"brand\": \"<value or null>\",\n",
    "    \"season\": \"<value or null>\",\n",
    "    \"gender\": \"<value or null>\",\n",
    "    \"sizes\": \"<value or null>\",\n",
    "    \"day_night_score\": \"<value or null>\",\n",
    "    \"concentration\": \"<value or null>\"\n",
    "  }},\n",
    "  \"scent_vibe\": \"<value if detected, else null>\",\n",
    "  \"query_intent\": \"<price|faq|scent_pref|non_perfume|other>\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "# ---------- 1) State ----------\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]           # conversation log\n",
    "    next: Optional[str]                   # routing decision key\n",
    "    router_json: Optional[Dict[str, Any]] # parsed JSON from router\n",
    "\n",
    "# ---------- 2) LLM ì´ˆê¸°í™” ----------\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Pinecone ì´ˆê¸°í™”\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(\"perfume-vectordb2\")\n",
    "\n",
    "router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SUPERVISOR_SYSTEM_PROMPT),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Call the router LLM and return parsed JSON + routing target.\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    chain = router_prompt | llm\n",
    "    ai = chain.invoke({\"query\": user_query})\n",
    "    text = ai.content\n",
    "\n",
    "    # JSON strict parse\n",
    "    chosen = \"human_fallback\"\n",
    "    parsed: Dict[str, Any] = {}\n",
    "    try:\n",
    "        parsed = json.loads(text)\n",
    "        maybe = parsed.get(\"next\")\n",
    "        if isinstance(maybe, str) and maybe in {\"LLM_parser\",\"FAQ_agent\",\"human_fallback\",\"price_agent\",\"ML_agent\"}:\n",
    "            chosen = maybe\n",
    "    except Exception:\n",
    "        parsed = {\"error\": \"invalid_json\", \"raw\": text}\n",
    "\n",
    "    msgs = state[\"messages\"] + [AIMessage(content=text)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": chosen,\n",
    "        \"router_json\": parsed\n",
    "    }\n",
    "\n",
    "# ---------- 3) RAG Pipeline Functions ----------\n",
    "parse_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë„ˆëŠ” í–¥ìˆ˜ ì¿¼ë¦¬ íŒŒì„œì•¼.\n",
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜:\n",
    "- brand: ë¸Œëœë“œëª… (ì˜ˆ: ìƒ¤ë„¬, ë””ì˜¬, ì…ìƒë¡œë‘ ë“±)\n",
    "- concentration: (í¼í“¸, ì½”ë¡± ë“±)\n",
    "- day_night_score: ì‚¬ìš©ì‹œê°„ (ì£¼ê°„, ì•¼ê°„, ë°ì¼ë¦¬ ë“±)\n",
    "- gender: ì„±ë³„ (ë‚¨ì„±, ì—¬ì„±, ìœ ë‹ˆì„¹ìŠ¤)\n",
    "- season_score: ê³„ì ˆ (ë´„, ì—¬ë¦„, ê°€ì„, ê²¨ìš¸)\n",
    "- sizes: ìš©ëŸ‰ (30ml, 50ml, 100ml ë“±) ë‹¨ìœ„ëŠ” ë¬´ì‹œí•˜ê³  ìˆ«ìë§Œ\n",
    "\n",
    "ì—†ëŠ” ê°’ì€ nullë¡œ ë‘ê³ , ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì¤˜.\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "{{\"brand\": \"ìƒ¤ë„¬\", \"gender\": null, \"sizes\": \"50\", \"season_score\": null, \"concentration\": null, \"day_night_score\": null}}\"\"\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "def run_llm_parser(query: str):\n",
    "    \"\"\"ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±\"\"\"\n",
    "    try:\n",
    "        chain = parse_prompt | llm\n",
    "        ai_response = chain.invoke({\"query\": query})\n",
    "        response_text = ai_response.content.strip()\n",
    "\n",
    "        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "        if \"```json\" in response_text:\n",
    "            response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in response_text:\n",
    "            response_text = response_text.split(\"```\")[1].strip()\n",
    "\n",
    "        parsed = json.loads(response_text)\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"íŒŒì‹± ì˜¤ë¥˜: {str(e)}\"}\n",
    "\n",
    "# ë©”íƒ€í•„í„° í•¨ìˆ˜ë“¤\n",
    "def filter_brand(brand_value):\n",
    "    valid_brands = [\n",
    "        'ê²”ë‘', 'êµ¬ì°Œ', 'ëŒë¡œì—', 'ë‚˜ë¥´ì‹œì†Œ ë¡œë“œë¦¬ê²Œì¦ˆ', 'ë‹ˆìƒ¤ë„¤', 'ë„ë¥´ì„¸', 'ë””ì˜¬', 'ë”¥í‹°í¬', 'ë‘ì½¤',\n",
    "        'ë¡œë¼ ë©”ë¥´ì‹œì—', 'ë¡œì—ë² ', 'ë¡ì‹œë•…', 'ë¥´ ë¼ë³´', 'ë©”ëª¨', 'ë©”ì¢… ë§ˆë¥´ì§€ì—˜ë¼', 'ë©”ì¢… í”„ë€ì‹œìŠ¤ ì»¤ì •',\n",
    "        'ë©œë¦°ì•¤ê²Œì¸ ', 'ë¯¸ìš°ë¯¸ìš°', 'ë°”ì´ë ˆë„', 'ë°˜í´ë¦¬í”„ ì•„í ', 'ë²„ë²„ë¦¬', 'ë² ë¥´ì‚¬ì²´', 'ë¶ˆê°€ë¦¬', 'ë¹„ë””ì¼€ì´',\n",
    "        'ì‚°íƒ€ ë§ˆë¦¬ì•„ ë…¸ë²¨ë¼', 'ìƒ¤ë„¬', 'ì„¸ë¥´ì£¼ ë£¨í…', 'ì‹œìŠ¬ë¦¬ ì½”ìŠ¤ë©”í‹±', 'ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ', 'ì—ë”° ë¦¬ë¸Œë¥´ ë„ëŸ‰ì¥¬',\n",
    "        'ì—ë¥´ë©”ìŠ¤', 'ì—ìŠ¤í‹° ë¡œë”', 'ì—‘ìŠ¤ ë‹ˆíë¡œ', 'ì´ë‹ˆì‹œì˜¤ í¼í“¸', 'ì´ì†', 'ì…ìƒë¡œë‘', 'ì œë¥´ì¡°í”„', 'ì¡° ë§ë¡ ',\n",
    "        'ì¡°ë¥´ì§€ì˜¤ ì•„ë¥´ë§ˆë‹ˆ', 'ì¤„ë¦¬ì—£ í—¤ì¦ˆ ì–´ ê±´', 'ì§€ë°©ì‹œ', 'ì§ˆ ìŠ¤íŠœì–´íŠ¸', 'í¬ë¦¬ë“œ', 'í‚¬ë¦¬ì•ˆ', 'í†° í¬ë“œ',\n",
    "        'í‹°íŒŒë‹ˆì•¤ì½”', 'í¼í“¸ ë“œ ë§ë¦¬', 'íœí• ë¦¬ê³¤ìŠ¤', 'í”„ë¼ë‹¤', 'í”„ë ˆë°ë¦­ ë§'\n",
    "    ]\n",
    "    if brand_value is None:\n",
    "        return None\n",
    "    return brand_value if brand_value in valid_brands else None\n",
    "\n",
    "def filter_concentration(concentration_value):\n",
    "    valid_concentrations = ['ì†”ë¦¬ë“œ í¼í“¸', 'ì—‘ìŠ¤íŠ¸ë ˆ ë“œ í¼í“¸', 'ì˜¤ ë“œ ëšœì™ˆë ›', 'ì˜¤ ë“œ ì½”ë¡±', 'ì˜¤ ë“œ í¼í“¸', 'í¼í“¸']\n",
    "    if concentration_value is None:\n",
    "        return None\n",
    "    return concentration_value if concentration_value in valid_concentrations else None\n",
    "\n",
    "def filter_day_night_score(day_night_value):\n",
    "    valid_day_night = [\"day\", \"night\"]\n",
    "    if day_night_value is None:\n",
    "        return None\n",
    "    if isinstance(day_night_value, str) and ',' in day_night_value:\n",
    "        values = [v.strip() for v in day_night_value.split(',')]\n",
    "        filtered_values = [v for v in values if v in valid_day_night]\n",
    "        return ','.join(filtered_values) if filtered_values else None\n",
    "    return day_night_value if day_night_value in valid_day_night else None\n",
    "\n",
    "def filter_gender(gender_value):\n",
    "    valid_genders = ['Female', 'Male', 'Unisex', 'unisex ']\n",
    "    if gender_value is None:\n",
    "        return None\n",
    "    return gender_value if gender_value in valid_genders else None\n",
    "\n",
    "def filter_season_score(season_value):\n",
    "    valid_seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "    if season_value is None:\n",
    "        return None\n",
    "    return season_value if season_value in valid_seasons else None\n",
    "\n",
    "def filter_sizes(sizes_value):\n",
    "    valid_sizes = ['30', '50', '75', '100', '150']\n",
    "    if sizes_value is None:\n",
    "        return None\n",
    "    if isinstance(sizes_value, str):\n",
    "        numbers = re.findall(r'\\d+', sizes_value)\n",
    "        for num in numbers:\n",
    "            if num in valid_sizes:\n",
    "                return num\n",
    "    return str(sizes_value) if str(sizes_value) in valid_sizes else None\n",
    "\n",
    "def apply_meta_filters(parsed_json: dict) -> dict:\n",
    "    \"\"\"íŒŒì‹±ëœ JSONì— ë©”íƒ€priceë§ ì ìš©\"\"\"\n",
    "    if not parsed_json or \"error\" in parsed_json:\n",
    "        return parsed_json\n",
    "    \n",
    "    return {\n",
    "        'brand': filter_brand(parsed_json.get('brand')),\n",
    "        'concentration': filter_concentration(parsed_json.get('concentration')),\n",
    "        'day_night_score': filter_day_night_score(parsed_json.get('day_night_score')),\n",
    "        'gender': filter_gender(parsed_json.get('gender')),\n",
    "        'season_score': filter_season_score(parsed_json.get('season_score')),\n",
    "        'sizes': filter_sizes(parsed_json.get('sizes'))\n",
    "    }\n",
    "\n",
    "def build_pinecone_filter(filtered_json: dict) -> dict:\n",
    "    \"\"\"ë©”íƒ€priceë§ ê²°ê³¼ë¥¼ Pinecone filter dictë¡œ ë³€í™˜\"\"\"\n",
    "    pinecone_filter = {}\n",
    "    if filtered_json.get(\"brand\"):\n",
    "        pinecone_filter[\"brand\"] = {\"$eq\": filtered_json[\"brand\"]}\n",
    "    if filtered_json.get(\"sizes\"):\n",
    "        pinecone_filter[\"sizes\"] = {\"$eq\": filtered_json[\"sizes\"]}\n",
    "    if filtered_json.get(\"season_score\"):\n",
    "        pinecone_filter[\"season_score\"] = {\"$eq\": filtered_json[\"season_score\"]}\n",
    "    if filtered_json.get(\"gender\"):\n",
    "        pinecone_filter[\"gender\"] = {\"$eq\": filtered_json[\"gender\"]}\n",
    "    if filtered_json.get(\"concentration\"):\n",
    "        pinecone_filter[\"concentration\"] = {\"$eq\": filtered_json[\"concentration\"]}\n",
    "    if filtered_json.get(\"day_night_score\"):\n",
    "        pinecone_filter[\"day_night_score\"] = {\"$eq\": filtered_json[\"day_night_score\"]}\n",
    "    return pinecone_filter\n",
    "\n",
    "keyword_extraction_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë„ˆëŠ” ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ìš© í‚¤ì›Œë“œ ì¶”ì¶œ ì „ë¬¸ê°€ì•¼.\n",
    "\n",
    "ì‚¬ìš©ìì˜ í–¥ìˆ˜ ê°€ê²© ì§ˆë¬¸ì—ì„œ ë„¤ì´ë²„ ì‡¼í•‘ API ê²€ìƒ‰ì— ìµœì í™”ëœ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•´ì¤˜.\n",
    "\n",
    "**ì¶”ì¶œ ê·œì¹™:**\n",
    "1. ë¸Œëœë“œëª…ê³¼ ì œí’ˆëª…ë§Œ ì¶”ì¶œ (í•œêµ­ì–´ ìš°ì„ )\n",
    "2. ê°€ê²© ê´€ë ¨ ë‹¨ì–´ë“¤ì€ ëª¨ë‘ ì œê±° (ê°€ê²©, ì–¼ë§ˆ, ìµœì €ê°€, í• ì¸, ì–´ë””ì„œ, ì‚¬ëŠ”, êµ¬ë§¤ ë“±)\n",
    "3. ì§ˆë¬¸ í˜•íƒœ ë‹¨ì–´ë“¤ë„ ì œê±° (?, ì•¼, ê²Œ, ì¤˜, ì•Œë ¤, ë­, ì–´ë–¤ ë“±)\n",
    "4. ìµœëŒ€ 2-3ê°œ ë‹¨ì–´ë¡œ ê°„ê²°í•˜ê²Œ\n",
    "5. í–¥ìˆ˜ ë¸Œëœë“œëª…ê³¼ ì œí’ˆëª…ì´ ëª…í™•í•˜ë©´ \"ë¸Œëœë“œ ì œí’ˆëª…\" í˜•íƒœë¡œ\n",
    "6. ë¸Œëœë“œëª…ë§Œ ìˆìœ¼ë©´ \"ë¸Œëœë“œëª…\" ë§Œ\n",
    "7. ì• ë§¤í•˜ë©´ \"í–¥ìˆ˜\" í‚¤ì›Œë“œ ì‚¬ìš©\n",
    "\n",
    "**ì˜ˆì‹œ:**\n",
    "- \"ë””ì˜¬ ì†Œë°”ì¥¬ ê°€ê²© ì–¼ë§ˆì•¼?\" â†’ \"ë””ì˜¬ ì†Œë°”ì¥¬\"  \n",
    "- \"ìƒ¤ë„¬ ë„˜ë²„5 50ml ì–´ë””ì„œ ì‚¬?\" â†’ \"ìƒ¤ë„¬ ë„˜ë²„5\"\n",
    "- \"í†°í¬ë“œ í–¥ìˆ˜ ìµœì €ê°€ ì•Œë ¤ì¤˜\" â†’ \"í†°í¬ë“œ í–¥ìˆ˜\"\n",
    "- \"í–¥ìˆ˜ ê°€ê²© ì•Œë ¤ì¤˜\" â†’ \"í–¥ìˆ˜\"\n",
    "\n",
    "ë°˜ë“œì‹œ ê²€ìƒ‰ í‚¤ì›Œë“œë§Œ ì‘ë‹µí•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ë§ˆ.\"\"\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "\n",
    "# í‚¤ì›Œë“œ ì •ì œìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¶”ê°€\n",
    "keyword_extraction_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë„ˆëŠ” ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ìš© í‚¤ì›Œë“œ ì¶”ì¶œ ì „ë¬¸ê°€ì•¼.\n",
    "\n",
    "ì‚¬ìš©ìì˜ í–¥ìˆ˜ ê°€ê²© ì§ˆë¬¸ì—ì„œ ë„¤ì´ë²„ ì‡¼í•‘ API ê²€ìƒ‰ì— ìµœì í™”ëœ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•´ì¤˜.\n",
    "\n",
    "**ì¶”ì¶œ ê·œì¹™:**\n",
    "1. ë¸Œëœë“œëª…ê³¼ ì œí’ˆëª…ë§Œ ì¶”ì¶œ (í•œêµ­ì–´ ìš°ì„ )\n",
    "2. ê°€ê²© ê´€ë ¨ ë‹¨ì–´ë“¤ì€ ëª¨ë‘ ì œê±° (ê°€ê²©, ì–¼ë§ˆ, ìµœì €ê°€, í• ì¸, ì–´ë””ì„œ, ì‚¬ëŠ”, êµ¬ë§¤ ë“±)\n",
    "3. ì§ˆë¬¸ í˜•íƒœ ë‹¨ì–´ë“¤ë„ ì œê±° (?, ì•¼, ê²Œ, ì¤˜, ì•Œë ¤, ë­, ì–´ë–¤ ë“±)\n",
    "4. ìµœëŒ€ 2-3ê°œ ë‹¨ì–´ë¡œ ê°„ê²°í•˜ê²Œ\n",
    "5. í–¥ìˆ˜ ë¸Œëœë“œëª…ê³¼ ì œí’ˆëª…ì´ ëª…í™•í•˜ë©´ \"ë¸Œëœë“œ ì œí’ˆëª…\" í˜•íƒœë¡œ\n",
    "6. ë¸Œëœë“œëª…ë§Œ ìˆìœ¼ë©´ \"ë¸Œëœë“œëª…\" ë§Œ\n",
    "7. ì• ë§¤í•˜ë©´ \"í–¥ìˆ˜\" í‚¤ì›Œë“œ ì‚¬ìš©\n",
    "\n",
    "**ì˜ˆì‹œ:**\n",
    "- \"ë””ì˜¬ ì†Œë°”ì¥¬ ê°€ê²© ì–¼ë§ˆì•¼?\" â†’ \"ë””ì˜¬ ì†Œë°”ì¥¬\"  \n",
    "- \"ìƒ¤ë„¬ ë„˜ë²„5 50ml ì–´ë””ì„œ ì‚¬?\" â†’ \"ìƒ¤ë„¬ ë„˜ë²„5\"\n",
    "- \"í†°í¬ë“œ í–¥ìˆ˜ ìµœì €ê°€ ì•Œë ¤ì¤˜\" â†’ \"í†°í¬ë“œ í–¥ìˆ˜\"\n",
    "- \"í–¥ìˆ˜ ê°€ê²© ì•Œë ¤ì¤˜\" â†’ \"í–¥ìˆ˜\"\n",
    "\n",
    "ë°˜ë“œì‹œ ê²€ìƒ‰ í‚¤ì›Œë“œë§Œ ì‘ë‹µí•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ë§ˆ.\"\"\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "@tool\n",
    "def price_tool(user_query: str) -> str:\n",
    "    \"\"\"A tool that uses the Naver Shopping API to look up perfume prices (results are returned as formatted strings)\"\"\"\n",
    "    \n",
    "    # LLMìœ¼ë¡œ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "    search_keyword = extract_search_keyword_with_llm(user_query)\n",
    "    \n",
    "    url = \"https://openapi.naver.com/v1/search/shop.json\"\n",
    "    headers = {\n",
    "        \"X-Naver-Client-Id\": naver_client_id,\n",
    "        \"X-Naver-Client-Secret\": naver_client_secret\n",
    "    }\n",
    "    params = {\"query\": search_keyword, \"display\": 5, \"sort\": \"sim\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "    except Exception as e:\n",
    "        return f\"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}\"\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f\"âŒ API ì˜¤ë¥˜: {response.status_code}\"\n",
    "    \n",
    "    data = response.json()\n",
    "    if not data or \"items\" not in data or len(data[\"items\"]) == 0:\n",
    "        return f\"ğŸ˜” '{search_keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\\nğŸ’¡ ë‹¤ë¥¸ ë¸Œëœë“œëª…ì´ë‚˜ í–¥ìˆ˜ëª…ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.\"\n",
    "    \n",
    "    # HTML íƒœê·¸ ì œê±° í•¨ìˆ˜\n",
    "    def remove_html_tags(text: str) -> str:\n",
    "        return re.sub(r\"<[^>]+>\", \"\", text)\n",
    "    \n",
    "    # ìƒìœ„ 3ê°œë§Œ ì •ë¦¬\n",
    "    products = data[\"items\"][:3]\n",
    "    output = f\"ğŸ” '{search_keyword}' ê²€ìƒ‰ ê²°ê³¼:\\n\\n\"\n",
    "    \n",
    "    prices = []  # ê°€ê²© ì •ë³´ ìˆ˜ì§‘ìš©\n",
    "    \n",
    "    for i, item in enumerate(products, 1):\n",
    "        title = remove_html_tags(item.get(\"title\", \"\"))\n",
    "        lprice = item.get(\"lprice\", \"0\")\n",
    "        mall = item.get(\"mallName\", \"ì •ë³´ ì—†ìŒ\")\n",
    "        link = item.get(\"link\", \"ì •ë³´ ì—†ìŒ\")\n",
    "        \n",
    "        output += f\"ğŸ“¦ {i}. {title}\\n\"\n",
    "        if lprice != \"0\":\n",
    "            formatted_price = f\"{int(lprice):,}ì›\"\n",
    "            output += f\"   ğŸ’° ê°€ê²©: {formatted_price}\\n\"\n",
    "            prices.append(int(lprice))\n",
    "        output += f\"   ğŸª íŒë§¤ì²˜: {mall}\\n\"\n",
    "        output += f\"   ğŸ”— ë§í¬: {link}\\n\\n\"\n",
    "    \n",
    "    # ê°€ê²© ë²”ìœ„ ì •ë³´ ì¶”ê°€ (ìµœì €ê°€/ìµœê³ ê°€ ëŒ€ì‹  ê°€ê²©ëŒ€ ì •ë³´ ì œê³µ)\n",
    "    if prices:\n",
    "        min_price = min(prices)\n",
    "        max_price = max(prices)\n",
    "        if len(prices) > 1:\n",
    "            output += f\"ğŸ’¡ **ê°€ê²©ëŒ€ ì •ë³´**\\n\"\n",
    "            output += f\"   ğŸ“Š ê²€ìƒ‰ëœ ê°€ê²© ë²”ìœ„: {min_price:,}ì› ~ {max_price:,}ì›\\n\"\n",
    "            output += f\"   âš ï¸ ì •í™•í•œ ìµœì €ê°€/ìµœê³ ê°€ ì •ë³´ëŠ” ê° ì‡¼í•‘ëª°ì—ì„œ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.\\n\"\n",
    "        else:\n",
    "            output += f\"ğŸ’¡ **ì°¸ê³ ì‚¬í•­**\\n\"\n",
    "            output += f\"   âš ï¸ ë” ë§ì€ ê°€ê²© ë¹„êµë¥¼ ì›í•˜ì‹œë©´ ì—¬ëŸ¬ ì‡¼í•‘ëª°ì„ ì§ì ‘ í™•ì¸í•´ë³´ì„¸ìš”.\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "def extract_search_keyword_with_llm(user_query: str) -> str:\n",
    "    \"\"\"LLMì„ ì‚¬ìš©í•´ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ\"\"\"\n",
    "    try:\n",
    "        chain = keyword_extraction_prompt | llm\n",
    "        response = chain.invoke({\"query\": user_query})\n",
    "        keyword = response.content.strip()\n",
    "        \n",
    "        # ë¹ˆ ì‘ë‹µì´ê±°ë‚˜ ë„ˆë¬´ ê¸´ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜\n",
    "        if not keyword or len(keyword) > 20:\n",
    "            return \"í–¥ìˆ˜\"\n",
    "        \n",
    "        return keyword\n",
    "    except Exception as e:\n",
    "        print(f\"í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}\")\n",
    "        return \"í–¥ìˆ˜\"  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’\n",
    "\n",
    "@tool\n",
    "def faq_knowledge_tool(question: str) -> str:\n",
    "    \"\"\"í–¥ìˆ˜ ê´€ë ¨ ì§€ì‹ê³¼ FAQë¥¼ ë‹µë³€í•˜ëŠ” ë„êµ¬\"\"\"\n",
    "    # ê¸°ë³¸ì ì¸ í–¥ìˆ˜ ì§€ì‹ DB\n",
    "    faq_db = {\n",
    "        \"edp edt ì°¨ì´\": \"EDP(Eau de Parfum)ëŠ” í–¥ë£Œ ë†ë„ 15-20%ë¡œ ì§€ì†ë ¥ì´ 6-8ì‹œê°„, EDT(Eau de Toilette)ëŠ” ë†ë„ 5-15%ë¡œ ì§€ì†ë ¥ì´ 2-4ì‹œê°„ì…ë‹ˆë‹¤.\",\n",
    "        \"íƒ‘ë…¸íŠ¸ ë¯¸ë“¤ë…¸íŠ¸ ë² ì´ìŠ¤ë…¸íŠ¸\": \"íƒ‘ë…¸íŠ¸ëŠ” ì²˜ìŒ 10-15ë¶„ê°„ ëŠë¼ëŠ” í–¥, ë¯¸ë“¤ë…¸íŠ¸ëŠ” 1-3ì‹œê°„ ì§€ì†ë˜ëŠ” ë©”ì¸ í–¥, ë² ì´ìŠ¤ë…¸íŠ¸ëŠ” 3ì‹œê°„ ì´í›„ ë‚¨ëŠ” ì”í–¥ì…ë‹ˆë‹¤.\",\n",
    "        \"í–¥ìˆ˜ ì§€ì†ë ¥\": \"í–¥ìˆ˜ ì§€ì†ë ¥ì€ ë†ë„, í”¼ë¶€íƒ€ì…, ë‚ ì”¨ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ë³´ìŠµëœ í”¼ë¶€ì— ë¿Œë¦¬ë©´ ë” ì˜¤ë˜ ì§€ì†ë©ë‹ˆë‹¤.\",\n",
    "        \"í–¥ìˆ˜ ë³´ê´€ë²•\": \"ì§ì‚¬ê´‘ì„ ì„ í”¼í•˜ê³  ì„œëŠ˜í•œ ê³³ì— ë³´ê´€í•˜ì„¸ìš”. ëƒ‰ì¥ê³  ë³´ê´€ë„ ì¢‹ìŠµë‹ˆë‹¤.\",\n",
    "        \"í–¥ìˆ˜ ì¢…ë¥˜\": \"ë†ë„ ìˆœìœ¼ë¡œ í¼í“¸(20-40%), EDP(15-20%), EDT(5-15%), ì˜¤ë“œì½œë¡œë‰´(2-5%)ì…ë‹ˆë‹¤.\"\n",
    "    }\n",
    "    \n",
    "    # í‚¤ì›Œë“œ ë§¤ì¹­\n",
    "    question_lower = question.lower()\n",
    "    for key, answer in faq_db.items():\n",
    "        if any(word in question_lower for word in key.split()):\n",
    "            return f\"ğŸ’¡ {answer}\"\n",
    "    \n",
    "    return f\"ğŸ“š '{question}'ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "@tool\n",
    "def recommend_perfume_simple(\n",
    "    user_text: str,\n",
    "    topk_labels: int = 4,\n",
    "    top_n_perfumes: int = 5,\n",
    "    use_thresholds: bool = True,\n",
    "    model_pkl_path: str = \"./models.pkl\",\n",
    "    perfume_json_path: str = \"perfumes.json\",\n",
    "    model_name: str = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    max_len: int = 256,\n",
    "):\n",
    "    \"\"\"\n",
    "    Minimal one-shot perfume recommender (no caching).\n",
    "    Loads model & data every call, predicts labels, retrieves with BM25, and returns a JSON-serializable dict.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # 1) Load ML bundle\n",
    "    data = joblib.load(model_pkl_path)\n",
    "    clf = data[\"classifier\"]\n",
    "    mlb = data[\"mlb\"]\n",
    "    thresholds = data.get(\"thresholds\", {}) or {}\n",
    "\n",
    "    # 2) Encoder\n",
    "    tok = AutoTokenizer.from_pretrained(model_name)\n",
    "    enc_model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    enc_model.eval()\n",
    "\n",
    "    # 3) Load perfumes\n",
    "    with open(perfume_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        perfumes = json.load(f)\n",
    "        if not isinstance(perfumes, list):\n",
    "            raise ValueError(\"perfumes.json must contain a list of perfume objects\")\n",
    "\n",
    "    # 4) BM25 index (simple: use 'fragrances' or fallback to description/name/brand)\n",
    "    def doc_of(p):\n",
    "        fr = p.get(\"fragrances\")\n",
    "        if isinstance(fr, list):\n",
    "            text = \" \".join(map(str, fr))\n",
    "        elif isinstance(fr, str):\n",
    "            text = fr\n",
    "        else:\n",
    "            text = \" \".join(\n",
    "                str(x)\n",
    "                for x in [\n",
    "                    p.get(\"description\", \"\"),\n",
    "                    p.get(\"main_accords\", \"\"),\n",
    "                    p.get(\"name_perfume\") or p.get(\"name\", \"\"),\n",
    "                    p.get(\"brand\", \"\"),\n",
    "                ]\n",
    "                if x\n",
    "            )\n",
    "        return (text or \"unknown\").lower()\n",
    "\n",
    "    tokenized_corpus = [doc_of(p).split() for p in perfumes]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    # 5) Encode text -> vector\n",
    "    batch = tok(\n",
    "        [user_text],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = enc_model(**batch)\n",
    "        emb = out.last_hidden_state.mean(dim=1).cpu().numpy()  # ultra-simple mean\n",
    "\n",
    "    # 6) Predict labels (supports predict_proba / decision_function / predict)\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        proba = clf.predict_proba(emb)[0]\n",
    "    elif hasattr(clf, \"decision_function\"):\n",
    "        logits = np.asarray(clf.decision_function(emb)[0], dtype=float)\n",
    "        proba = 1.0 / (1.0 + np.exp(-logits))\n",
    "    else:\n",
    "        proba = np.asarray(clf.predict(emb)[0], dtype=float)\n",
    "\n",
    "    classes = list(mlb.classes_)\n",
    "    if use_thresholds and thresholds:\n",
    "        picked_idx = [i for i, p in enumerate(proba) if p >= float(thresholds.get(classes[i], 0.5))]\n",
    "        if not picked_idx:\n",
    "            picked_idx = np.argsort(-proba)[:topk_labels].tolist()\n",
    "    else:\n",
    "        picked_idx = np.argsort(-proba)[:topk_labels].tolist()\n",
    "\n",
    "    labels = [classes[i] for i in picked_idx]\n",
    "\n",
    "    # 7) Retrieve with BM25\n",
    "    scores = bm25.get_scores(\" \".join(labels).split())\n",
    "    top_idx = np.argsort(scores)[-top_n_perfumes:][::-1]\n",
    "\n",
    "    def _safe(d, *keys, default=\"N/A\"):\n",
    "        for k in keys:\n",
    "            if k in d and d[k] not in (None, \"\"):\n",
    "                return d[k]\n",
    "        return default\n",
    "\n",
    "    recs = []\n",
    "    for rnk, idx in enumerate(top_idx, 1):\n",
    "        p = perfumes[int(idx)]\n",
    "        fr = p.get(\"fragrances\")\n",
    "        if isinstance(fr, list):\n",
    "            fr_text = \", \".join(map(str, fr))\n",
    "        else:\n",
    "            fr_text = fr if isinstance(fr, str) else _safe(p, \"main_accords\", default=\"N/A\")\n",
    "        recs.append({\n",
    "            \"rank\": int(rnk),\n",
    "            \"index\": int(idx),\n",
    "            \"score\": float(scores[int(idx)]),\n",
    "            \"brand\": _safe(p, \"brand\"),\n",
    "            \"name\": _safe(p, \"name_perfume\", \"name\"),\n",
    "            \"fragrances\": fr_text,\n",
    "            \"perfume_data\": p,  # JSON-native\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"user_input\": user_text,\n",
    "        \"predicted_labels\": labels,\n",
    "        \"recommendations\": recs,\n",
    "        \"meta\": {\n",
    "            \"model_name\": model_name,\n",
    "            \"device\": device,\n",
    "            \"max_len\": int(max_len),\n",
    "            \"db_size\": int(len(perfumes)),\n",
    "        },\n",
    "    }\n",
    "\n",
    "def query_pinecone(vector, filtered_json: dict, top_k: int = 5):\n",
    "    \"\"\"Pinecone ë²¡í„° ê²€ìƒ‰ + ë©”íƒ€ë°ì´í„° price ì ìš©\"\"\"\n",
    "    pinecone_filter = build_pinecone_filter(filtered_json)\n",
    "    \n",
    "    result = index.query(\n",
    "        vector=vector,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        filter=pinecone_filter if pinecone_filter else None\n",
    "    )\n",
    "    return result\n",
    "\n",
    "response_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë„ˆëŠ” í–¥ìˆ˜ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì¶”ì²œì„ í•´ì¤˜.\n",
    "\n",
    "ì¶”ì²œí•  ë•Œ ë‹¤ìŒì„ í¬í•¨í•´ì¤˜:\n",
    "1. ì™œ ì´ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•˜ëŠ”ì§€\n",
    "2. í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ\n",
    "3. ì–´ë–¤ ìƒí™©ì— ì í•©í•œì§€\n",
    "4. ê°€ê²©ëŒ€ë‚˜ ìš©ëŸ‰ ê´€ë ¨ ì¡°ì–¸ (ìˆë‹¤ë©´)\n",
    "\n",
    "ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.\"\"\"),\n",
    "    (\"user\", \"\"\"ì‚¬ìš©ì ì§ˆë¬¸: {original_query}\n",
    "\n",
    "ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´:\n",
    "{search_results}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì¤˜.\"\"\")\n",
    "])\n",
    "\n",
    "def format_search_results(pinecone_results):\n",
    "    \"\"\"Pinecone ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…\"\"\"\n",
    "    if not pinecone_results or not pinecone_results.get('matches'):\n",
    "        return \"ê²€ìƒ‰ëœ í–¥ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    formatted_results = []\n",
    "    for i, match in enumerate(pinecone_results['matches'], 1):\n",
    "        metadata = match.get('metadata', {})\n",
    "        score = match.get('score', 0)\n",
    "        \n",
    "        result_text = f\"\"\"\n",
    "{i}. í–¥ìˆ˜ëª…: {metadata.get('perfume_name', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ë¸Œëœë“œ: {metadata.get('brand', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ì„±ë³„: {metadata.get('gender', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ìš©ëŸ‰: {metadata.get('sizes', 'ì •ë³´ì—†ìŒ')}ml\n",
    "   - ê³„ì ˆ: {metadata.get('season_score', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ì‚¬ìš©ì‹œê°„: {metadata.get('day_night_score', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ë†ë„: {metadata.get('concentration', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ìœ ì‚¬ë„ ì ìˆ˜: {score:.3f}\n",
    "\"\"\"\n",
    "        formatted_results.append(result_text.strip())\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "def generate_response(original_query: str, search_results):\n",
    "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„±\"\"\"\n",
    "    try:\n",
    "        formatted_results = format_search_results(search_results)\n",
    "        \n",
    "        chain = response_prompt | llm\n",
    "        response = chain.invoke({\n",
    "            \"original_query\": original_query,\n",
    "            \"search_results\": formatted_results\n",
    "        })\n",
    "        \n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "def extract_price_search_keywords(search_results, original_query: str, parsed_json: dict) -> str:\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‹¤ì œ í–¥ìˆ˜ ì œí’ˆëª…ì„ ì¶”ì¶œí•˜ì—¬ ê°€ê²© ê²€ìƒ‰ í‚¤ì›Œë“œë¡œ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    # 1. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í–¥ìˆ˜ëª… ì¶”ì¶œ (ìµœìƒìœ„ 1ê°œ)\n",
    "    if search_results and search_results.get('matches'):\n",
    "        top_match = search_results['matches'][0]  # ê°€ì¥ ìœ ì‚¬ë„ ë†’ì€ í–¥ìˆ˜\n",
    "        metadata = top_match.get('metadata', {})\n",
    "        \n",
    "        perfume_name = metadata.get('perfume_name', '')\n",
    "        brand_name = metadata.get('brand', '')\n",
    "        \n",
    "        if perfume_name and brand_name:\n",
    "            # \"ë¸Œëœë“œ + í–¥ìˆ˜ëª…\" ì¡°í•©ìœ¼ë¡œ êµ¬ì²´ì ì¸ ê²€ìƒ‰\n",
    "            search_keyword = f\"{brand_name} {perfume_name}\"\n",
    "            \n",
    "            # ìš©ëŸ‰ ì •ë³´ ì¶”ê°€ (ìˆë‹¤ë©´)\n",
    "            sizes = parsed_json.get('sizes')\n",
    "            if sizes:\n",
    "                search_keyword += f\" {sizes}ml\"\n",
    "            \n",
    "            return search_keyword\n",
    "        \n",
    "        elif perfume_name:\n",
    "            # í–¥ìˆ˜ëª…ë§Œ ìˆëŠ” ê²½ìš°\n",
    "            sizes = parsed_json.get('sizes')\n",
    "            if sizes:\n",
    "                return f\"{perfume_name} {sizes}ml\"\n",
    "            return perfume_name\n",
    "        \n",
    "        elif brand_name:\n",
    "            # ë¸Œëœë“œëª…ë§Œ ìˆëŠ” ê²½ìš°\n",
    "            sizes = parsed_json.get('sizes')\n",
    "            if sizes:\n",
    "                return f\"{brand_name} í–¥ìˆ˜ {sizes}ml\"\n",
    "            return f\"{brand_name} í–¥ìˆ˜\"\n",
    "    \n",
    "    # 2. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ë©”íƒ€ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° íŒŒì‹± ê²°ê³¼ ì‚¬ìš©\n",
    "    brand = parsed_json.get('brand')\n",
    "    sizes = parsed_json.get('sizes')\n",
    "    \n",
    "    if brand:\n",
    "        if sizes:\n",
    "            return f\"{brand} í–¥ìˆ˜ {sizes}ml\"\n",
    "        return f\"{brand} í–¥ìˆ˜\"\n",
    "    \n",
    "    # 3. ëª¨ë“  ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’\n",
    "    return \"í–¥ìˆ˜\"\n",
    "\n",
    "# ---------- 4) Agent Nodes ----------\n",
    "def LLM_parser_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” LLM_parser ë…¸ë“œ + ê°€ê²© ê²€ìƒ‰ í†µí•©\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸ” LLM_parser ì‹¤í–‰: {user_query}\")\n",
    "        \n",
    "        # 1ë‹¨ê³„: LLMìœ¼ë¡œ ì¿¼ë¦¬ íŒŒì‹±\n",
    "        parsed_json = run_llm_parser(user_query)\n",
    "        if \"error\" in parsed_json:\n",
    "            error_msg = f\"[LLM_parser] ì¿¼ë¦¬ íŒŒì‹± ì˜¤ë¥˜: {parsed_json['error']}\"\n",
    "            msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "            return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "        \n",
    "        # 2ë‹¨ê³„: ë©”íƒ€í•„í„° ì ìš©\n",
    "        filtered_json = apply_meta_filters(parsed_json)\n",
    "        \n",
    "        # 3ë‹¨ê³„: ì¿¼ë¦¬ ë²¡í„°í™”\n",
    "        query_vector = embeddings.embed_query(user_query)\n",
    "        \n",
    "        # 4ë‹¨ê³„: Pinecone ê²€ìƒ‰\n",
    "        search_results = query_pinecone(query_vector, filtered_json, top_k=5)\n",
    "        \n",
    "        # 5ë‹¨ê³„: ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "        final_response = generate_response(user_query, search_results)\n",
    "        \n",
    "        # 6ë‹¨ê³„: ê°€ê²© ì˜ë„ ê°ì§€ ë° ê°€ê²© ì •ë³´ ì¶”ê°€\n",
    "        price_keywords = ['ê°€ê²©', 'ì–¼ë§ˆ', 'ê°€ê²©ëŒ€', 'êµ¬ë§¤', 'íŒë§¤', 'í• ì¸', 'ì–´ë””ì„œ ì‚¬', 'ë°°ì†¡ë¹„', 'price', 'cost', 'cheapest', 'buy', 'purchase', 'discount']\n",
    "        has_price_intent = any(keyword in user_query.lower() for keyword in price_keywords)\n",
    "        \n",
    "        if has_price_intent:\n",
    "            # ê²€ìƒ‰ëœ í–¥ìˆ˜ë“¤ë¡œë¶€í„° ê°€ê²© ê²€ìƒ‰ìš© í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "            price_search_keywords = extract_price_search_keywords(search_results, user_query, parsed_json)\n",
    "            \n",
    "            print(f\"ğŸ’° ê°€ê²© ê²€ìƒ‰ í‚¤ì›Œë“œ: {price_search_keywords}\")\n",
    "            print(f\"ğŸ” ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´: {search_results.get('matches', [{}])[0].get('metadata', {}) if search_results.get('matches') else 'No matches'}\")\n",
    "            \n",
    "            if price_search_keywords and price_search_keywords != \"í–¥ìˆ˜\":\n",
    "                try:\n",
    "                    price_info = price_tool.invoke({\"user_query\": price_search_keywords})\n",
    "                    \n",
    "                    # ê°€ê²© ì •ë³´ë¥¼ ìµœì¢… ì‘ë‹µì— ì¶”ê°€\n",
    "                    final_response_with_price = f\"\"\"{final_response}\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ’° **ê°€ê²© ì •ë³´**\n",
    "{price_info}\"\"\"\n",
    "                except Exception as price_error:\n",
    "                    print(f\"âŒ ê°€ê²© ê²€ìƒ‰ ì˜¤ë¥˜: {price_error}\")\n",
    "                    final_response_with_price = f\"\"\"{final_response}\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ’° **ê°€ê²© ì •ë³´**\n",
    "âŒ ê°€ê²© ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "            else:\n",
    "                final_response_with_price = f\"\"\"{final_response}\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ’° **ê°€ê²© ì •ë³´**\n",
    "ğŸ” êµ¬ì²´ì ì¸ í–¥ìˆ˜ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤. ìœ„ ì¶”ì²œ í–¥ìˆ˜ë“¤ ì¤‘ ì›í•˜ëŠ” ì œí’ˆëª…ì„ ë‹¤ì‹œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.\"\"\"\n",
    "        else:\n",
    "            final_response_with_price = final_response\n",
    "        \n",
    "        # ê²°ê³¼ ìš”ì•½\n",
    "        summary = f\"\"\"[LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ âœ…\n",
    "\n",
    "ğŸ“Š íŒŒì‹± ê²°ê³¼: {json.dumps(parsed_json, ensure_ascii=False)}\n",
    "ğŸ” í•„í„°ë§ ê²°ê³¼: {json.dumps(filtered_json, ensure_ascii=False)}\n",
    "ğŸ¯ ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: {len(search_results.get('matches', []))}\n",
    "\n",
    "ğŸ’¬ ì¶”ì²œ ê²°ê³¼:\n",
    "{final_response_with_price}\"\"\"\n",
    "\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=summary)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"[LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "        print(f\"âŒ LLM_parser ì „ì²´ ì˜¤ë¥˜: {e}\")\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "    \n",
    "    \n",
    "def human_fallback_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"í–¥ìˆ˜ ê´€ë ¨ ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ê¸°ë³¸ ì‘ë‹µ\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "    \n",
    "    fallback_response = (\n",
    "        f\"â“ '{user_query}' ë” ëª…í™•í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\\n\"\n",
    "        f\"ğŸ‘‰ ì§ˆë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\\n\"\n",
    "        f\"ğŸ’¡ ë˜ëŠ” í–¥ìˆ˜ì— ê´€í•œ ë©‹ì§„ ì§ˆë¬¸ì„ í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?\"\n",
    "    )\n",
    "    \n",
    "    msgs = state[\"messages\"] + [AIMessage(content=fallback_response)]\n",
    "    return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "\n",
    "# ---------- 5) ì§ì ‘ ë„êµ¬ í˜¸ì¶œ ë°©ì‹ìœ¼ë¡œ ì—ì´ì „íŠ¸ êµ¬í˜„ ----------\n",
    "def price_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Price agent - ì§ì ‘ ë„êµ¬ í˜¸ì¶œ\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "    \n",
    "    try:\n",
    "        # ì§ì ‘ price_tool í˜¸ì¶œ\n",
    "        price_result = price_tool.invoke({\"user_query\": user_query})\n",
    "        \n",
    "        # ê²°ê³¼ë¥¼ ë” ìì—°ìŠ¤ëŸ½ê²Œ í¬ë§·íŒ…\n",
    "        final_answer = f\"ğŸ’° **ê°€ê²© ì •ë³´**\\n\\n{price_result}\"\n",
    "        \n",
    "        msgs = state[\"messages\"] + [AIMessage(content=final_answer)]\n",
    "        return {\n",
    "            \"messages\": msgs, \n",
    "            \"next\": None, \n",
    "            \"router_json\": state.get(\"router_json\")\n",
    "        }\n",
    "    except Exception as e:\n",
    "        error_msg = f\"âŒ ê°€ê²© ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "        return {\n",
    "            \"messages\": msgs, \n",
    "            \"next\": None, \n",
    "            \"router_json\": state.get(\"router_json\")\n",
    "        }\n",
    "\n",
    "def FAQ_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"FAQ agent - ì§ì ‘ ë„êµ¬ í˜¸ì¶œ\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "    \n",
    "    try:\n",
    "        # ì§ì ‘ faq_knowledge_tool í˜¸ì¶œ\n",
    "        faq_result = faq_knowledge_tool.invoke({\"question\": user_query})\n",
    "        \n",
    "        # ê²°ê³¼ë¥¼ ë” ìì—°ìŠ¤ëŸ½ê²Œ í¬ë§·íŒ…\n",
    "        final_answer = f\"ğŸ“š **í–¥ìˆ˜ ì§€ì‹**\\n\\n{faq_result}\"\n",
    "        \n",
    "        msgs = state[\"messages\"] + [AIMessage(content=final_answer)]\n",
    "        return {\n",
    "            \"messages\": msgs, \n",
    "            \"next\": None, \n",
    "            \"router_json\": state.get(\"router_json\")\n",
    "        }\n",
    "    except Exception as e:\n",
    "        error_msg = f\"âŒ ì§€ì‹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "        return {\n",
    "            \"messages\": msgs, \n",
    "            \"next\": None, \n",
    "            \"router_json\": state.get(\"router_json\")\n",
    "        }\n",
    "\n",
    "def ML_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ML agent - recommend_perfume_simple ë„êµ¬ ì‚¬ìš©\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "    \n",
    "    try:\n",
    "        # recommend_perfume_simple ë„êµ¬ í˜¸ì¶œ\n",
    "        ml_result = recommend_perfume_simple.invoke({\"user_text\": user_query})\n",
    "        \n",
    "        # ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í¬ë§·íŒ…\n",
    "        if isinstance(ml_result, dict) and \"recommendations\" in ml_result:\n",
    "            recommendations = ml_result[\"recommendations\"]\n",
    "            labels = ml_result.get(\"predicted_labels\", [])\n",
    "            \n",
    "            formatted_response = f\"ğŸ¯ **í–¥ìˆ˜ ì¶”ì²œ ê²°ê³¼**\\n\\n\"\n",
    "            formatted_response += f\"ğŸ“Š ì˜ˆì¸¡ëœ í–¥ íŠ¹ì„±: {', '.join(labels)}\\n\\n\"\n",
    "            \n",
    "            for rec in recommendations:\n",
    "                formatted_response += f\"ğŸ† **{rec['rank']}ìœ„** - {rec['brand']} {rec['name']}\\n\"\n",
    "                formatted_response += f\"   ğŸŒ¸ í–¥ë£Œ: {rec['fragrances']}\\n\"\n",
    "            \n",
    "        else:\n",
    "            formatted_response = f\"ğŸ¯ **í–¥ìˆ˜ ì¶”ì²œ**\\n\\n{str(ml_result)}\"\n",
    "        \n",
    "        msgs = state[\"messages\"] + [AIMessage(content=formatted_response)]\n",
    "        return {\n",
    "            \"messages\": msgs, \n",
    "            \"next\": None, \n",
    "            \"router_json\": state.get(\"router_json\")\n",
    "        }\n",
    "    except Exception as e:\n",
    "        error_msg = f\"âŒ ML ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "        return {\n",
    "            \"messages\": msgs, \n",
    "            \"next\": None, \n",
    "            \"router_json\": state.get(\"router_json\")\n",
    "        }\n",
    "# ---------- 7) Build Graph ----------\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"LLM_parser\", LLM_parser_node)\n",
    "graph.add_node(\"FAQ_agent\", FAQ_agent_node)\n",
    "graph.add_node(\"human_fallback\", human_fallback_node)\n",
    "graph.add_node(\"price_agent\", price_agent_node)\n",
    "graph.add_node(\"ML_agent\", ML_agent_node)\n",
    "\n",
    "# ì‹œì‘ì  ì„¤ì •\n",
    "graph.set_entry_point(\"supervisor\")\n",
    "\n",
    "# ì¡°ê±´ë¶€ ë¼ìš°íŒ… í•¨ìˆ˜\n",
    "def router_edge(state: AgentState) -> str:\n",
    "    return state[\"next\"] or \"human_fallback\"\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€ (supervisorì—ì„œ ê° agentë¡œ)\n",
    "graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    router_edge,\n",
    "    {\n",
    "        \"LLM_parser\": \"LLM_parser\",\n",
    "        \"FAQ_agent\": \"FAQ_agent\",\n",
    "        \"human_fallback\": \"human_fallback\",\n",
    "        \"price_agent\": \"price_agent\",\n",
    "        \"ML_agent\": \"ML_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# ê° ì—ì´ì „íŠ¸ì—ì„œ ENDë¡œ ê°€ëŠ” ì—£ì§€ ì¶”ê°€\n",
    "for node in [\"LLM_parser\", \"FAQ_agent\", \"human_fallback\", \"price_agent\", \"ML_agent\"]:\n",
    "    graph.add_edge(node, END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "app = graph.compile()\n",
    "\n",
    "# ---------- 8) Batch Test ----------\n",
    "TEST_QUERIES = [\n",
    "    \"ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.ê°€ê²©ë„ ì•Œë ¤ì¤˜\",                 \n",
    "    \"ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\",                \n",
    "    \"EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?\",                                       \n",
    "    \"íƒ‘ë…¸íŠ¸Â·ë¯¸ë“¤ë…¸íŠ¸Â·ë² ì´ìŠ¤ë…¸íŠ¸ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì´ì•¼?\",               \n",
    "    \"ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?\",                                         \n",
    "    \"ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?\",                                         \n",
    "    \"ìƒ¤ë„¬ ë„˜ë²„5 50ml ê°€ê²© ì•Œë ¤ì¤˜.\",                               \n",
    "    \"ë””ì˜¬ ì†Œë°”ì¥¬ ê°€ê²© ì–¼ë§ˆì•¼? ì–´ë””ì„œ ì‚¬ëŠ” ê²Œ ì œì¼ ì‹¸?\",             \n",
    "    \"ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\",                                 \n",
    "    \"ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.\",                                         \n",
    "]\n",
    "\n",
    "def run_tests():\n",
    "    for q in TEST_QUERIES:\n",
    "        print(\"=\"*80)\n",
    "        print(\"Query:\", q)\n",
    "        init: AgentState = {\n",
    "            \"messages\": [HumanMessage(content=q)],\n",
    "            \"next\": None,\n",
    "            \"router_json\": None\n",
    "        }\n",
    "        try:\n",
    "            out = app.invoke(init)\n",
    "            ai_msgs = [m for m in out[\"messages\"] if isinstance(m, AIMessage)]\n",
    "            router_raw = ai_msgs[-2].content if len(ai_msgs) >= 2 else \"(no router output)\"\n",
    "            agent_summary = ai_msgs[-1].content if ai_msgs else \"(no agent output)\"\n",
    "            print(\"Router JSON:\", router_raw)\n",
    "            print(\"Agent summary:\", agent_summary)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query: {e}\")\n",
    "\n",
    "def run_single_query(query: str):\n",
    "    \"\"\"ë‹¨ì¼ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(f\"ğŸ” Query: {query}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    init: AgentState = {\n",
    "        \"messages\": [HumanMessage(content=query)],\n",
    "        \"next\": None,\n",
    "        \"router_json\": None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        out = app.invoke(init)\n",
    "        ai_msgs = [m for m in out[\"messages\"] if isinstance(m, AIMessage)]\n",
    "        \n",
    "        if len(ai_msgs) >= 2:\n",
    "            print(\"ğŸ¤– Router Decision:\")\n",
    "            print(ai_msgs[-2].content)\n",
    "            print(\"\\nğŸ“ Final Response:\")\n",
    "            print(ai_msgs[-1].content)\n",
    "        elif len(ai_msgs) == 1:\n",
    "            print(\"ğŸ“ Response:\")\n",
    "            print(ai_msgs[-1].content)\n",
    "        else:\n",
    "            print(\"âŒ No response generated\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "    print(\"ğŸ”§ í™˜ê²½ ë³€ìˆ˜ í™•ì¸:\")\n",
    "    print(f\"OPENAI_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('OPENAI_API_KEY') else 'âŒ ë¯¸ì„¤ì •'}\")\n",
    "    print(f\"PINECONE_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('PINECONE_API_KEY') else 'âŒ ë¯¸ì„¤ì •'}\")\n",
    "    print(f\"NAVER_CLIENT_ID: {'âœ… ì„¤ì •ë¨' if os.getenv('NAVER_CLIENT_ID') else 'âŒ ë¯¸ì„¤ì •'}\")\n",
    "    print(f\"NAVER_CLIENT_SECRET: {'âœ… ì„¤ì •ë¨' if os.getenv('NAVER_CLIENT_SECRET') else 'âŒ ë¯¸ì„¤ì •'}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"ğŸš€ í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "    print()\n",
    "    \n",
    "    # ê°œë³„ í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜ ì œê³µ\n",
    "    print(\"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜:\")\n",
    "    print(\"- run_tests(): ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰\")\n",
    "    print(\"- run_single_query('your query'): ë‹¨ì¼ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸\")\n",
    "    print()\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì£¼ì„ ì²˜ë¦¬í•˜ì—¬ í•„ìš”ì‹œì—ë§Œ ì‹¤í–‰)\n",
    "    # run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8de61d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Query: ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.ê°€ê²©ë„ ì•Œë ¤ì¤˜\n",
      "ğŸ” LLM_parser ì‹¤í–‰: ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.ê°€ê²©ë„ ì•Œë ¤ì¤˜\n",
      "ğŸ’° ê°€ê²© ê²€ìƒ‰ í‚¤ì›Œë“œ: ì…ìƒë¡œë‘ í–¥ìˆ˜ 50ml\n",
      "ğŸ” ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´: {'brand': 'ì…ìƒë¡œë‘', 'concentration': 'ì˜¤ ë“œ í¼í“¸', 'day_night_score': 'day', 'gender': 'Female', 'id': 'perfume_abeb2f019e80abc3', 'name': 'ë¸”ë™ ì˜¤í”¼ì›€ ì˜¤ ë“œ í¼í“¸', 'no': 533.0, 'season_score': 'fall', 'sizes': ['30', '50', '90'], 'text': 'ì „ì„¤ì˜ í–¥ìˆ˜ì˜ í˜„ëŒ€ì  í„°ì¹˜'}\n",
      "Router JSON: {\n",
      "  \"next\": \"LLM_parser\",\n",
      "  \"reason\": \"The query contains multiple facets including brand, gender, size, season, and price intent.\",\n",
      "  \"facet_count\": 4,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"ì…ìƒë¡œë‘\",\n",
      "    \"season\": \"ê²¨ìš¸\",\n",
      "    \"gender\": \"ì—¬ì„±\",\n",
      "    \"sizes\": \"50ml\",\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"other\"\n",
      "}\n",
      "Agent summary: [LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ âœ…\n",
      "\n",
      "ğŸ“Š íŒŒì‹± ê²°ê³¼: {\"brand\": \"ì…ìƒë¡œë‘\", \"gender\": \"ì—¬ì„±\", \"sizes\": \"50\", \"season_score\": \"ê²¨ìš¸\", \"concentration\": null, \"day_night_score\": null}\n",
      "ğŸ” í•„í„°ë§ ê²°ê³¼: {\"brand\": \"ì…ìƒë¡œë‘\", \"concentration\": null, \"day_night_score\": null, \"gender\": null, \"season_score\": null, \"sizes\": \"50\"}\n",
      "ğŸ¯ ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: 5\n",
      "\n",
      "ğŸ’¬ ì¶”ì²œ ê²°ê³¼:\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ì…ìƒë¡œë‘ì˜ ê²¨ìš¸ìš© ì—¬ì„± í–¥ìˆ˜ë¥¼ ì°¾ê³  ê³„ì‹œêµ°ìš”. ì œê°€ ì¶”ì²œë“œë¦´ í–¥ìˆ˜ëŠ” **ì…ìƒë¡œë‘ ì˜¤ ë“œ ëšœì™ˆë ›** 50mlì…ë‹ˆë‹¤. \n",
      "\n",
      "### ì¶”ì²œ ì´ìœ \n",
      "ì´ í–¥ìˆ˜ëŠ” ê²¨ìš¸ì² ì— íŠ¹íˆ ì˜ ì–´ìš¸ë¦¬ëŠ” í–¥ìœ¼ë¡œ, ë”°ëœ»í•˜ê³  í¬ê·¼í•œ ëŠë‚Œì„ ì£¼ê¸° ë•Œë¬¸ì— ì°¨ê°€ìš´ ë‚ ì”¨ì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. \n",
      "\n",
      "### í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ\n",
      "ì…ìƒë¡œë‘ì˜ ì˜¤ ë“œ ëšœì™ˆë ›ì€ ìƒí¼í•˜ë©´ì„œë„ ë¶€ë“œëŸ¬ìš´ í”Œë¡œëŸ´ ë…¸íŠ¸ê°€ íŠ¹ì§•ì…ë‹ˆë‹¤. ì²˜ìŒì—ëŠ” ì‹ ì„ í•œ ê³¼ì¼ í–¥ì´ ëŠê»´ì§€ë‹¤ê°€, ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ë”°ëœ»í•œ ìš°ë”” ë…¸íŠ¸ì™€ ì„ì—¬ ê¹Šì´ ìˆëŠ” í–¥ì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤. ì´ ì¡°í™”ë¡œìš´ í–¥ì€ ê¸°ë¶„ì„ ì¢‹ê²Œ í•˜ê³ , ìì‹ ê°ì„ ì£¼ëŠ” ë§¤ë ¥ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ì í•©í•œ ìƒí™©\n",
      "ì´ í–¥ìˆ˜ëŠ” ë°ì¼ë¦¬ë¡œ ì‚¬ìš©í•˜ê¸°ì— ì í•©í•˜ë©°, íŠ¹íˆ ê²¨ìš¸ì² ì˜ ë‚® ì‹œê°„ì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. ì¹œêµ¬ë“¤ê³¼ì˜ ë§Œë‚¨ì´ë‚˜ ì§ì¥ì—ì„œë„ ë¶€ë‹´ ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ìš”. ë˜í•œ, íŠ¹ë³„í•œ ë‚ ì˜ ë°ì´íŠ¸ì—ë„ ì˜ ì–´ìš¸ë¦¬ëŠ” í–¥ì…ë‹ˆë‹¤.\n",
      "\n",
      "### ê°€ê²©ëŒ€ ë° ìš©ëŸ‰\n",
      "50ml ìš©ëŸ‰ì˜ ì˜¤ ë“œ ëšœì™ˆë ›ì€ ëŒ€ì²´ë¡œ 70,000ì›ì—ì„œ 100,000ì› ì‚¬ì´ì˜ ê°€ê²©ëŒ€ì—ì„œ êµ¬ë§¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ê²©ì€ íŒë§¤ì²˜ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ, ì—¬ëŸ¬ ê³³ì„ ë¹„êµí•´ë³´ì‹œëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ í–¥ìˆ˜ê°€ ë§ˆìŒì— ë“œì…¨ìœ¼ë©´ ì¢‹ê² ì–´ìš”! ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "---\n",
      "\n",
      "ğŸ’° **ê°€ê²© ì •ë³´**\n",
      "ğŸ” 'ì…ìƒë¡œë‘ í–¥ìˆ˜' ê²€ìƒ‰ ê²°ê³¼:\n",
      "\n",
      "ğŸ“¦ 1. ì…ìƒë¡œë‘ í–¥ìˆ˜ ëª½íŒŒë¦¬ ì˜¤ë“œ ë¹ ë¥´í­ EDP 90ml\n",
      "   ğŸ’° ê°€ê²©: 169,800ì›\n",
      "   ğŸª íŒë§¤ì²˜: ì˜¤ë“œí¼í“¸\n",
      "   ğŸ”— ë§í¬: https://smartstore.naver.com/main/products/11917463109\n",
      "\n",
      "ğŸ“¦ 2. ì…ìƒë¡œë‘ í–¥ìˆ˜ ë¦¬ë¸Œë¥´ ì˜¤ë“œë¹ ë¥´í­ EDP 90ml\n",
      "   ğŸ’° ê°€ê²©: 187,900ì›\n",
      "   ğŸª íŒë§¤ì²˜: ì˜¤ë“œí¼í“¸\n",
      "   ğŸ”— ë§í¬: https://smartstore.naver.com/main/products/6411183480\n",
      "\n",
      "ğŸ“¦ 3. ì…ìƒë¡œë‘ ë¦¬ë¸Œë¥´ ì˜¤ ë“œ ëšœì™ˆë › í”Œë¡œëŸ´í–¥, 30ml, 1ê°œ\n",
      "   ğŸ’° ê°€ê²©: 80,190ì›\n",
      "   ğŸª íŒë§¤ì²˜: ë„¤ì´ë²„\n",
      "   ğŸ”— ë§í¬: https://search.shopping.naver.com/catalog/52962468249\n",
      "\n",
      "ğŸ’¡ **ê°€ê²©ëŒ€ ì •ë³´**\n",
      "   ğŸ“Š ê²€ìƒ‰ëœ ê°€ê²© ë²”ìœ„: 80,190ì› ~ 187,900ì›\n",
      "   âš ï¸ ì •í™•í•œ ìµœì €ê°€/ìµœê³ ê°€ ì •ë³´ëŠ” ê° ì‡¼í•‘ëª°ì—ì„œ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
      "\n",
      "================================================================================\n",
      "Query: ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\n",
      "ğŸ” LLM_parser ì‹¤í–‰: ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\n",
      "Router JSON: {\n",
      "  \"next\": \"LLM_parser\",\n",
      "  \"reason\": \"The query contains multiple facets including brand, season, and day/night score.\",\n",
      "  \"facet_count\": 3,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"Dior\",\n",
      "    \"season\": \"fall\",\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": \"night\",\n",
      "    \"concentration\": \"EDP\"\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"scent_pref\"\n",
      "}\n",
      "Agent summary: [LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ âœ…\n",
      "\n",
      "ğŸ“Š íŒŒì‹± ê²°ê³¼: {\"brand\": \"ë””ì˜¬\", \"gender\": null, \"sizes\": null, \"season_score\": \"ê°€ì„\", \"concentration\": \"EDP\", \"day_night_score\": \"ì•¼ê°„\"}\n",
      "ğŸ” í•„í„°ë§ ê²°ê³¼: {\"brand\": \"ë””ì˜¬\", \"concentration\": null, \"day_night_score\": null, \"gender\": null, \"season_score\": null, \"sizes\": null}\n",
      "ğŸ¯ ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: 5\n",
      "\n",
      "ğŸ’¬ ì¶”ì²œ ê²°ê³¼:\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ê°€ì„ ë°¤ì— ì–´ìš¸ë¦¬ëŠ” ë””ì˜¬ í–¥ìˆ˜ë¥¼ ì°¾ê³  ê³„ì‹œêµ°ìš”. ë””ì˜¬ì€ ë‹¤ì–‘í•œ ë§¤ë ¥ì„ ê°€ì§„ í–¥ìˆ˜ë¡œ ìœ ëª…í•œ ë¸Œëœë“œì¸ë°ìš”, ê°€ì„ ë°¤ì— ì˜ ì–´ìš¸ë¦¬ëŠ” í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”.\n",
      "\n",
      "### ì¶”ì²œ í–¥ìˆ˜: ë””ì˜¬ \"ë¯¸ìŠ¤ ë””ì˜¬ ì˜¤ ë“œ í¼í“¸\" (Dior Miss Dior Eau de Parfum)\n",
      "\n",
      "1. **ì™œ ì´ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•˜ëŠ”ì§€**: ë¯¸ìŠ¤ ë””ì˜¬ì€ ì—¬ì„±ìŠ¤ëŸ¬ì›€ê³¼ ìš°ì•„í•¨ì„ ë™ì‹œì— ì§€ë‹Œ í–¥ìˆ˜ë¡œ, ê°€ì„ ë°¤ì˜ ë¡œë§¨í‹±í•œ ë¶„ìœ„ê¸°ì™€ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. ì´ í–¥ìˆ˜ëŠ” ê¹Šê³  í’ë¶€í•œ í–¥ì´ íŠ¹ì§•ìœ¼ë¡œ, ê°€ì„ì˜ ìŒ€ìŒ€í•œ ê³µê¸°ì™€ ì˜ ì–´ìš°ëŸ¬ì ¸ ë”°ëœ»í•œ ëŠë‚Œì„ ì¤ë‹ˆë‹¤.\n",
      "\n",
      "2. **í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ**: ë¯¸ìŠ¤ ë””ì˜¬ì€ í”Œë¡œëŸ´ê³¼ ìš°ë”” ë…¸íŠ¸ê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, íŠ¹íˆ ì¥ë¯¸ì™€ íŒŒì´ë¦¬ì˜ ì¡°í™”ê°€ ë§¤ë ¥ì ì…ë‹ˆë‹¤. ì²˜ìŒì—ëŠ” ìƒí¼í•œ ì‹œíŠ¸ëŸ¬ìŠ¤ í–¥ì´ ëŠê»´ì§€ë‹¤ê°€, ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë¶€ë“œëŸ¬ìš´ í”Œë¡œëŸ´ í–¥ê³¼ ë”°ëœ»í•œ ìš°ë”” í–¥ìœ¼ë¡œ ë³€í•´ê°‘ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì„¸ë ¨ë˜ë©´ì„œë„ ê°ì„±ì ì¸ ëŠë‚Œì„ ì¤ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì–´ë–¤ ìƒí™©ì— ì í•©í•œì§€**: ì´ í–¥ìˆ˜ëŠ” íŠ¹ë³„í•œ ì €ë… ì™¸ì¶œì´ë‚˜ ë°ì´íŠ¸, í˜¹ì€ ì¹œêµ¬ë“¤ê³¼ì˜ ëª¨ì„ ë“± ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ì‚¬ìš©í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤. ê°€ì„ ë°¤ì˜ ì°¨ê°€ìš´ ê³µê¸° ì†ì—ì„œ ë”°ëœ»í•œ ëŠë‚Œì„ ì£¼ë©°, ìì‹ ê°ì„ ë†’ì—¬ì¤„ ìˆ˜ ìˆëŠ” í–¥ìˆ˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "4. **ê°€ê²©ëŒ€ë‚˜ ìš©ëŸ‰ ê´€ë ¨ ì¡°ì–¸**: ë¯¸ìŠ¤ ë””ì˜¬ ì˜¤ ë“œ í¼í“¸ì€ ë³´í†µ 50ml ìš©ëŸ‰ìœ¼ë¡œ íŒë§¤ë˜ë©°, ê°€ê²©ëŒ€ëŠ” ì•½ 100,000ì›ì—ì„œ 150,000ì› ì‚¬ì´ì…ë‹ˆë‹¤. ê°€ì„ ì‹œì¦Œì— ë§ì¶° íŠ¹ë³„í•œ ë‚ ì„ ìœ„í•´ ì†Œì¤‘í•œ í–¥ìˆ˜ë¥¼ êµ¬ë§¤í•˜ì‹ ë‹¤ë©´, 100ml ìš©ëŸ‰ì„ ê³ ë ¤í•´ë³´ì‹œëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤. ë” ì˜¤ë«ë™ì•ˆ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë‹ˆê¹Œìš”!\n",
      "\n",
      "ê°€ì„ ë°¤ì— ì–´ìš¸ë¦¬ëŠ” ì´ í–¥ìˆ˜ë¡œ íŠ¹ë³„í•œ ìˆœê°„ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”.\n",
      "================================================================================\n",
      "Query: EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?\n",
      "Router JSON: {\n",
      "  \"next\": \"FAQ_agent\",\n",
      "  \"reason\": \"User is asking for definitions and differences.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"faq\"\n",
      "}\n",
      "Agent summary: ğŸ“š **í–¥ìˆ˜ ì§€ì‹**\n",
      "\n",
      "ğŸ’¡ EDP(Eau de Parfum)ëŠ” í–¥ë£Œ ë†ë„ 15-20%ë¡œ ì§€ì†ë ¥ì´ 6-8ì‹œê°„, EDT(Eau de Toilette)ëŠ” ë†ë„ 5-15%ë¡œ ì§€ì†ë ¥ì´ 2-4ì‹œê°„ì…ë‹ˆë‹¤.\n",
      "================================================================================\n",
      "Query: íƒ‘ë…¸íŠ¸Â·ë¯¸ë“¤ë…¸íŠ¸Â·ë² ì´ìŠ¤ë…¸íŠ¸ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì´ì•¼?\n",
      "Router JSON: {\n",
      "  \"next\": \"FAQ_agent\",\n",
      "  \"reason\": \"User is asking for definitions of perfume notes.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"faq\"\n",
      "}\n",
      "Agent summary: ğŸ“š **í–¥ìˆ˜ ì§€ì‹**\n",
      "\n",
      "ğŸ’¡ íƒ‘ë…¸íŠ¸ëŠ” ì²˜ìŒ 10-15ë¶„ê°„ ëŠë¼ëŠ” í–¥, ë¯¸ë“¤ë…¸íŠ¸ëŠ” 1-3ì‹œê°„ ì§€ì†ë˜ëŠ” ë©”ì¸ í–¥, ë² ì´ìŠ¤ë…¸íŠ¸ëŠ” 3ì‹œê°„ ì´í›„ ë‚¨ëŠ” ì”í–¥ì…ë‹ˆë‹¤.\n",
      "================================================================================\n",
      "Query: ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?\n",
      "Router JSON: {\n",
      "  \"next\": \"human_fallback\",\n",
      "  \"reason\": \"The query is off-topic and not related to perfume.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"non_perfume\"\n",
      "}\n",
      "Agent summary: â“ 'ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?' ë” ëª…í™•í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "ğŸ‘‰ ì§ˆë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n",
      "ğŸ’¡ ë˜ëŠ” í–¥ìˆ˜ì— ê´€í•œ ë©‹ì§„ ì§ˆë¬¸ì„ í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?\n",
      "================================================================================\n",
      "Query: ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?\n",
      "Router JSON: {\n",
      "  \"next\": \"human_fallback\",\n",
      "  \"reason\": \"The query is off-topic and not related to perfume.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"non_perfume\"\n",
      "}\n",
      "Agent summary: â“ 'ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?' ë” ëª…í™•í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "ğŸ‘‰ ì§ˆë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n",
      "ğŸ’¡ ë˜ëŠ” í–¥ìˆ˜ì— ê´€í•œ ë©‹ì§„ ì§ˆë¬¸ì„ í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?\n",
      "================================================================================\n",
      "Query: ìƒ¤ë„¬ ë„˜ë²„5 50ml ê°€ê²© ì•Œë ¤ì¤˜.\n",
      "Router JSON: {\n",
      "  \"next\": \"price_agent\",\n",
      "  \"reason\": \"Pure price query with specific brand and size.\",\n",
      "  \"facet_count\": 2,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"Chanel\",\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": \"50 ml\",\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"price\"\n",
      "}\n",
      "Agent summary: ğŸ’° **ê°€ê²© ì •ë³´**\n",
      "\n",
      "ğŸ” 'ìƒ¤ë„¬ ë„˜ë²„5' ê²€ìƒ‰ ê²°ê³¼:\n",
      "\n",
      "ğŸ“¦ 1. [êµ­ë‚´ë°±í™”ì /ì„ ë¬¼í¬ì¥] ìƒ¤ë„¬ ë„˜ë²„5 NO5 ì˜¤ë“œë¹ ë¥´í­ ì—¬ì„± í–¥ìˆ˜ 35ml\n",
      "   ğŸ’° ê°€ê²©: 141,000ì›\n",
      "   ğŸª íŒë§¤ì²˜: ë¼ì´í¬ì»´í¼ë‹ˆ\n",
      "   ğŸ”— ë§í¬: https://smartstore.naver.com/main/products/11549340601\n",
      "\n",
      "ğŸ“¦ 2. ìƒ¤ë„¬ ë„˜ë²„ 5 No.5 ì˜¤ ë“œ í¼í“¸ EDP 100ml\n",
      "   ğŸ’° ê°€ê²©: 210,000ì›\n",
      "   ğŸª íŒë§¤ì²˜: ì•„ë¦„ë‹¤ìš´ ë§ˆë…€\n",
      "   ğŸ”— ë§í¬: https://smartstore.naver.com/main/products/7686711609\n",
      "\n",
      "ğŸ“¦ 3. ìƒ¤ë„¬ ë„˜ë²„5 ì˜¤ë“œë¹ ë¥´í­ 1.5ml\n",
      "   ğŸ’° ê°€ê²©: 5,500ì›\n",
      "   ğŸª íŒë§¤ì²˜: ìŠ¤ì™„ì½”ìŠ¤ë©”í‹±\n",
      "   ğŸ”— ë§í¬: https://smartstore.naver.com/main/products/5992905332\n",
      "\n",
      "ğŸ’¡ **ê°€ê²©ëŒ€ ì •ë³´**\n",
      "   ğŸ“Š ê²€ìƒ‰ëœ ê°€ê²© ë²”ìœ„: 5,500ì› ~ 210,000ì›\n",
      "   âš ï¸ ì •í™•í•œ ìµœì €ê°€/ìµœê³ ê°€ ì •ë³´ëŠ” ê° ì‡¼í•‘ëª°ì—ì„œ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
      "\n",
      "================================================================================\n",
      "Query: ë””ì˜¬ ì†Œë°”ì¥¬ ê°€ê²© ì–¼ë§ˆì•¼? ì–´ë””ì„œ ì‚¬ëŠ” ê²Œ ì œì¼ ì‹¸?\n",
      "Router JSON: {\n",
      "  \"next\": \"price_agent\",\n",
      "  \"reason\": \"Pure price query with specific brand/product.\",\n",
      "  \"facet_count\": 1,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"Dior\",\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"price\"\n",
      "}\n",
      "Agent summary: ğŸ’° **ê°€ê²© ì •ë³´**\n",
      "\n",
      "ğŸ” 'ë””ì˜¬ ì†Œë°”ì¥¬' ê²€ìƒ‰ ê²°ê³¼:\n",
      "\n",
      "ğŸ“¦ 1. (êµ­ë‚´ë°±í™”ì ) ë””ì˜¬ ì†Œë°”ì¥¬ ì˜¤ë“œí¼í“¸ ë‚¨ì„±í–¥ìˆ˜ 60ml\n",
      "   ğŸ’° ê°€ê²©: 134,900ì›\n",
      "   ğŸª íŒë§¤ì²˜: ëŸ­ìŠ¤ë¦¬ë°‹\n",
      "   ğŸ”— ë§í¬: https://smartstore.naver.com/main/products/11512674629\n",
      "\n",
      "ğŸ“¦ 2. ë””ì˜¬ ì†Œë°”ì¥¬ ì˜¤ë“œëšœì™ˆë › 10ml\n",
      "   ğŸ’° ê°€ê²©: 18,900ì›\n",
      "   ğŸª íŒë§¤ì²˜: ìŠ¤ì™„ì½”ìŠ¤ë©”í‹±\n",
      "   ğŸ”— ë§í¬: https://smartstore.naver.com/main/products/5747664407\n",
      "\n",
      "ğŸ“¦ 3. ë””ì˜¬ë·°í‹° ì†Œë°”ì¥¬ ì˜¤ ë“œ í¼í“¸ ë² ë¥´ê°€ëª»í–¥, 60ml, 1ê°œ\n",
      "   ğŸ’° ê°€ê²©: 125,000ì›\n",
      "   ğŸª íŒë§¤ì²˜: ë„¤ì´ë²„\n",
      "   ğŸ”— ë§í¬: https://search.shopping.naver.com/catalog/53527870653\n",
      "\n",
      "ğŸ’¡ **ê°€ê²©ëŒ€ ì •ë³´**\n",
      "   ğŸ“Š ê²€ìƒ‰ëœ ê°€ê²© ë²”ìœ„: 18,900ì› ~ 134,900ì›\n",
      "   âš ï¸ ì •í™•í•œ ìµœì €ê°€/ìµœê³ ê°€ ì •ë³´ëŠ” ê° ì‡¼í•‘ëª°ì—ì„œ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
      "\n",
      "================================================================================\n",
      "Query: ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [12:03:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\gbm\\gbtree.cc:359: \n",
      "  Loading from a raw memory buffer (like pickle in Python, RDS in R) on a CPU-only\n",
      "  machine. Consider using `save_model/load_model` instead. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.  Changing `tree_method` to `hist`.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [12:03:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\gbm\\gbtree.cc:384: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [12:03:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [12:03:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  setstate(state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router JSON: {\n",
      "  \"next\": \"ML_agent\",\n",
      "  \"reason\": \"User is asking for a single preference recommendation for summer.\",\n",
      "  \"facet_count\": 1,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": \"summer\",\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": \"cool\",\n",
      "  \"query_intent\": \"scent_pref\"\n",
      "}\n",
      "Agent summary: ğŸ¯ **í–¥ìˆ˜ ì¶”ì²œ ê²°ê³¼**\n",
      "\n",
      "ğŸ“Š ì˜ˆì¸¡ëœ í–¥ íŠ¹ì„±: Amber, Fresher, Gourmand\n",
      "\n",
      "ğŸ† **1ìœ„** - Charlie Charlie Original / Charlie Blue\n",
      "   ğŸŒ¸ í–¥ë£Œ: Floral Crisp Green\n",
      "ğŸ† **2ìœ„** - Bulgari Omnia Crystalline L'Eau De Parfum\n",
      "   ğŸŒ¸ í–¥ë£Œ: Soft Floral Fresher Citrus\n",
      "ğŸ† **3ìœ„** - Tom Tailor Urban Life Man\n",
      "   ğŸŒ¸ í–¥ë£Œ: Aromatic FougÃ¨re Crisp Fruity\n",
      "ğŸ† **4ìœ„** - James Bond 007 007 For Women Ii\n",
      "   ğŸŒ¸ í–¥ë£Œ: Floral Amber Fresher Fruity\n",
      "ğŸ† **5ìœ„** - Jeanne Arthes Perpetual Silver Pearl\n",
      "   ğŸŒ¸ í–¥ë£Œ: Floral Amber Crisp Citrus Fruity\n",
      "\n",
      "================================================================================\n",
      "Query: ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [12:03:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\gbm\\gbtree.cc:359: \n",
      "  Loading from a raw memory buffer (like pickle in Python, RDS in R) on a CPU-only\n",
      "  machine. Consider using `save_model/load_model` instead. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.  Changing `tree_method` to `hist`.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [12:03:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\gbm\\gbtree.cc:384: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [12:03:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [12:03:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  setstate(state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router JSON: {\n",
      "  \"next\": \"ML_agent\",\n",
      "  \"reason\": \"User is asking for a sweet scent recommendation.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": \"sweet\",\n",
      "  \"query_intent\": \"scent_pref\"\n",
      "}\n",
      "Agent summary: ğŸ¯ **í–¥ìˆ˜ ì¶”ì²œ ê²°ê³¼**\n",
      "\n",
      "ğŸ“Š ì˜ˆì¸¡ëœ í–¥ íŠ¹ì„±: Amber, Fresher, Gourmand\n",
      "\n",
      "ğŸ† **1ìœ„** - Charlie Charlie Original / Charlie Blue\n",
      "   ğŸŒ¸ í–¥ë£Œ: Floral Crisp Green\n",
      "ğŸ† **2ìœ„** - Bulgari Omnia Crystalline L'Eau De Parfum\n",
      "   ğŸŒ¸ í–¥ë£Œ: Soft Floral Fresher Citrus\n",
      "ğŸ† **3ìœ„** - Tom Tailor Urban Life Man\n",
      "   ğŸŒ¸ í–¥ë£Œ: Aromatic FougÃ¨re Crisp Fruity\n",
      "ğŸ† **4ìœ„** - James Bond 007 007 For Women Ii\n",
      "   ğŸŒ¸ í–¥ë£Œ: Floral Amber Fresher Fruity\n",
      "ğŸ† **5ìœ„** - Jeanne Arthes Perpetual Silver Pearl\n",
      "   ğŸŒ¸ í–¥ë£Œ: Floral Amber Crisp Citrus Fruity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
