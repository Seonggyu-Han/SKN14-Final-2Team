# function.py
import requests
import re
import os
from dotenv import load_dotenv
from langchain.tools import tool
from langgraph.graph import StateGraph, END
from openai import OpenAI
from langgraph import State, StateNode, StateEdge

# === .env ë¶ˆëŸ¬ì˜¤ê¸° ===
load_dotenv()
naver_client_id = os.getenv("NAVER_CLIENT_ID")
naver_client_secret = os.getenv("NAVER_CLIENT_SECRET")

@tool
def price_tool(user_query: str) -> str:
    """A tool that uses the Naver Shopping API to look up perfume prices (results are returned as formatted strings)"""
    
    url = "https://openapi.naver.com/v1/search/shop.json"
    headers = {
        "X-Naver-Client-Id": naver_client_id,
        "X-Naver-Client-Secret": naver_client_secret
    }
    params = {"query": user_query, "display": 5, "sort": "sim"}
    
    try:
        response = requests.get(url, headers=headers, params=params)
    except Exception as e:
        return f"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}"
    
    if response.status_code != 200:
        return f"âŒ API ì˜¤ë¥˜: {response.status_code}"
    
    data = response.json()
    if not data or "items" not in data or len(data["items"]) == 0:
        return f"ğŸ˜” '{user_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    # HTML íƒœê·¸ ì œê±° í•¨ìˆ˜
    def remove_html_tags(text: str) -> str:
        return re.sub(r"<[^>]+>", "", text)
    
    # ìƒìœ„ 3ê°œë§Œ ì •ë¦¬
    products = data["items"][:3]
    output = f"ğŸ” '{user_query}' ê²€ìƒ‰ ê²°ê³¼:\n\n"
    for i, item in enumerate(products, 1):
        title = remove_html_tags(item.get("title", ""))
        lprice = item.get("lprice", "0")
        mall = item.get("mallName", "ì •ë³´ ì—†ìŒ")
        link = item.get("link", "ì •ë³´ ì—†ìŒ")
        
        output += f"ğŸ“¦ {i}. {title}\n"
        if lprice != "0":
            output += f"   ğŸ’° ê°€ê²©: {int(lprice):,}ì›\n"
        output += f"   ğŸª íŒë§¤ì²˜: {mall}\n"
        output += f"   ğŸ”— ë§í¬: {link}\n\n"
    
    return output

def human_fallback(state: dict) -> str:
    """í–¥ìˆ˜ ê´€ë ¨ ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ê¸°ë³¸ ì‘ë‹µ"""
    query = state.get("input", "")
    return (
        f"â“ '{query}' ë” ëª…í™•í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n"
        f"ğŸ‘‰ ì§ˆë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
        f"ğŸ’¡ ë˜ëŠ” í–¥ìˆ˜ì— ê´€í•œ ë©‹ì§„ ì§ˆë¬¸ì„ í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"
    )

# -------------------------------
# LLM íŒŒì„œ í•¨ìˆ˜
# -------------------------------
def query_parser_node(state: AgentState) -> AgentState:
    user_query = state["messages"][-1] if state.get("messages") else ""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "user",
            "content": f"""
            ë„ˆëŠ” í–¥ìˆ˜ ì¿¼ë¦¬ íŒŒì„œì•¼.
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ brand, concentration, day_night_score, gender,
            name, season_score, sizes ê°™ì€ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë½‘ì•„ì¤˜.
            ì—†ëŠ” ê°’ì€ nullë¡œ ë‘ê³ , ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•´.

            ì§ˆë¬¸: {user_query}
            """
        }],
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "PerfumeQuery",
                "schema": {
                    "type": "object",
                    "properties": {
                        "brand": {"type": ["string", "null"]},
                        "concentration": {"type": ["string", "null"]},
                        "day_night_score": {"type": ["string", "null"]},
                        "gender": {"type": ["string", "null"]},
                        "season_score": {"type": ["string", "null"]},
                        "sizes": {"type": ["string", "null"]}
                    }
                }
            }
        }
    )

    parsed = response.choices[0].message.parsed
    state["parsed"] = parsed
    return state

import json
import joblib
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModel
from rank_bm25 import BM25Okapi
from typing import List, Dict, Tuple, Optional


class PerfumeRecommender:
    """í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 model_pkl_path: str = "./models.pkl", 
                 perfume_json_path: str = "perfumes.json",
                 model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                 max_len: int = 256):
        
        self.model_name = model_name
        self.max_len = max_len
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"[Device] {self.device}")
        
        # ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ
        self._load_ml_model(model_pkl_path)
        self._load_transformer_model()
        self._load_perfume_data(perfume_json_path)
        self._build_bm25_index()
    
    def _load_ml_model(self, pkl_path: str):
        """ì €ì¥ëœ ML ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
        data = joblib.load(pkl_path)
        self.clf = data["classifier"]
        self.mlb = data["mlb"]
        self.thresholds = data["thresholds"]
        
        print(f"[Loaded model from {pkl_path}]")
        print(f"Labels: {list(self.mlb.classes_)}")
    
    def _load_transformer_model(self):
        """Transformer ëª¨ë¸ ë¡œë“œ"""
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.base_model = AutoModel.from_pretrained(self.model_name).to(self.device)
        self.base_model.eval()
    
    def _load_perfume_data(self, json_path: str):
        """í–¥ìˆ˜ ë°ì´í„° ë¡œë“œ"""
        with open(json_path, "r", encoding="utf-8") as f:
            self.perfumes = json.load(f)
        print(f"[Loaded {len(self.perfumes)} perfumes from {json_path}]")
    
    def _build_bm25_index(self):
        """BM25 ì¸ë±ìŠ¤ êµ¬ì¶•"""
        self.corpus = [item.get("fragrances", "") for item in self.perfumes]
        tokenized_corpus = [doc.lower().split() for doc in self.corpus]
        self.bm25 = BM25Okapi(tokenized_corpus)
        print("[BM25 index built]")
    
    def encode_texts(self, texts: List[str], batch_size: int = 32) -> np.ndarray:
        """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        all_embeddings = []
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]
            enc = self.tokenizer(
                batch, 
                padding=True, 
                truncation=True, 
                max_length=self.max_len, 
                return_tensors="pt"
            ).to(self.device)
            
            with torch.no_grad():
                model_out = self.base_model(**enc)
                emb = model_out.last_hidden_state.mean(dim=1)
            
            all_embeddings.append(emb.cpu().numpy())
        
        return np.vstack(all_embeddings)
    
    def predict_labels(self, text: str, topk: int = 3, use_thresholds: bool = True) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í–¥ìˆ˜ ë¼ë²¨ ì˜ˆì¸¡"""
        emb = self.encode_texts([text], batch_size=1)
        proba = self.clf.predict_proba(emb)[0]
        
        if use_thresholds and self.thresholds:
            # threshold ê¸°ë°˜ ì„ íƒ
            pick = [
                i for i, p in enumerate(proba) 
                if p >= self.thresholds.get(self.mlb.classes_[i], 0.5)
            ]
            # thresholdë¥¼ ë„˜ëŠ” ê²ƒì´ ì—†ìœ¼ë©´ topk ì„ íƒ
            if not pick:
                pick = np.argsort(-proba)[:topk]
        else:
            # ìƒìœ„ topk ì„ íƒ
            pick = np.argsort(-proba)[:topk]
        
        return [self.mlb.classes_[i] for i in pick]
    
    def search_perfumes(self, labels: List[str], top_n: int = 5) -> List[Tuple[int, float, Dict]]:
        """BM25ë¥¼ ì‚¬ìš©í•´ í–¥ìˆ˜ ê²€ìƒ‰"""
        query = " ".join(labels)
        tokenized_query = query.lower().split()
        scores = self.bm25.get_scores(tokenized_query)
        
        # ìƒìœ„ Nê°œ ì¸ë±ìŠ¤ ì„ íƒ
        top_idx = np.argsort(scores)[-top_n:][::-1]
        
        results = []
        for idx in top_idx:
            results.append((idx, scores[idx], self.perfumes[idx]))
        
        return results
    
    def recommend(self, 
                  user_text: str, 
                  topk_labels: int = 4, 
                  top_n_perfumes: int = 5,
                  use_thresholds: bool = True,
                  verbose: bool = True) -> Dict:
        """ì „ì²´ ì¶”ì²œ íŒŒì´í”„ë¼ì¸"""
        
        # 1. ML ëª¨ë¸ë¡œ ë¼ë²¨ ì˜ˆì¸¡
        predicted_labels = self.predict_labels(
            user_text, 
            topk=topk_labels, 
            use_thresholds=use_thresholds
        )
        
        # 2. BM25ë¡œ í–¥ìˆ˜ ê²€ìƒ‰
        search_results = self.search_perfumes(predicted_labels, top_n=top_n_perfumes)
        
        if verbose:
            print("=== ML ì˜ˆì¸¡ ë¼ë²¨ ===")
            print(predicted_labels)
            print(f"\n=== BM25 Top-{top_n_perfumes} ê²°ê³¼ ===")
            
            for rank, (idx, score, perfume) in enumerate(search_results, 1):
                print(f"[Rank {rank}] Score: {score:.2f}")
                print(f"  Brand      : {perfume.get('brand', 'N/A')}")
                print(f"  Name       : {perfume.get('name_perfume', 'N/A')}")
                print(f"  Fragrances : {perfume.get('fragrances', 'N/A')}")
                print()
        
        return {
            "user_input": user_text,
            "predicted_labels": predicted_labels,
            "recommendations": [
                {
                    "rank": rank,
                    "score": score,
                    "brand": perfume.get('brand', 'N/A'),
                    "name": perfume.get('name_perfume', 'N/A'),
                    "fragrances": perfume.get('fragrances', 'N/A'),
                    "perfume_data": perfume
                }
                for rank, (idx, score, perfume) in enumerate(search_results, 1)
            ]
        }


# ì‚¬ìš© ì˜ˆì‹œ
def main():
    # ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    recommender = PerfumeRecommender()
    
    # ì‚¬ìš©ì ì…ë ¥ ì˜ˆì‹œë“¤
    test_inputs = [
        "ì‹œíŠ¸ëŸ¬ìŠ¤í•˜ê³  í”„ë£¨í‹°í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜",
        "ë¡œë§¨í‹±í•˜ê³  í”Œë¡œë„í•œ í–¥ ì›í•´",
        "ìš°ë””í•˜ê³  ìŠ¤íŒŒì´ì‹œí•œ í–¥ìˆ˜",
        "ê¹”ë”í•˜ê³  ìƒì¾Œí•œ í–¥"
    ]
    
    for user_input in test_inputs:
        print(f"\n{'='*50}")
        print(f"ì‚¬ìš©ì ì…ë ¥: {user_input}")
        print(f"{'='*50}")
        
        # ì¶”ì²œ ì‹¤í–‰
        result = recommender.recommend(
            user_text=user_input,
            topk_labels=4,
            top_n_perfumes=3,
            verbose=True
        )


if __name__ == "__main__":
    main()
    parsed = response.choices[0].message.parsed

    # stateì— íŒŒì‹± ê²°ê³¼ ì €ì¥
    state["parsed"] = parsed
    return state