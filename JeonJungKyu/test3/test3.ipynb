{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dbabe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Query: ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\n",
      "Router: LLM_parser\n",
      "Response: ğŸ” **ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼**\n",
      "\n",
      "â€¢ ë¸Œëœë“œ: ì…ìƒë¡œë‘\n",
      "â€¢ ì„±ë³„: ì—¬ì„±\n",
      "â€¢ ìš©ëŸ‰: 50ml\n",
      "â€¢ ê³„ì ˆ: ê²¨ìš¸\n",
      "\n",
      "ğŸ“ ë¶„ì„ëœ ì¡°ê±´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ í•„í„°ë§í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "================================================================================\n",
      "Query: ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\n",
      "Router: LLM_parser\n",
      "Response: ğŸ” **ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼**\n",
      "\n",
      "â€¢ ë¸Œëœë“œ: ë””ì˜¬\n",
      "â€¢ ê³„ì ˆ: ê°€ì„\n",
      "â€¢ ë†ë„: EDP\n",
      "â€¢ ì‚¬ìš©ì‹œê°„: ì•¼ê°„\n",
      "\n",
      "ğŸ“ ë¶„ì„ëœ ì¡°ê±´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ í•„í„°ë§í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "================================================================================\n",
      "Query: EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?\n",
      "Router: FAQ_agent\n",
      "Response: ğŸŒŸ **EDP vs EDT ì°¨ì´ì **\n",
      "\n",
      "EDP (Eau de Parfum): í–¥ë£Œ ë†ë„ 15-20%, ì§€ì†ì‹œê°„ 6-8ì‹œê°„\n",
      "EDT (Eau de Toilette): í–¥ë£Œ ë†ë„ 5-15%, ì§€ì†ì‹œê°„ 3-5ì‹œê°„\n",
      "\n",
      "EDPê°€ ë” ì§„í•˜ê³  ì˜¤ë˜ê°€ì§€ë§Œ, EDTê°€ ë” ê°€ë³ê³  ìƒì¾Œí•´ìš”!\n",
      "\n",
      "================================================================================\n",
      "Query: íƒ‘ë…¸íŠ¸Â·ë¯¸ë“¤ë…¸íŠ¸Â·ë² ì´ìŠ¤ë…¸íŠ¸ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì´ì•¼?\n",
      "Router: FAQ_agent\n",
      "Response: ğŸµ **í–¥ìˆ˜ ë…¸íŠ¸ êµ¬ì„±**\n",
      "\n",
      "â€¢ **íƒ‘ë…¸íŠ¸**: ì²« ì¸ìƒ (5-15ë¶„)\n",
      "â€¢ **ë¯¸ë“¤ë…¸íŠ¸**: ë©”ì¸ í–¥ (30ë¶„-2ì‹œê°„)\n",
      "â€¢ **ë² ì´ìŠ¤ë…¸íŠ¸**: ë§ˆë¬´ë¦¬ í–¥ (2ì‹œê°„ ì´ìƒ)\n",
      "\n",
      "ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ í–¥ì´ ë³€í™”í•˜ëŠ” ê²ƒì´ í–¥ìˆ˜ì˜ ë§¤ë ¥ì´ì—ìš”!\n",
      "\n",
      "================================================================================\n",
      "Query: ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?\n",
      "Router: human_fallback\n",
      "Response: â“ í–¥ìˆ˜ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”!\n",
      "\n",
      "ğŸ’¡ ì˜ˆì‹œ:\n",
      "â€¢ í–¥ìˆ˜ ì¶”ì²œ\n",
      "â€¢ í–¥ìˆ˜ ê°€ê²© ë¬¸ì˜\n",
      "â€¢ í–¥ìˆ˜ ì§€ì‹ ë¬¸ë‹µ\n",
      "\n",
      "================================================================================\n",
      "Query: ìƒ¤ë„¬ ë„˜ë²„5 50ml ìµœì €ê°€ ì•Œë ¤ì¤˜.\n",
      "Router: price_agent\n",
      "Response: ğŸ” 'ìƒ¤ë„¬ ë„˜ë²„5 50ml ìµœì €ê°€ ì•Œë ¤ì¤˜.' ê²€ìƒ‰ ê²°ê³¼:\n",
      "\n",
      "ğŸ“¦ 1. CHANEL No.5 ì˜¤ ë“œ í¼í“¸ í”Œë¡œëŸ´í–¥, 50ml, 1ê°œ\n",
      "   ğŸ’° ê°€ê²©: 130,000ì›\n",
      "   ğŸª íŒë§¤ì²˜: ë„¤ì´ë²„\n",
      "   ğŸ”— ë§í¬: https://search.shopping.naver.com/catalog/53015716331\n",
      "\n",
      "ğŸ“¦ 2. [êµ­ë‚´ë°±í™”ì /ì„ ë¬¼í¬ì¥] ìƒ¤ë„¬ ë„˜ë²„5 NO5 LEAU ë¡œ ì˜¤ ë“œ ëšœì™ˆë › ì—¬ì„± í–¥ìˆ˜ 50ml\n",
      "   ğŸ’° ê°€ê²©: 206,000ì›\n",
      "   ğŸª íŒë§¤ì²˜: ë¼ì´í¬ì»´í¼ë‹ˆ\n",
      "   ğŸ”— ë§í¬: https://smartstore.naver.com/main/products/11549357996\n",
      "\n",
      "ğŸ“¦ 3. CHANEL No.5 ìš°ë¨¼ ì˜¤ ë“œ ëšœì™ˆë ›\n",
      "   ğŸ’° ê°€ê²©: 165,990ì›\n",
      "   ğŸª íŒë§¤ì²˜: ë„¤ì´ë²„\n",
      "   ğŸ”— ë§í¬: https://search.shopping.naver.com/catalog/2600028834\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query: ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\n",
      "[Device] cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [14:33:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\gbm\\gbtree.cc:359: \n",
      "  Loading from a raw memory buffer (like pickle in Python, RDS in R) on a CPU-only\n",
      "  machine. Consider using `save_model/load_model` instead. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.  Changing `tree_method` to `hist`.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [14:33:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\gbm\\gbtree.cc:384: Changing updater from `grow_gpu_hist` to `grow_quantile_histmaker`.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [14:33:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  setstate(state)\n",
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\pickle.py:1760: UserWarning: [14:33:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  setstate(state)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaded model from ./models.pkl]\n",
      "Labels: ['Amber', 'Aromatic', 'Blossom', 'Bouquet', 'Citrus', 'Classical', 'Crisp', 'Dry', 'Floral', 'Flower', 'FougÃ¨re', 'Fresh', 'Fresher', 'Fruity', 'Gourmand', 'Green', 'Iris', 'Jasmine', 'Lily', 'Mossy', 'Musk', 'Orange', 'Rich', 'Richer', 'Rose', 'Soft', 'Spicy', 'Tuberose', 'Valley', 'Violet', 'Water', 'White', 'Woods', 'Woody']\n",
      "[Loaded 26319 perfumes from perfumes.json]\n",
      "[BM25 index built]\n",
      "Router: ML_agent\n",
      "Response: ğŸ¯ **'ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.' ì¶”ì²œ ê²°ê³¼**\n",
      "\n",
      "ğŸ·ï¸ **ì˜ˆì¸¡ëœ í–¥ íŠ¹ì„±**: Amber, Fresher, Gourmand\n",
      "\n",
      "ğŸŒŸ **1ìœ„** (ì ìˆ˜: 4.86)\n",
      "   ë¸Œëœë“œ: Beachwaver\n",
      "   ì œí’ˆëª…: Polynesian Pink Sugar\n",
      "   í–¥ íŠ¹ì„±: Amber Fresher Gourmand\n",
      "\n",
      "ğŸŒŸ **2ìœ„** (ì ìˆ˜: 4.86)\n",
      "   ë¸Œëœë“œ: O BoticÃ¡rio\n",
      "   ì œí’ˆëª…: Dream CÃ©u De Baunilha\n",
      "   í–¥ íŠ¹ì„±: Amber Fresher Gourmand\n",
      "\n",
      "ğŸŒŸ **3ìœ„** (ì ìˆ˜: 4.86)\n",
      "   ë¸Œëœë“œ: Lalique\n",
      "   ì œí’ˆëª…: Fruits Du Mouvement 1977\n",
      "   í–¥ íŠ¹ì„±: Amber Fresher Gourmand\n",
      "\n",
      "ğŸŒŸ **4ìœ„** (ì ìˆ˜: 4.86)\n",
      "   ë¸Œëœë“œ: Simone Andreoli\n",
      "   ì œí’ˆëª…: Silenzio\n",
      "   í–¥ íŠ¹ì„±: Amber Fresher Gourmand\n",
      "\n",
      "ğŸŒŸ **5ìœ„** (ì ìˆ˜: 4.86)\n",
      "   ë¸Œëœë“œ: Le Monde Gourmand\n",
      "   ì œí’ˆëª…: Rum Tropique 2023\n",
      "   í–¥ íŠ¹ì„±: Amber Fresher Gourmand\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query: ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.\n",
      "Router: ML_agent\n",
      "Response: ğŸ¯ **'ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.' ì¶”ì²œ ê²°ê³¼**\n",
      "\n",
      "ğŸ·ï¸ **ì˜ˆì¸¡ëœ í–¥ íŠ¹ì„±**: Amber, Fresher, Gourmand\n",
      "\n",
      "ğŸŒŸ **1ìœ„** (ì ìˆ˜: 4.86)\n",
      "   ë¸Œëœë“œ: Beachwaver\n",
      "   ì œí’ˆëª…: Polynesian Pink Sugar\n",
      "   í–¥ íŠ¹ì„±: Amber Fresher Gourmand\n",
      "\n",
      "ğŸŒŸ **2ìœ„** (ì ìˆ˜: 4.86)\n",
      "   ë¸Œëœë“œ: O BoticÃ¡rio\n",
      "   ì œí’ˆëª…: Dream CÃ©u De Baunilha\n",
      "   í–¥ íŠ¹ì„±: Amber Fresher Gourmand\n",
      "\n",
      "ğŸŒŸ **3ìœ„** (ì ìˆ˜: 4.86)\n",
      "   ë¸Œëœë“œ: Lalique\n",
      "   ì œí’ˆëª…: Fruits Du Mouvement 1977\n",
      "   í–¥ íŠ¹ì„±: Amber Fresher Gourmand\n",
      "\n",
      "ğŸŒŸ **4ìœ„** (ì ìˆ˜: 4.86)\n",
      "   ë¸Œëœë“œ: Simone Andreoli\n",
      "   ì œí’ˆëª…: Silenzio\n",
      "   í–¥ íŠ¹ì„±: Amber Fresher Gourmand\n",
      "\n",
      "ğŸŒŸ **5ìœ„** (ì ìˆ˜: 4.86)\n",
      "   ë¸Œëœë“œ: Le Monde Gourmand\n",
      "   ì œí’ˆëª…: Rum Tropique 2023\n",
      "   í–¥ íŠ¹ì„±: Amber Fresher Gourmand\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain langgraph langchain-openai tiktoken transformers torch rank-bm25 joblib scikit-learn\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import TypedDict, List, Optional, Dict, Any, Tuple\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "# ---------- 0) Config ----------\n",
    "load_dotenv()\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "naver_client_id = os.getenv(\"NAVER_CLIENT_ID\")\n",
    "naver_client_secret = os.getenv(\"NAVER_CLIENT_SECRET\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# ---------- 1) State ----------\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    next: Optional[str]\n",
    "    router_json: Optional[Dict[str, Any]]\n",
    "    parsed: Optional[Dict[str, Any]]  # LLM_parser ê²°ê³¼\n",
    "    recommendations: Optional[List[Dict]]  # ML_agent ê²°ê³¼\n",
    "    price_info: Optional[str]  # price_agent ê²°ê³¼\n",
    "\n",
    "# ---------- 2) PerfumeRecommender Class ----------\n",
    "class PerfumeRecommender:\n",
    "    \"\"\"í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_pkl_path: str = \"./models.pkl\", \n",
    "                 perfume_json_path: str = \"perfumes.json\",\n",
    "                 model_name: str = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "                 max_len: int = 256):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.max_len = max_len\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"[Device] {self.device}\")\n",
    "        \n",
    "        # ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ\n",
    "        self._load_ml_model(model_pkl_path)\n",
    "        self._load_transformer_model()\n",
    "        self._load_perfume_data(perfume_json_path)\n",
    "        self._build_bm25_index()\n",
    "    \n",
    "    def _load_ml_model(self, pkl_path: str):\n",
    "        \"\"\"ì €ì¥ëœ ML ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\"\"\"\n",
    "        try:\n",
    "            data = joblib.load(pkl_path)\n",
    "            self.clf = data[\"classifier\"]\n",
    "            self.mlb = data[\"mlb\"]\n",
    "            self.thresholds = data[\"thresholds\"]\n",
    "            print(f\"[Loaded model from {pkl_path}]\")\n",
    "            print(f\"Labels: {list(self.mlb.classes_)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Could not load ML model: {e}\")\n",
    "            self.clf = None\n",
    "            self.mlb = None\n",
    "            self.thresholds = None\n",
    "    \n",
    "    def _load_transformer_model(self):\n",
    "        \"\"\"Transformer ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "            self.base_model = AutoModel.from_pretrained(self.model_name).to(self.device)\n",
    "            self.base_model.eval()\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Could not load transformer model: {e}\")\n",
    "            self.tokenizer = None\n",
    "            self.base_model = None\n",
    "    \n",
    "    def _load_perfume_data(self, json_path: str):\n",
    "        \"\"\"í–¥ìˆ˜ ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "        try:\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                self.perfumes = json.load(f)\n",
    "            print(f\"[Loaded {len(self.perfumes)} perfumes from {json_path}]\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Could not load perfume data: {e}\")\n",
    "            self.perfumes = []\n",
    "    \n",
    "    def _build_bm25_index(self):\n",
    "        \"\"\"BM25 ì¸ë±ìŠ¤ êµ¬ì¶•\"\"\"\n",
    "        if not self.perfumes:\n",
    "            self.bm25 = None\n",
    "            return\n",
    "        \n",
    "        self.corpus = [item.get(\"fragrances\", \"\") for item in self.perfumes]\n",
    "        tokenized_corpus = [doc.lower().split() for doc in self.corpus]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        print(\"[BM25 index built]\")\n",
    "    \n",
    "    def encode_texts(self, texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
    "        \"\"\"í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "        if not self.tokenizer or not self.base_model:\n",
    "            return np.array([])\n",
    "            \n",
    "        all_embeddings = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            enc = self.tokenizer(\n",
    "                batch, \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                max_length=self.max_len, \n",
    "                return_tensors=\"pt\"\n",
    "            ).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model_out = self.base_model(**enc)\n",
    "                emb = model_out.last_hidden_state.mean(dim=1)\n",
    "            \n",
    "            all_embeddings.append(emb.cpu().numpy())\n",
    "        \n",
    "        return np.vstack(all_embeddings)\n",
    "    \n",
    "    def predict_labels(self, text: str, topk: int = 3, use_thresholds: bool = True) -> List[str]:\n",
    "        \"\"\"í…ìŠ¤íŠ¸ì—ì„œ í–¥ìˆ˜ ë¼ë²¨ ì˜ˆì¸¡\"\"\"\n",
    "        if not self.clf or not self.mlb:\n",
    "            return []\n",
    "            \n",
    "        emb = self.encode_texts([text], batch_size=1)\n",
    "        if emb.size == 0:\n",
    "            return []\n",
    "            \n",
    "        proba = self.clf.predict_proba(emb)[0]\n",
    "        \n",
    "        if use_thresholds and self.thresholds:\n",
    "            pick = [\n",
    "                i for i, p in enumerate(proba) \n",
    "                if p >= self.thresholds.get(self.mlb.classes_[i], 0.5)\n",
    "            ]\n",
    "            if not pick:\n",
    "                pick = np.argsort(-proba)[:topk]\n",
    "        else:\n",
    "            pick = np.argsort(-proba)[:topk]\n",
    "        \n",
    "        return [self.mlb.classes_[i] for i in pick]\n",
    "    \n",
    "    def search_perfumes(self, labels: List[str], top_n: int = 5) -> List[Tuple[int, float, Dict]]:\n",
    "        \"\"\"BM25ë¥¼ ì‚¬ìš©í•´ í–¥ìˆ˜ ê²€ìƒ‰\"\"\"\n",
    "        if not self.bm25 or not labels:\n",
    "            return []\n",
    "            \n",
    "        query = \" \".join(labels)\n",
    "        tokenized_query = query.lower().split()\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        top_idx = np.argsort(scores)[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_idx:\n",
    "            results.append((idx, scores[idx], self.perfumes[idx]))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def recommend(self, \n",
    "                  user_text: str, \n",
    "                  topk_labels: int = 4, \n",
    "                  top_n_perfumes: int = 5,\n",
    "                  use_thresholds: bool = True) -> Dict:\n",
    "        \"\"\"ì „ì²´ ì¶”ì²œ íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "        \n",
    "        predicted_labels = self.predict_labels(\n",
    "            user_text, \n",
    "            topk=topk_labels, \n",
    "            use_thresholds=use_thresholds\n",
    "        )\n",
    "        \n",
    "        search_results = self.search_perfumes(predicted_labels, top_n=top_n_perfumes)\n",
    "        \n",
    "        return {\n",
    "            \"user_input\": user_text,\n",
    "            \"predicted_labels\": predicted_labels,\n",
    "            \"recommendations\": [\n",
    "                {\n",
    "                    \"rank\": rank,\n",
    "                    \"score\": score,\n",
    "                    \"brand\": perfume.get('brand', 'N/A'),\n",
    "                    \"name\": perfume.get('name_perfume', 'N/A'),\n",
    "                    \"fragrances\": perfume.get('fragrances', 'N/A'),\n",
    "                    \"perfume_data\": perfume\n",
    "                }\n",
    "                for rank, (idx, score, perfume) in enumerate(search_results, 1)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "# ---------- 3) Global Instances ----------\n",
    "# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹¤ì œ ì‚¬ìš©ì‹œì—ëŠ” ë” ë‚˜ì€ ë°©ë²•ìœ¼ë¡œ ê´€ë¦¬)\n",
    "perfume_recommender = None\n",
    "\n",
    "def initialize_recommender():\n",
    "    \"\"\"ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\"\"\"\n",
    "    global perfume_recommender\n",
    "    if perfume_recommender is None:\n",
    "        perfume_recommender = PerfumeRecommender()\n",
    "\n",
    "# ---------- 4) Tools ----------\n",
    "@tool\n",
    "def price_tool(user_query: str) -> str:\n",
    "    \"\"\"A tool that uses the Naver Shopping API to look up perfume prices\"\"\"\n",
    "    \n",
    "    url = \"https://openapi.naver.com/v1/search/shop.json\"\n",
    "    headers = {\n",
    "        \"X-Naver-Client-Id\": naver_client_id,\n",
    "        \"X-Naver-Client-Secret\": naver_client_secret\n",
    "    }\n",
    "    params = {\"query\": user_query, \"display\": 5, \"sort\": \"sim\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "    except Exception as e:\n",
    "        return f\"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}\"\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f\"âŒ API ì˜¤ë¥˜: {response.status_code}\"\n",
    "    \n",
    "    data = response.json()\n",
    "    if not data or \"items\" not in data or len(data[\"items\"]) == 0:\n",
    "        return f\"ğŸ˜” '{user_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    def remove_html_tags(text: str) -> str:\n",
    "        return re.sub(r\"<[^>]+>\", \"\", text)\n",
    "    \n",
    "    products = data[\"items\"][:3]\n",
    "    output = f\"ğŸ” '{user_query}' ê²€ìƒ‰ ê²°ê³¼:\\n\\n\"\n",
    "    for i, item in enumerate(products, 1):\n",
    "        title = remove_html_tags(item.get(\"title\", \"\"))\n",
    "        lprice = item.get(\"lprice\", \"0\")\n",
    "        mall = item.get(\"mallName\", \"ì •ë³´ ì—†ìŒ\")\n",
    "        link = item.get(\"link\", \"ì •ë³´ ì—†ìŒ\")\n",
    "        \n",
    "        output += f\"ğŸ“¦ {i}. {title}\\n\"\n",
    "        if lprice != \"0\":\n",
    "            output += f\"   ğŸ’° ê°€ê²©: {int(lprice):,}ì›\\n\"\n",
    "        output += f\"   ğŸª íŒë§¤ì²˜: {mall}\\n\"\n",
    "        output += f\"   ğŸ”— ë§í¬: {link}\\n\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "# ---------- 5) Supervisor (Router) ----------\n",
    "SUPERVISOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are the â€œPerfume Recommendation Supervisor (Router)â€. Analyze the userâ€™s query (Korean or English) and route to exactly ONE agent below.\n",
    "\n",
    "[Agents]\n",
    "- LLM_parser         : Parses/normalizes multi-facet queries (2+ product facets).\n",
    "- FAQ_agent          : Perfume knowledge / definitions / differences / general questions.\n",
    "- human_fallback     : Non-perfume or off-topic queries.\n",
    "- price_agent        : Price-only intents (cheapest, price, buy, discount, etc.).\n",
    "- ML_agent           : Single-preference recommendations (mood/season vibe like â€œfresh summerâ€, â€œsweetâ€, etc.).\n",
    "\n",
    "[Facets to detect (â€œproduct facetsâ€)]\n",
    "- brand            (e.g., Chanel, Dior, Creed)\n",
    "- season           (spring/summer/fall/winter; â€œfor summer/winterâ€)\n",
    "- gender           (male/female/unisex)\n",
    "- sizes            (volume in ml: 30/50/100 ml)\n",
    "- day_night_score  (day/night/daily/office/club, etc.)\n",
    "- concentration    (EDT/EDP/Extrait/Parfum/Cologne)\n",
    "\n",
    "[Price intent keywords (not exhaustive)]\n",
    "- Korean: ê°€ê²©, ìµœì €ê°€, ì–¼ë§ˆ, ê°€ê²©ëŒ€, êµ¬ë§¤, íŒë§¤, í• ì¸, ì–´ë””ì„œ ì‚¬, ë°°ì†¡ë¹„\n",
    "- English: price, cost, cheapest, buy, purchase, discount\n",
    "\n",
    "[FAQ examples]\n",
    "- Differences between EDP vs EDT, note definitions, longevity/projection, brand/line info.\n",
    "\n",
    "[Single-preference (ML_agent) examples]\n",
    "- â€œRecommend a cool perfume for summerâ€, â€œRecommend a sweet scentâ€, â€œOne citrusy fresh pickâ€\n",
    "  (= 0â€“1 of the above facets mentioned; primarily taste/mood/situation).\n",
    "\n",
    "[Routing rules (priority)]\n",
    "1) Non-perfume / off-topic â†’ human_fallback\n",
    "2) Clear price-only intent (even if one facet is present as context) â†’ price_agent\n",
    "   e.g., â€œChanel No. 5 50ml cheapest price?â€ â†’ price_agent\n",
    "3) Count product facets in the query:\n",
    "   - If facets â‰¥ 2 â†’ LLM_parser\n",
    "4) Otherwise (single-topic queries):\n",
    "   - Perfume knowledge/definitions â†’ FAQ_agent\n",
    "   - Single taste/mood recommendation â†’ ML_agent\n",
    "5) Tie-breakers:\n",
    "   - If price intent is clear â†’ price_agent\n",
    "   - If facets â‰¥ 2 â†’ LLM_parser\n",
    "   - Else: knowledge â†’ FAQ_agent, taste â†’ ML_agent\n",
    "\n",
    "[Output format]\n",
    "Return ONLY this JSON (no extra text):\n",
    "{{\n",
    "  \"next\": \"<LLM_parser|FAQ_agent|human_fallback|price_agent|ML_agent>\",\n",
    "  \"reason\": \"<one short English sentence>\",\n",
    "  \"facet_count\": <integer>,\n",
    "  \"facets\": {{\n",
    "    \"brand\": \"<value or null>\",\n",
    "    \"season\": \"<value or null>\",\n",
    "    \"gender\": \"<value or null>\",\n",
    "    \"sizes\": \"<value or null>\",\n",
    "    \"day_night_score\": \"<value or null>\",\n",
    "    \"concentration\": \"<value or null>\"\n",
    "  }},\n",
    "  \"scent_vibe\": \"<value if detected, else null>\",\n",
    "  \"query_intent\": \"<price|faq|scent_pref|non_perfume|other>\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "router_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SUPERVISOR_SYSTEM_PROMPT),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Call the router LLM and return parsed JSON + routing target.\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    chain = router_prompt | llm\n",
    "    ai = chain.invoke({\"query\": user_query})\n",
    "    text = ai.content\n",
    "\n",
    "    chosen = \"human_fallback\"\n",
    "    parsed: Dict[str, Any] = {}\n",
    "    try:\n",
    "        parsed = json.loads(text)\n",
    "        maybe = parsed.get(\"next\")\n",
    "        if isinstance(maybe, str) and maybe in {\"LLM_parser\",\"FAQ_agent\",\"human_fallback\",\"price_agent\",\"ML_agent\"}:\n",
    "            chosen = maybe\n",
    "    except Exception:\n",
    "        parsed = {\"error\": \"invalid_json\", \"raw\": text}\n",
    "\n",
    "    msgs = state[\"messages\"] + [AIMessage(content=text)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": chosen,\n",
    "        \"router_json\": parsed,\n",
    "        \"parsed\": state.get(\"parsed\"),\n",
    "        \"recommendations\": state.get(\"recommendations\"),\n",
    "        \"price_info\": state.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "# ---------- 6) Agent Nodes ----------\n",
    "def llm_parser_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ë³µí•© ì¿¼ë¦¬ íŒŒì‹±\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    \n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    # LangChain LLM ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½\n",
    "    parse_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"ë„ˆëŠ” í–¥ìˆ˜ ì¿¼ë¦¬ íŒŒì„œì•¼.\n",
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜:\n",
    "- brand: ë¸Œëœë“œëª… (ì˜ˆ: ìƒ¤ë„¬, ë””ì˜¬, ì…ìƒë¡œë‘ ë“±)\n",
    "- concentration:  (í¼í“¸, ì½”ë¡± ë“±)\n",
    "- day_night_score: ì‚¬ìš©ì‹œê°„ (ì£¼ê°„, ì•¼ê°„, ë°ì¼ë¦¬ ë“±)\n",
    "- gender: ì„±ë³„ (ë‚¨ì„±, ì—¬ì„±, ìœ ë‹ˆì„¹ìŠ¤)\n",
    "- season_score: ê³„ì ˆ (ë´„, ì—¬ë¦„, ê°€ì„, ê²¨ìš¸)\n",
    "- sizes: ìš©ëŸ‰ (30ml, 50ml, 100ml ë“±)\n",
    "\n",
    "ì—†ëŠ” ê°’ì€ nullë¡œ ë‘ê³ , ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì¤˜.\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "{{\"brand\": \"ìƒ¤ë„¬\", \"gender\": \"ì—¬ì„±\", \"sizes\": \"50ml\", \"season_score\": \"ê²¨ìš¸\", \"concentration\": null, \"day_night_score\": null}}\"\"\"),\n",
    "        (\"user\", \"{query}\")\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        chain = parse_prompt | llm\n",
    "        ai_response = chain.invoke({\"query\": user_query})\n",
    "        \n",
    "        # JSON íŒŒì‹± ì‹œë„\n",
    "        response_text = ai_response.content.strip()\n",
    "        \n",
    "        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±°)\n",
    "        if \"```json\" in response_text:\n",
    "            response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in response_text:\n",
    "            response_text = response_text.split(\"```\")[1].strip()\n",
    "        \n",
    "        parsed_result = json.loads(response_text)\n",
    "        \n",
    "        # í•„ë“œ ê²€ì¦\n",
    "        expected_fields = [\"brand\", \"concentration\", \"day_night_score\", \"gender\", \"season_score\", \"sizes\"]\n",
    "        for field in expected_fields:\n",
    "            if field not in parsed_result:\n",
    "                parsed_result[field] = None\n",
    "                \n",
    "    except json.JSONDecodeError as e:\n",
    "        parsed_result = {\"error\": f\"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}\", \"raw_response\": response_text}\n",
    "    except Exception as e:\n",
    "        parsed_result = {\"error\": f\"íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(e)}\"}\n",
    "    \n",
    "    # ê²°ê³¼ í¬ë§·íŒ…\n",
    "    result_text = f\"ğŸ” **ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼**\\n\\n\"\n",
    "    if \"error\" not in parsed_result:\n",
    "        found_any = False\n",
    "        for key, value in parsed_result.items():\n",
    "            if value and value != \"null\":\n",
    "                korean_labels = {\n",
    "                    \"brand\": \"ë¸Œëœë“œ\",\n",
    "                    \"concentration\": \"ë†ë„\", \n",
    "                    \"day_night_score\": \"ì‚¬ìš©ì‹œê°„\",\n",
    "                    \"gender\": \"ì„±ë³„\",\n",
    "                    \"season_score\": \"ê³„ì ˆ\", \n",
    "                    \"sizes\": \"ìš©ëŸ‰\"\n",
    "                }\n",
    "                result_text += f\"â€¢ {korean_labels.get(key, key)}: {value}\\n\"\n",
    "                found_any = True\n",
    "        \n",
    "        if found_any:\n",
    "            result_text += f\"\\nğŸ“ ë¶„ì„ëœ ì¡°ê±´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ í•„í„°ë§í–ˆìŠµë‹ˆë‹¤.\"\n",
    "        else:\n",
    "            result_text += f\"ğŸ“ êµ¬ì²´ì ì¸ ì¡°ê±´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì¶”ì²œì„ ì§„í–‰í•©ë‹ˆë‹¤.\"\n",
    "    else:\n",
    "        result_text += f\"âŒ íŒŒì‹± ì˜¤ë¥˜: {parsed_result['error']}\"\n",
    "        if 'raw_response' in parsed_result:\n",
    "            result_text += f\"\\nì›ë³¸ ì‘ë‹µ: {parsed_result['raw_response']}\"\n",
    "    \n",
    "    msgs = state[\"messages\"] + [AIMessage(content=result_text)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": None,\n",
    "        \"router_json\": state.get(\"router_json\"),\n",
    "        \"parsed\": parsed_result,\n",
    "        \"recommendations\": state.get(\"recommendations\"),\n",
    "        \"price_info\": state.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "def faq_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"í–¥ìˆ˜ FAQ ì²˜ë¦¬\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    \n",
    "    # ê°„ë‹¨í•œ FAQ ë§¤ì¹­\n",
    "    faq_responses = {\n",
    "        \"edp\": \"ğŸŒŸ **EDP vs EDT ì°¨ì´ì **\\n\\nEDP (Eau de Parfum): í–¥ë£Œ ë†ë„ 15-20%, ì§€ì†ì‹œê°„ 6-8ì‹œê°„\\nEDT (Eau de Toilette): í–¥ë£Œ ë†ë„ 5-15%, ì§€ì†ì‹œê°„ 3-5ì‹œê°„\\n\\nEDPê°€ ë” ì§„í•˜ê³  ì˜¤ë˜ê°€ì§€ë§Œ, EDTê°€ ë” ê°€ë³ê³  ìƒì¾Œí•´ìš”!\",\n",
    "        \"ë…¸íŠ¸\": \"ğŸµ **í–¥ìˆ˜ ë…¸íŠ¸ êµ¬ì„±**\\n\\nâ€¢ **íƒ‘ë…¸íŠ¸**: ì²« ì¸ìƒ (5-15ë¶„)\\nâ€¢ **ë¯¸ë“¤ë…¸íŠ¸**: ë©”ì¸ í–¥ (30ë¶„-2ì‹œê°„)\\nâ€¢ **ë² ì´ìŠ¤ë…¸íŠ¸**: ë§ˆë¬´ë¦¬ í–¥ (2ì‹œê°„ ì´ìƒ)\\n\\nì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ í–¥ì´ ë³€í™”í•˜ëŠ” ê²ƒì´ í–¥ìˆ˜ì˜ ë§¤ë ¥ì´ì—ìš”!\",\n",
    "        \"ì§€ì†\": \"â° **í–¥ìˆ˜ ì§€ì†ì‹œê°„**\\n\\nâ€¢ Parfum: 8ì‹œê°„ ì´ìƒ\\nâ€¢ EDP: 6-8ì‹œê°„\\nâ€¢ EDT: 3-5ì‹œê°„\\nâ€¢ EDC: 2-3ì‹œê°„\\n\\ní”¼ë¶€íƒ€ì…ê³¼ ë³´ê´€ìƒíƒœì— ë”°ë¼ ì°¨ì´ê°€ ìˆì–´ìš”!\"\n",
    "    }\n",
    "    \n",
    "    response = \"â“ **í–¥ìˆ˜ ê´€ë ¨ ì§ˆë¬¸**\\n\\nêµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”!\\n\\nğŸ’¡ ì˜ˆì‹œ: EDPì™€ EDT ì°¨ì´, ë…¸íŠ¸ êµ¬ì„±, ì§€ì†ì‹œê°„ ë“±\"\n",
    "    \n",
    "    query_lower = user_query.lower()\n",
    "    for keyword, answer in faq_responses.items():\n",
    "        if keyword in query_lower:\n",
    "            response = answer\n",
    "            break\n",
    "    \n",
    "    msgs = state[\"messages\"] + [AIMessage(content=response)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": None,\n",
    "        \"router_json\": state.get(\"router_json\"),\n",
    "        \"parsed\": state.get(\"parsed\"),\n",
    "        \"recommendations\": state.get(\"recommendations\"),\n",
    "        \"price_info\": state.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "def human_fallback_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ì¼ë°˜ì ì¸ í´ë°±\"\"\"\n",
    "    response = \"â“ í–¥ìˆ˜ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”!\\n\\nğŸ’¡ ì˜ˆì‹œ:\\nâ€¢ í–¥ìˆ˜ ì¶”ì²œ\\nâ€¢ í–¥ìˆ˜ ê°€ê²© ë¬¸ì˜\\nâ€¢ í–¥ìˆ˜ ì§€ì‹ ë¬¸ë‹µ\"\n",
    "    \n",
    "    msgs = state[\"messages\"] + [AIMessage(content=response)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": None,\n",
    "        \"router_json\": state.get(\"router_json\"),\n",
    "        \"parsed\": state.get(\"parsed\"),\n",
    "        \"recommendations\": state.get(\"recommendations\"),\n",
    "        \"price_info\": state.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "def price_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ê°€ê²© ì¡°íšŒ\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    \n",
    "    if not user_query:\n",
    "        user_query = \"í–¥ìˆ˜\"\n",
    "    \n",
    "    if not naver_client_id or not naver_client_secret:\n",
    "        price_result = \"âŒ ë„¤ì´ë²„ API ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
    "    else:\n",
    "        price_result = price_tool.invoke({\"user_query\": user_query})\n",
    "    \n",
    "    msgs = state[\"messages\"] + [AIMessage(content=price_result)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": None,\n",
    "        \"router_json\": state.get(\"router_json\"),\n",
    "        \"parsed\": state.get(\"parsed\"),\n",
    "        \"recommendations\": state.get(\"recommendations\"),\n",
    "        \"price_info\": price_result\n",
    "    }\n",
    "\n",
    "def ml_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ML ê¸°ë°˜ í–¥ìˆ˜ ì¶”ì²œ\"\"\"\n",
    "    initialize_recommender()\n",
    "    \n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    \n",
    "    if not user_query:\n",
    "        user_query = \"í–¥ìˆ˜ ì¶”ì²œ\"\n",
    "    \n",
    "    if perfume_recommender is None:\n",
    "        response = \"âŒ ì¶”ì²œ ì‹œìŠ¤í…œì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        recommendations = []\n",
    "    else:\n",
    "        try:\n",
    "            result = perfume_recommender.recommend(\n",
    "                user_text=user_query,\n",
    "                topk_labels=4,\n",
    "                top_n_perfumes=5,\n",
    "                use_thresholds=True\n",
    "            )\n",
    "            \n",
    "            recommendations = result.get(\"recommendations\", [])\n",
    "            predicted_labels = result.get(\"predicted_labels\", [])\n",
    "            \n",
    "            if recommendations:\n",
    "                response = f\"ğŸ¯ **'{user_query}' ì¶”ì²œ ê²°ê³¼**\\n\\n\"\n",
    "                response += f\"ğŸ·ï¸ **ì˜ˆì¸¡ëœ í–¥ íŠ¹ì„±**: {', '.join(predicted_labels)}\\n\\n\"\n",
    "                \n",
    "                for rec in recommendations:\n",
    "                    response += f\"ğŸŒŸ **{rec['rank']}ìœ„** (ì ìˆ˜: {rec['score']:.2f})\\n\"\n",
    "                    response += f\"   ë¸Œëœë“œ: {rec['brand']}\\n\"\n",
    "                    response += f\"   ì œí’ˆëª…: {rec['name']}\\n\"\n",
    "                    response += f\"   í–¥ íŠ¹ì„±: {rec['fragrances']}\\n\\n\"\n",
    "            else:\n",
    "                response = \"ğŸ˜” ì¶”ì²œí•  í–¥ìˆ˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            response = f\"âŒ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "            recommendations = []\n",
    "    \n",
    "    msgs = state[\"messages\"] + [AIMessage(content=response)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": None,\n",
    "        \"router_json\": state.get(\"router_json\"),\n",
    "        \"parsed\": state.get(\"parsed\"),\n",
    "        \"recommendations\": recommendations,\n",
    "        \"price_info\": state.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "# ---------- 7) Build Graph ----------\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"LLM_parser\", llm_parser_node)\n",
    "graph.add_node(\"FAQ_agent\", faq_agent_node)\n",
    "graph.add_node(\"human_fallback\", human_fallback_node)\n",
    "graph.add_node(\"price_agent\", price_agent_node)\n",
    "graph.add_node(\"ML_agent\", ml_agent_node)\n",
    "\n",
    "graph.set_entry_point(\"supervisor\")\n",
    "\n",
    "def router_edge(state: AgentState) -> str:\n",
    "    return state[\"next\"] or \"human_fallback\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    router_edge,\n",
    "    {\n",
    "        \"LLM_parser\": \"LLM_parser\",\n",
    "        \"FAQ_agent\": \"FAQ_agent\",\n",
    "        \"human_fallback\": \"human_fallback\",\n",
    "        \"price_agent\": \"price_agent\",\n",
    "        \"ML_agent\": \"ML_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "for node in [\"LLM_parser\", \"FAQ_agent\", \"human_fallback\", \"price_agent\", \"ML_agent\"]:\n",
    "    graph.add_edge(node, END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# ---------- 8) Main Function ----------\n",
    "def process_query(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜\"\"\"\n",
    "    init: AgentState = {\n",
    "        \"messages\": [HumanMessage(content=query)],\n",
    "        \"next\": None,\n",
    "        \"router_json\": None,\n",
    "        \"parsed\": None,\n",
    "        \"recommendations\": None,\n",
    "        \"price_info\": None\n",
    "    }\n",
    "    \n",
    "    result = app.invoke(init)\n",
    "    \n",
    "    # ê²°ê³¼ ì •ë¦¬\n",
    "    final_response = \"\"\n",
    "    for msg in result[\"messages\"]:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            final_response = msg.content\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": final_response,\n",
    "        \"router_decision\": result.get(\"router_json\", {}),\n",
    "        \"parsed_data\": result.get(\"parsed\"),\n",
    "        \"recommendations\": result.get(\"recommendations\"),\n",
    "        \"price_info\": result.get(\"price_info\")\n",
    "    }\n",
    "\n",
    "# ---------- 9) Test Function ----------\n",
    "def run_tests():\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "    TEST_QUERIES = [\n",
    "        \"ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\",\n",
    "        \"ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\",\n",
    "        \"EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?\",\n",
    "        \"íƒ‘ë…¸íŠ¸Â·ë¯¸ë“¤ë…¸íŠ¸Â·ë² ì´ìŠ¤ë…¸íŠ¸ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì´ì•¼?\",\n",
    "        \"ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?\",\n",
    "        \"ìƒ¤ë„¬ ë„˜ë²„5 50ml ìµœì €ê°€ ì•Œë ¤ì¤˜.\",\n",
    "        \"ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\",\n",
    "        \"ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.\",\n",
    "    ]\n",
    "    \n",
    "    for query in TEST_QUERIES:\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Query: {query}\")\n",
    "        result = process_query(query)\n",
    "        print(f\"Router: {result['router_decision'].get('next', 'unknown')}\")\n",
    "        print(f\"Response: {result['response']}\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595823e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: {'brand': 'ìƒ¤ë„¬', 'gender': 'ì—¬ì„±', 'sizes': '50ml', 'season_score': 'ê²¨ìš¸', 'concentration': None, 'day_night_score': 'day,night'}\n",
      "Filtered: {'brand': 'ìƒ¤ë„¬', 'concentration': None, 'day_night_score': 'day,night', 'gender': None, 'season_score': None, 'sizes': '50'}\n",
      "\n",
      "Invalid Original: {'brand': 'ì˜ëª»ëœë¸Œëœë“œ', 'gender': 'ì˜ëª»ëœì„±ë³„', 'sizes': '100ml', 'season_score': 'ì˜ëª»ëœê³„ì ˆ', 'concentration': 'ì˜ëª»ëœë†ë„', 'day_night_score': 'morning'}\n",
      "Filtered Invalid: {'brand': None, 'concentration': None, 'day_night_score': None, 'gender': None, 'season_score': None, 'sizes': None}\n"
     ]
    }
   ],
   "source": [
    "def filter_brand(brand_value):\n",
    "    \"\"\"ë¸Œëœë“œ í•„í„°ë§ í•¨ìˆ˜\"\"\"\n",
    "    valid_brands = [\n",
    "        'ê²”ë‘', 'êµ¬ì°Œ', 'ëŒë¡œì—', 'ë‚˜ë¥´ì‹œì†Œ ë¡œë“œë¦¬ê²Œì¦ˆ', 'ë‹ˆìƒ¤ë„¤', 'ë„ë¥´ì„¸', 'ë””ì˜¬', 'ë”¥í‹°í¬', 'ë‘ì½¤',\n",
    "        'ë¡œë¼ ë©”ë¥´ì‹œì—', 'ë¡œì—ë² ', 'ë¡ì‹œë•…', 'ë¥´ ë¼ë³´', 'ë©”ëª¨', 'ë©”ì¢… ë§ˆë¥´ì§€ì—˜ë¼', 'ë©”ì¢… í”„ë€ì‹œìŠ¤ ì»¤ì •',\n",
    "        'ë©œë¦°ì•¤ê²Œì¸ ', 'ë¯¸ìš°ë¯¸ìš°', 'ë°”ì´ë ˆë„', 'ë°˜í´ë¦¬í”„ ì•„í ', 'ë²„ë²„ë¦¬', 'ë² ë¥´ì‚¬ì²´', 'ë¶ˆê°€ë¦¬', 'ë¹„ë””ì¼€ì´',\n",
    "        'ì‚°íƒ€ ë§ˆë¦¬ì•„ ë…¸ë²¨ë¼', 'ìƒ¤ë„¬', 'ì„¸ë¥´ì£¼ ë£¨í…', 'ì‹œìŠ¬ë¦¬ ì½”ìŠ¤ë©”í‹±', 'ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ', 'ì—ë”° ë¦¬ë¸Œë¥´ ë„ëŸ‰ì¥¬',\n",
    "        'ì—ë¥´ë©”ìŠ¤', 'ì—ìŠ¤í‹° ë¡œë”', 'ì—‘ìŠ¤ ë‹ˆíë¡œ', 'ì´ë‹ˆì‹œì˜¤ í¼í“¸', 'ì´ì†', 'ì…ìƒë¡œë‘', 'ì œë¥´ì¡°í”„', 'ì¡° ë§ë¡ ',\n",
    "        'ì¡°ë¥´ì§€ì˜¤ ì•„ë¥´ë§ˆë‹ˆ', 'ì¤„ë¦¬ì—£ í—¤ì¦ˆ ì–´ ê±´', 'ì§€ë°©ì‹œ', 'ì§ˆ ìŠ¤íŠœì–´íŠ¸', 'í¬ë¦¬ë“œ', 'í‚¬ë¦¬ì•ˆ', 'í†° í¬ë“œ',\n",
    "        'í‹°íŒŒë‹ˆì•¤ì½”', 'í¼í“¸ ë“œ ë§ë¦¬', 'íœí• ë¦¬ê³¤ìŠ¤', 'í”„ë¼ë‹¤', 'í”„ë ˆë°ë¦­ ë§'\n",
    "    ]\n",
    "    \n",
    "    if brand_value is None:\n",
    "        return None\n",
    "    \n",
    "    return brand_value if brand_value in valid_brands else None\n",
    "\n",
    "\n",
    "def filter_concentration(concentration_value):\n",
    "    \"\"\"ë†ë„ í•„í„°ë§ í•¨ìˆ˜\"\"\"\n",
    "    valid_concentrations = ['ì†”ë¦¬ë“œ í¼í“¸', 'ì—‘ìŠ¤íŠ¸ë ˆ ë“œ í¼í“¸', 'ì˜¤ ë“œ ëšœì™ˆë ›', 'ì˜¤ ë“œ ì½”ë¡±', 'ì˜¤ ë“œ í¼í“¸', 'í¼í“¸']\n",
    "    \n",
    "    if concentration_value is None:\n",
    "        return None\n",
    "    \n",
    "    return concentration_value if concentration_value in valid_concentrat ions else None\n",
    "\n",
    "\n",
    "def filter_day_night_score(day_night_value):\n",
    "    \"\"\"ì‚¬ìš©ì‹œê°„ í•„í„°ë§ í•¨ìˆ˜\"\"\"\n",
    "    valid_day_night = [\"day\", \"night\"]\n",
    "    \n",
    "    if day_night_value is None:\n",
    "        return None\n",
    "    \n",
    "    # ì‰¼í‘œë¡œ ë¶„ë¦¬ëœ ê°’ë“¤ ì²˜ë¦¬\n",
    "    if isinstance(day_night_value, str) and ',' in day_night_value:\n",
    "        values = [v.strip() for v in day_night_value.split(',')]\n",
    "        filtered_values = [v for v in values if v in valid_day_night]\n",
    "        return ','.join(filtered_values) if filtered_values else None\n",
    "    \n",
    "    return day_night_value if day_night_value in valid_day_night else None\n",
    "\n",
    "\n",
    "def filter_gender(gender_value):\n",
    "    \"\"\"ì„±ë³„ í•„í„°ë§ í•¨ìˆ˜\"\"\"\n",
    "    valid_genders = ['Female', 'Male', 'Unisex', 'unisex ']\n",
    "    \n",
    "    if gender_value is None:\n",
    "        return None\n",
    "    \n",
    "    return gender_value if gender_value in valid_genders else None\n",
    "\n",
    "\n",
    "def filter_season_score(season_value):\n",
    "    \"\"\"ê³„ì ˆ í•„í„°ë§ í•¨ìˆ˜\"\"\"\n",
    "    valid_seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "    \n",
    "    if season_value is None:\n",
    "        return None\n",
    "    \n",
    "    return season_value if season_value in valid_seasons else None\n",
    "\n",
    "\n",
    "def filter_sizes(sizes_value):\n",
    "    \"\"\"ìš©ëŸ‰ í•„í„°ë§ í•¨ìˆ˜\"\"\"\n",
    "    valid_sizes = ['50', '75']\n",
    "    \n",
    "    if sizes_value is None:\n",
    "        return None\n",
    "    \n",
    "    # ìˆ«ìë§Œ ì¶”ì¶œ (ì˜ˆ: \"50ml\" -> \"50\")\n",
    "    if isinstance(sizes_value, str):\n",
    "        import re\n",
    "        numbers = re.findall(r'\\d+', sizes_value)\n",
    "        for num in numbers:\n",
    "            if num in valid_sizes:\n",
    "                return num\n",
    "    \n",
    "    return sizes_value if str(sizes_value) in valid_sizes else None\n",
    "\n",
    "\n",
    "def apply_meta_filters(parsed_json):\n",
    "    \"\"\"ì „ì²´ JSONì— ë©”íƒ€í•„í„°ë§ ì ìš©\"\"\"\n",
    "    filtered_result = {\n",
    "        'brand': filter_brand(parsed_json.get('brand')),\n",
    "        'concentration': filter_concentration(parsed_json.get('concentration')),\n",
    "        'day_night_score': filter_day_night_score(parsed_json.get('day_night_score')),\n",
    "        'gender': filter_gender(parsed_json.get('gender')),\n",
    "        'season_score': filter_season_score(parsed_json.get('season_score')),\n",
    "        'sizes': filter_sizes(parsed_json.get('sizes'))\n",
    "    }\n",
    "    \n",
    "    return filtered_result\n",
    "\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    # ì˜ˆì‹œ íŒŒì‹±ëœ JSON\n",
    "    sample_parsed = {\n",
    "        \"brand\": \"ìƒ¤ë„¬\",\n",
    "        \"gender\": \"ì—¬ì„±\", \n",
    "        \"sizes\": \"50ml\",\n",
    "        \"season_score\": \"ê²¨ìš¸\",\n",
    "        \"concentration\": None,\n",
    "        \"day_night_score\": \"day,night\"\n",
    "    }\n",
    "    \n",
    "    # ë©”íƒ€í•„í„°ë§ ì ìš©\n",
    "    filtered_result = apply_meta_filters(sample_parsed)\n",
    "    print(\"Original:\", sample_parsed)\n",
    "    print(\"Filtered:\", filtered_result)\n",
    "    \n",
    "    # ì˜ëª»ëœ ê°’ë“¤ì´ í¬í•¨ëœ ì˜ˆì‹œ\n",
    "    invalid_sample = {\n",
    "        \"brand\": \"ì˜ëª»ëœë¸Œëœë“œ\",\n",
    "        \"gender\": \"ì˜ëª»ëœì„±ë³„\",\n",
    "        \"sizes\": \"100ml\",  # valid_sizesì— ì—†ìŒ\n",
    "        \"season_score\": \"ì˜ëª»ëœê³„ì ˆ\",\n",
    "        \"concentration\": \"ì˜ëª»ëœë†ë„\",\n",
    "        \"day_night_score\": \"morning\"  # validì— ì—†ìŒ\n",
    "    }\n",
    "    \n",
    "    filtered_invalid = apply_meta_filters(invalid_sample)\n",
    "    print(\"\\nInvalid Original:\", invalid_sample)\n",
    "    print(\"Filtered Invalid:\", filtered_invalid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
