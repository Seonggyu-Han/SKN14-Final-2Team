{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1527bc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import TypedDict, List, Optional, Dict, Any, Tuple\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a62648",
   "metadata": {},
   "source": [
    "# LLM Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29ec55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1) .envì—ì„œ OPENAI_API_KEY ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 2) í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "parse_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë„ˆëŠ” í–¥ìˆ˜ ì¿¼ë¦¬ íŒŒì„œì•¼.\n",
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜:\n",
    "- brand: ë¸Œëœë“œëª… (ì˜ˆ: ìƒ¤ë„¬, ë””ì˜¬, ì…ìƒë¡œë‘ ë“±)\n",
    "- concentration: (í¼í“¸, ì½”ë¡± ë“±)\n",
    "- day_night_score: ì‚¬ìš©ì‹œê°„ (ì£¼ê°„, ì•¼ê°„, ë°ì¼ë¦¬ ë“±)\n",
    "- gender: ì„±ë³„ (ë‚¨ì„±, ì—¬ì„±, ìœ ë‹ˆì„¹ìŠ¤)\n",
    "- season_score: ê³„ì ˆ (ë´„, ì—¬ë¦„, ê°€ì„, ê²¨ìš¸)\n",
    "- sizes: ìš©ëŸ‰ (30ml, 50ml, 100ml ë“±) ë‹¨ìœ„ëŠ” ë¬´ì‹œí•˜ê³  ìˆ«ìë§Œ\n",
    "\n",
    "ì—†ëŠ” ê°’ì€ nullë¡œ ë‘ê³ , ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì¤˜.\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "{{\"brand\": \"ìƒ¤ë„¬\", \"gender\": null, \"sizes\": \"50ml\", \"season_score\": null, \"concentration\": null, \"day_night_score\": null}}\"\"\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "def run_llm_parser(query: str):\n",
    "    chain = parse_prompt | llm\n",
    "    ai_response = chain.invoke({\"query\": query})\n",
    "    response_text = ai_response.content.strip()\n",
    "\n",
    "    # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "    if \"```json\" in response_text:\n",
    "        response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "    elif \"```\" in response_text:\n",
    "        response_text = response_text.split(\"```\")[1].strip()\n",
    "\n",
    "    parsed = json.loads(response_text)\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f31932e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ì¿¼ë¦¬: ë”¥ë í¬ 50ml í–¥ìˆ˜ ìˆì–´?\n",
      "íŒŒì‹± ê²°ê³¼: {\n",
      "  \"brand\": \"ë”¥ë í¬\",\n",
      "  \"gender\": null,\n",
      "  \"sizes\": \"50\",\n",
      "  \"season_score\": null,\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"ë”¥ë í¬ 50ml í–¥ìˆ˜ ìˆì–´?\"\n",
    "    parsed = run_llm_parser(query)\n",
    "    print(\"ì›ë³¸ ì¿¼ë¦¬:\", query)\n",
    "    print(\"íŒŒì‹± ê²°ê³¼:\", json.dumps(parsed, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f990886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "\n",
    "# ---- ë©”íƒ€í•„í„° í•¨ìˆ˜ë“¤ ----\n",
    "def filter_brand(brand_value):\n",
    "    valid_brands = [\n",
    "        'ê²”ë‘', 'êµ¬ì°Œ', 'ëŒë¡œì—', 'ë‚˜ë¥´ì‹œì†Œ ë¡œë“œë¦¬ê²Œì¦ˆ', 'ë‹ˆìƒ¤ë„¤', 'ë„ë¥´ì„¸', 'ë””ì˜¬', 'ë”¥í‹°í¬', 'ë‘ì½¤',\n",
    "        'ë¡œë¼ ë©”ë¥´ì‹œì—', 'ë¡œì—ë² ', 'ë¡ì‹œë•…', 'ë¥´ ë¼ë³´', 'ë©”ëª¨', 'ë©”ì¢… ë§ˆë¥´ì§€ì—˜ë¼', 'ë©”ì¢… í”„ë€ì‹œìŠ¤ ì»¤ì •',\n",
    "        'ë©œë¦°ì•¤ê²Œì¸ ', 'ë¯¸ìš°ë¯¸ìš°', 'ë°”ì´ë ˆë„', 'ë°˜í´ë¦¬í”„ ì•„í ', 'ë²„ë²„ë¦¬', 'ë² ë¥´ì‚¬ì²´', 'ë¶ˆê°€ë¦¬', 'ë¹„ë””ì¼€ì´',\n",
    "        'ì‚°íƒ€ ë§ˆë¦¬ì•„ ë…¸ë²¨ë¼', 'ìƒ¤ë„¬', 'ì„¸ë¥´ì£¼ ë£¨í…', 'ì‹œìŠ¬ë¦¬ ì½”ìŠ¤ë©”í‹±', 'ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ', 'ì—ë”° ë¦¬ë¸Œë¥´ ë„ëŸ‰ì¥¬',\n",
    "        'ì—ë¥´ë©”ìŠ¤', 'ì—ìŠ¤í‹° ë¡œë”', 'ì—‘ìŠ¤ ë‹ˆíë¡œ', 'ì´ë‹ˆì‹œì˜¤ í¼í“¸', 'ì´ì†', 'ì…ìƒë¡œë‘', 'ì œë¥´ì¡°í”„', 'ì¡° ë§ë¡ ',\n",
    "        'ì¡°ë¥´ì§€ì˜¤ ì•„ë¥´ë§ˆë‹ˆ', 'ì¤„ë¦¬ì—£ í—¤ì¦ˆ ì–´ ê±´', 'ì§€ë°©ì‹œ', 'ì§ˆ ìŠ¤íŠœì–´íŠ¸', 'í¬ë¦¬ë“œ', 'í‚¬ë¦¬ì•ˆ', 'í†° í¬ë“œ',\n",
    "        'í‹°íŒŒë‹ˆì•¤ì½”', 'í¼í“¸ ë“œ ë§ë¦¬', 'íœí• ë¦¬ê³¤ìŠ¤', 'í”„ë¼ë‹¤', 'í”„ë ˆë°ë¦­ ë§'\n",
    "    ]\n",
    "    if brand_value is None:\n",
    "        return None\n",
    "    return brand_value if brand_value in valid_brands else None\n",
    "\n",
    "\n",
    "def filter_concentration(concentration_value):\n",
    "    valid_concentrations = ['ì†”ë¦¬ë“œ í¼í“¸', 'ì—‘ìŠ¤íŠ¸ë ˆ ë“œ í¼í“¸', 'ì˜¤ ë“œ ëšœì™ˆë ›', 'ì˜¤ ë“œ ì½”ë¡±', 'ì˜¤ ë“œ í¼í“¸', 'í¼í“¸']\n",
    "    if concentration_value is None:\n",
    "        return None\n",
    "    return concentration_value if concentration_value in valid_concentrations else None\n",
    "\n",
    "\n",
    "def filter_day_night_score(day_night_value):\n",
    "    valid_day_night = [\"day\", \"night\"]\n",
    "    if day_night_value is None:\n",
    "        return None\n",
    "    if isinstance(day_night_value, str) and ',' in day_night_value:\n",
    "        values = [v.strip() for v in day_night_value.split(',')]\n",
    "        filtered_values = [v for v in values if v in valid_day_night]\n",
    "        return ','.join(filtered_values) if filtered_values else None\n",
    "    return day_night_value if day_night_value in valid_day_night else None\n",
    "\n",
    "\n",
    "def filter_gender(gender_value):\n",
    "    valid_genders = ['Female', 'Male', 'Unisex', 'unisex ']\n",
    "    if gender_value is None:\n",
    "        return None\n",
    "    return gender_value if gender_value in valid_genders else None\n",
    "\n",
    "\n",
    "def filter_season_score(season_value):\n",
    "    valid_seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "    if season_value is None:\n",
    "        return None\n",
    "    return season_value if season_value in valid_seasons else None\n",
    "\n",
    "\n",
    "def filter_sizes(sizes_value):\n",
    "    \"\"\"ìˆ«ìë§Œ ì¶”ì¶œí•´ì„œ ìœ íš¨ê°’ì¸ì§€ í™•ì¸\"\"\"\n",
    "    valid_sizes = ['30', '50', '75', '100', '150']\n",
    "    if sizes_value is None:\n",
    "        return None\n",
    "    if isinstance(sizes_value, str):\n",
    "        numbers = re.findall(r'\\d+', sizes_value)\n",
    "        for num in numbers:\n",
    "            if num in valid_sizes:\n",
    "                return num\n",
    "    return str(sizes_value) if str(sizes_value) in valid_sizes else None\n",
    "\n",
    "\n",
    "def apply_meta_filters(parsed_json: dict) -> dict:\n",
    "    \"\"\"íŒŒì‹±ëœ JSONì— ë©”íƒ€í•„í„°ë§ ì ìš©\"\"\"\n",
    "    if not parsed_json or \"error\" in parsed_json:\n",
    "        return parsed_json\n",
    "    \n",
    "    return {\n",
    "        'brand': filter_brand(parsed_json.get('brand')),\n",
    "        'concentration': filter_concentration(parsed_json.get('concentration')),\n",
    "        'day_night_score': filter_day_night_score(parsed_json.get('day_night_score')),\n",
    "        'gender': filter_gender(parsed_json.get('gender')),\n",
    "        'season_score': filter_season_score(parsed_json.get('season_score')),\n",
    "        'sizes': filter_sizes(parsed_json.get('sizes'))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a788cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "# Pinecone ì´ˆê¸°í™”\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# perfume-vectordb2 ì¸ë±ìŠ¤ ì§€ì •\n",
    "index = pc.Index(\"perfume-vectordb2\")\n",
    "\n",
    "\n",
    "def build_pinecone_filter(filtered_json: dict) -> dict:\n",
    "    \"\"\"\n",
    "    ë©”íƒ€í•„í„°ë§ ê²°ê³¼ë¥¼ Pinecone filter dictë¡œ ë³€í™˜\n",
    "    \"\"\"\n",
    "    pinecone_filter = {}\n",
    "    if filtered_json.get(\"brand\"):\n",
    "        pinecone_filter[\"brand\"] = {\"$eq\": filtered_json[\"brand\"]}\n",
    "    if filtered_json.get(\"sizes\"):\n",
    "        pinecone_filter[\"sizes\"] = {\"$eq\": filtered_json[\"sizes\"]}\n",
    "    if filtered_json.get(\"season_score\"):\n",
    "        pinecone_filter[\"season_score\"] = {\"$eq\": filtered_json[\"season_score\"]}\n",
    "    if filtered_json.get(\"gender\"):\n",
    "        pinecone_filter[\"gender\"] = {\"$eq\": filtered_json[\"gender\"]}\n",
    "    if filtered_json.get(\"concentration\"):\n",
    "        pinecone_filter[\"concentration\"] = {\"$eq\": filtered_json[\"concentration\"]}\n",
    "    if filtered_json.get(\"day_night_score\"):\n",
    "        pinecone_filter[\"day_night_score\"] = {\"$eq\": filtered_json[\"day_night_score\"]}\n",
    "    return pinecone_filter\n",
    "\n",
    "\n",
    "def query_pinecone(vector, filtered_json: dict, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Pinecone ë²¡í„° ê²€ìƒ‰ + ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©\n",
    "    \"\"\"\n",
    "    pinecone_filter = build_pinecone_filter(filtered_json)\n",
    "\n",
    "    result = index.query(\n",
    "        vector=vector,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        filter=pinecone_filter if pinecone_filter else None\n",
    "    )\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì„œ ë¶€í„° í˜¼ëˆì‹œì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28be830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ ===\n",
      "\n",
      "[1]\n",
      "{\n",
      "  \"id\": \"perfume_3009ee702f886c68\",\n",
      "  \"brand\": \"ë”¥í‹°í¬\",\n",
      "  \"concentration\": \"ì˜¤ ë“œ ëšœì™ˆë ›\",\n",
      "  \"day_night_score\": \"night\",\n",
      "  \"gender\": \"Unisex\",\n",
      "  \"name\": \"ì˜¤ ë° ì½ ì˜¤ ë“œ ëšœì™ˆë ›\",\n",
      "  \"no\": 143.0,\n",
      "  \"season_score\": \"winter\",\n",
      "  \"sizes\": [\n",
      "    \"50\",\n",
      "    \"100\"\n",
      "  ],\n",
      "  \"text\": \"ê°ê°ì˜ ë¬¼ ë˜ëŠ” ì—ì„¼ìŠ¤ì˜ ë¬¼ë¡œ í•´ì„ë˜ëŠ” í–¥\"\n",
      "}\n",
      "\n",
      "[2]\n",
      "{\n",
      "  \"id\": \"perfume_8c25220938bc55f8\",\n",
      "  \"brand\": \"ë”¥í‹°í¬\",\n",
      "  \"concentration\": \"ì˜¤ ë“œ ëšœì™ˆë ›\",\n",
      "  \"day_night_score\": \"night\",\n",
      "  \"gender\": \"Unisex\",\n",
      "  \"name\": \"í•„ë¡œì‹œì½”ìŠ¤ ì˜¤ ë“œ ëšœì™ˆë ›\",\n",
      "  \"no\": 161.0,\n",
      "  \"season_score\": \"spring\",\n",
      "  \"sizes\": [\n",
      "    \"50\",\n",
      "    \"100\"\n",
      "  ],\n",
      "  \"text\": \"ì‹ ì„ í•˜ê³  ë‹¬ì½¤í•œ ë¬´í™”ê³¼ì˜ ëª¨ë“ ê²ƒì„ ëŠë‚„ ìˆ˜ ìˆëŠ” í–¥\"\n",
      "}\n",
      "\n",
      "[3]\n",
      "{\n",
      "  \"id\": \"perfume_3e3c134ca8e46fac\",\n",
      "  \"brand\": \"ë”¥í‹°í¬\",\n",
      "  \"concentration\": \"ì˜¤ ë“œ ëšœì™ˆë ›\",\n",
      "  \"day_night_score\": \"day\",\n",
      "  \"gender\": \"Unisex\",\n",
      "  \"name\": \"ë¡¬ë¸Œë¥´ ë‹¨ ë¡œ ì˜¤ ë“œ ëšœì™ˆë ›\",\n",
      "  \"no\": 138.0,\n",
      "  \"season_score\": \"spring\",\n",
      "  \"sizes\": [\n",
      "    \"50\",\n",
      "    \"100\"\n",
      "  ],\n",
      "  \"text\": \"ë¹„ ì˜¤ëŠ” ë‚  ë¿Œë¦¬ê¸° ì¢‹ì€ ìŒ‰ì‹¸ë¦„í•œ ì¥ë¯¸ìí–¥\"\n",
      "}\n",
      "\n",
      "[4]\n",
      "{\n",
      "  \"id\": \"perfume_d52dc5f679a0ff96\",\n",
      "  \"brand\": \"ë”¥í‹°í¬\",\n",
      "  \"concentration\": \"ì˜¤ ë“œ ëšœì™ˆë ›\",\n",
      "  \"day_night_score\": \"day\",\n",
      "  \"gender\": \"Unisex\",\n",
      "  \"name\": \"ë„ì† ì˜¤ ë“œ ëšœì™ˆë ›\",\n",
      "  \"no\": 132.0,\n",
      "  \"season_score\": \"spring\",\n",
      "  \"sizes\": [\n",
      "    \"50\",\n",
      "    \"100\"\n",
      "  ],\n",
      "  \"text\": \"ë¯¸í’ì— ë¶ˆì–´ì˜¨ íŠœë² ë¡œì¦ˆì˜ í–¥ê¸°\"\n",
      "}\n",
      "\n",
      "[5]\n",
      "{\n",
      "  \"id\": \"perfume_4f3f344dea2a270f\",\n",
      "  \"brand\": \"ë”¥í‹°í¬\",\n",
      "  \"concentration\": \"ì˜¤ ë“œ ëšœì™ˆë ›\",\n",
      "  \"day_night_score\": \"day\",\n",
      "  \"gender\": \"Unisex\",\n",
      "  \"name\": \"ë¡œ íŒŒí”¼ì— ì˜¤ ë“œ ëšœì™ˆë ›\",\n",
      "  \"no\": 137.0,\n",
      "  \"season_score\": \"fall\",\n",
      "  \"sizes\": [\n",
      "    \"50\"\n",
      "  ],\n",
      "  \"text\": \"ë¨¸ìŠ¤í¬ì˜ ì¤‘ì‹¬ì— ë”í•´ì§„ ë‹¤ì–‘í•œ ë‹¨ë©´ë“¤ì„ ë³´ì—¬ ì£¼ëŠ” í–¥ê¸°ì˜ ë§Œë‚¨\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# pip install -U pinecone-client openai python-dotenv\n",
    "import os, json\n",
    "from typing import Dict, Any, List\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, PineconeApiException\n",
    "from openai import OpenAI\n",
    "\n",
    "# ========= 0) ENV & CLIENTS =========\n",
    "load_dotenv()\n",
    "oa = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(\"perfume-vectordb2\")\n",
    "EMBED_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "# ========= 1) FILTER BUILDER =========\n",
    "def build_pinecone_filter(filtered_json: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Pinecone ë©”íƒ€í•„í„°.\n",
    "    - sizes: ë°°ì—´/ìŠ¤ì¹¼ë¼ ëª¨ë‘ ì»¤ë²„í•˜ê¸° ìœ„í•´ $in ì‚¬ìš© ([\"50\"] í˜•íƒœ)\n",
    "    - ë‚˜ë¨¸ì§€ëŠ” $eq\n",
    "    \"\"\"\n",
    "    f: Dict[str, Any] = {}\n",
    "    if filtered_json.get(\"brand\"):\n",
    "        f[\"brand\"] = {\"$eq\": filtered_json[\"brand\"]}\n",
    "    if filtered_json.get(\"sizes\"):\n",
    "        f[\"sizes\"] = {\"$in\": [str(filtered_json[\"sizes\"])]}  # ë°°ì—´/ìŠ¤ì¹¼ë¼ ëª¨ë‘ ì•ˆì „\n",
    "    if filtered_json.get(\"season_score\"):\n",
    "        f[\"season_score\"] = {\"$eq\": filtered_json[\"season_score\"]}\n",
    "    if filtered_json.get(\"gender\"):\n",
    "        f[\"gender\"] = {\"$eq\": filtered_json[\"gender\"]}\n",
    "    if filtered_json.get(\"concentration\"):\n",
    "        f[\"concentration\"] = {\"$eq\": filtered_json[\"concentration\"]}\n",
    "    if filtered_json.get(\"day_night_score\"):\n",
    "        f[\"day_night_score\"] = {\"$eq\": filtered_json[\"day_night_score\"]}\n",
    "    return f\n",
    "\n",
    "# ========= 2) QUERY =========\n",
    "def query_pinecone(vector: List[float], filtered_json: Dict[str, Any], top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Pinecone ì¿¼ë¦¬ (ë©”íƒ€í•„í„° + ë¬¸ì„œ ë©”íƒ€ë°ì´í„° í¬í•¨).\n",
    "    í•„í„° ì˜¤ë¥˜ ì‹œ sizes í•„í„° ì œê±° í›„ ì¬ì‹œë„í•˜ê³ , ê²°ê³¼ëŠ” í´ë¼ì´ì–¸íŠ¸ì—ì„œ í›„í•„í„°ë§.\n",
    "    \"\"\"\n",
    "    primary_filter = build_pinecone_filter(filtered_json) or None\n",
    "    try:\n",
    "        return index.query(\n",
    "            vector=vector,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True,\n",
    "            filter=primary_filter\n",
    "        )\n",
    "    except PineconeApiException as e:\n",
    "        # í•„í„° ì—°ì‚°/íƒ€ì… ì´ìŠˆ ë“±ìœ¼ë¡œ 400ì´ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ sizesë§Œ ì œê±°í•˜ê³  ì¬ì‹œë„\n",
    "        if primary_filter and \"sizes\" in primary_filter:\n",
    "            fallback_filter = dict(primary_filter)\n",
    "            fallback_filter.pop(\"sizes\", None)\n",
    "            res = index.query(\n",
    "                vector=vector,\n",
    "                top_k=top_k,\n",
    "                include_metadata=True,\n",
    "                filter=fallback_filter if fallback_filter else None\n",
    "            )\n",
    "            # í´ë¼ì´ì–¸íŠ¸ í›„í•„í„°: sizes ì¼ì¹˜ë§Œ ë‚¨ê¹€\n",
    "            want_size = str(filtered_json.get(\"sizes\"))\n",
    "            if want_size:\n",
    "                res[\"matches\"] = [\n",
    "                    m for m in res.get(\"matches\", [])\n",
    "                    if want_size in (m.get(\"metadata\", {}).get(\"sizes\") or [])\n",
    "                    or str(m.get(\"metadata\", {}).get(\"sizes\")) == want_size\n",
    "                ]\n",
    "            return res\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "# ========= 3) PRETTY PRINT =========\n",
    "def print_docs_only(res):\n",
    "    print(\"=== ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ ===\")\n",
    "    for i, m in enumerate(res.get(\"matches\", []), start=1):\n",
    "        meta = m.get(\"metadata\", {}) or {}\n",
    "        doc = {\"id\": m.get(\"id\")}\n",
    "        doc.update(meta)\n",
    "        print(f\"\\n[{i}]\")\n",
    "        print(json.dumps(doc, ensure_ascii=False, indent=2))\n",
    "\n",
    "# ========= 4) DEMO =========\n",
    "if __name__ == \"__main__\":\n",
    "    filtered = {\n",
    "        \"brand\": \"ë”¥í‹°í¬\",\n",
    "        \"concentration\": None,\n",
    "        \"day_night_score\": None,\n",
    "        \"gender\": None,\n",
    "        \"season_score\": None,\n",
    "        \"sizes\": \"50\"\n",
    "    }\n",
    "    query_text = \"ë”¥í‹°í¬ 50ml í–¥ìˆ˜ ìˆì–´?\"\n",
    "\n",
    "    embed = oa.embeddings.create(model=EMBED_MODEL, input=query_text)\n",
    "    vector = embed.data[0].embedding\n",
    "\n",
    "    res = query_pinecone(vector, filtered, top_k=5)\n",
    "    print_docs_only(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f831afc2",
   "metadata": {},
   "source": [
    "# LLM parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4f81b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ” ì‚¬ìš©ì ì¿¼ë¦¬: ìƒ¤ë„¬ 50ml ì—¬ì„±ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜\n",
      "\n",
      "1ï¸âƒ£ ì¿¼ë¦¬ íŒŒì‹± ì¤‘...\n",
      "íŒŒì‹± ê²°ê³¼: {\n",
      "  \"brand\": \"ìƒ¤ë„¬\",\n",
      "  \"gender\": \"ì—¬ì„±\",\n",
      "  \"sizes\": \"50\",\n",
      "  \"season_score\": null,\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": null\n",
      "}\n",
      "\n",
      "2ï¸âƒ£ ë©”íƒ€í•„í„° ì ìš© ì¤‘...\n",
      "í•„í„°ë§ ê²°ê³¼: {\n",
      "  \"brand\": \"ìƒ¤ë„¬\",\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": null,\n",
      "  \"gender\": null,\n",
      "  \"season_score\": null,\n",
      "  \"sizes\": \"50\"\n",
      "}\n",
      "\n",
      "3ï¸âƒ£ ì¿¼ë¦¬ ë²¡í„°í™” ì¤‘...\n",
      "ë²¡í„° ì°¨ì›: 1536\n",
      "\n",
      "4ï¸âƒ£ ë²¡í„° ê²€ìƒ‰ ì¤‘...\n",
      "ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: 5\n",
      "\n",
      "5ï¸âƒ£ ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...\n",
      "\n",
      "ğŸ¯ ìµœì¢… ì¶”ì²œ:\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ìƒ¤ë„¬ì˜ 50ml ì—¬ì„±ìš© í–¥ìˆ˜ë¥¼ ì°¾ê³  ê³„ì‹œêµ°ìš”. ì—¬ëŸ¬ ì˜µì…˜ì´ ìˆì§€ë§Œ, ì œê°€ ì¶”ì²œë“œë¦¬ê³  ì‹¶ì€ í–¥ìˆ˜ëŠ” **ìƒ¤ë„¬ì˜ ì˜¤ ë“œ í¼í“¸**ì…ë‹ˆë‹¤. \n",
      "\n",
      "### ì¶”ì²œ ì´ìœ \n",
      "ìƒ¤ë„¬ì€ ê³ ê¸‰ìŠ¤ëŸ¬ì›€ê³¼ ìš°ì•„í•¨ì„ ìƒì§•í•˜ëŠ” ë¸Œëœë“œë¡œ, ê·¸ë“¤ì˜ í–¥ìˆ˜ëŠ” í•­ìƒ ë›°ì–´ë‚œ í’ˆì§ˆê³¼ ë…ì°½ì„±ì„ ìë‘í•©ë‹ˆë‹¤. íŠ¹íˆ ì˜¤ ë“œ í¼í“¸ì€ ë†ë„ê°€ ë†’ì•„ í–¥ì´ ì˜¤ë˜ ì§€ì†ë˜ë©°, ê¹Šì´ ìˆëŠ” í–¥ì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ\n",
      "ì´ í–¥ìˆ˜ëŠ” ê°€ì„ì— ì˜ ì–´ìš¸ë¦¬ëŠ” ë”°ëœ»í•˜ê³  í’ë¶€í•œ í–¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ìƒ¤ë„¬ì˜ ì˜¤ ë“œ í¼í“¸ì€ í”Œë¡œëŸ´ê³¼ ìš°ë”” ë…¸íŠ¸ê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, ë¶€ë“œëŸ½ê³  ì„¸ë ¨ëœ ëŠë‚Œì„ ì¤ë‹ˆë‹¤. íŠ¹íˆ, ì—¬ì„±ìŠ¤ëŸ¬ì›€ì„ ê°•ì¡°í•˜ë©´ì„œë„ ê°•ë ¬í•œ ì¸ìƒì„ ë‚¨ê¸°ëŠ” ë§¤ë ¥ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ì í•©í•œ ìƒí™©\n",
      "ì´ í–¥ìˆ˜ëŠ” ì£¼ë¡œ ë‚®ì— ì‚¬ìš©í•˜ê¸° ì í•©í•©ë‹ˆë‹¤. ì¼ìƒì ì¸ ì™¸ì¶œì´ë‚˜ ì§ì¥, í˜¹ì€ íŠ¹ë³„í•œ ëª¨ì„ì—ì„œë„ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. ê°€ì„ì˜ ìŒ€ìŒ€í•œ ë‚ ì”¨ì™€ í•¨ê»˜í•˜ë©´ ë”ìš± ë§¤ë ¥ì ì¸ í–¥ì„ ë°œì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ê°€ê²©ëŒ€ ë° ìš©ëŸ‰ ì¡°ì–¸\n",
      "50ml ìš©ëŸ‰ì€ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸°ì— ì ë‹¹í•œ ì‚¬ì´ì¦ˆë¡œ, ê°€ê²©ëŒ€ëŠ” ë³´í†µ 10ë§Œì›ëŒ€ ì¤‘ë°˜ì—ì„œ í›„ë°˜ì— í˜•ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìƒ¤ë„¬ì˜ í–¥ìˆ˜ëŠ” í’ˆì§ˆì´ ë›°ì–´ë‚˜ê¸° ë•Œë¬¸ì—, ì´ ê°€ê²©ëŒ€ëŠ” ì¶©ë¶„íˆ ê°€ì¹˜ê°€ ìˆë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤. \n",
      "\n",
      "ì´ í–¥ìˆ˜ëŠ” ë‹¹ì‹ ì˜ ë§¤ë ¥ì„ í•œì¸µ ë” ë‹ë³´ì´ê²Œ í•´ì¤„ ê²ƒì…ë‹ˆë‹¤. í–¥ìˆ˜ êµ¬ë§¤ ì‹œ ê¼­ í…ŒìŠ¤íŠ¸í•´ë³´ì‹œê³ , ë³¸ì¸ì—ê²Œ ì˜ ì–´ìš¸ë¦¬ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ ë” ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ğŸ˜Š\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ì‚¬ìš©ì ì¿¼ë¦¬: ê²¨ìš¸ì— ì‚¬ìš©í•˜ê¸° ì¢‹ì€ ë‚¨ì„± í–¥ìˆ˜ê°€ ë­ê°€ ìˆì„ê¹Œ?\n",
      "\n",
      "1ï¸âƒ£ ì¿¼ë¦¬ íŒŒì‹± ì¤‘...\n",
      "íŒŒì‹± ê²°ê³¼: {\n",
      "  \"brand\": null,\n",
      "  \"gender\": \"ë‚¨ì„±\",\n",
      "  \"sizes\": null,\n",
      "  \"season_score\": \"ê²¨ìš¸\",\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": null\n",
      "}\n",
      "\n",
      "2ï¸âƒ£ ë©”íƒ€í•„í„° ì ìš© ì¤‘...\n",
      "í•„í„°ë§ ê²°ê³¼: {\n",
      "  \"brand\": null,\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": null,\n",
      "  \"gender\": null,\n",
      "  \"season_score\": null,\n",
      "  \"sizes\": null\n",
      "}\n",
      "\n",
      "3ï¸âƒ£ ì¿¼ë¦¬ ë²¡í„°í™” ì¤‘...\n",
      "ë²¡í„° ì°¨ì›: 1536\n",
      "\n",
      "4ï¸âƒ£ ë²¡í„° ê²€ìƒ‰ ì¤‘...\n",
      "ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: 5\n",
      "\n",
      "5ï¸âƒ£ ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...\n",
      "\n",
      "ğŸ¯ ìµœì¢… ì¶”ì²œ:\n",
      "ê²¨ìš¸ì— ì‚¬ìš©í•˜ê¸° ì¢‹ì€ ë‚¨ì„± í–¥ìˆ˜ë¡œëŠ” **ë”¥í‹°í¬**ì˜ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”! \n",
      "\n",
      "### ì¶”ì²œ ì´ìœ \n",
      "ë”¥í‹°í¬ëŠ” ê³ ê¸‰ìŠ¤ëŸ¬ìš´ í–¥ìˆ˜ë¡œ ìœ ëª…í•œ ë¸Œëœë“œì´ë©°, ê²¨ìš¸ì² ì— ì˜ ì–´ìš¸ë¦¬ëŠ” ë”°ëœ»í•˜ê³  í¬ê·¼í•œ ëŠë‚Œì„ ì£¼ëŠ” í–¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ê²¨ìš¸ì—ëŠ” ë”°ëœ»í•œ í–¥ì´ ë”ìš± ë§¤ë ¥ì ìœ¼ë¡œ ë‹¤ê°€ì˜¤ì£ .\n",
      "\n",
      "### í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ\n",
      "ë”¥í‹°í¬ì˜ í–¥ìˆ˜ëŠ” ì£¼ë¡œ ìš°ë””í•˜ê³  ìŠ¤íŒŒì´ì‹œí•œ ë…¸íŠ¸ë¥¼ í¬í•¨í•˜ê³  ìˆì–´, ì°¨ë¶„í•˜ë©´ì„œë„ ê¹Šì´ ìˆëŠ” í–¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ í–¥ìˆ˜ëŠ” ê²¨ìš¸ì˜ ì°¨ê°€ìš´ ê³µê¸° ì†ì—ì„œë„ ë”°ëœ»í•¨ì„ ëŠë‚„ ìˆ˜ ìˆê²Œ í•´ì£¼ë©°, ë¶€ë“œëŸ¬ìš´ ê°ì´‰ê³¼ í•¨ê»˜ ê°ê°ì ì¸ ë§¤ë ¥ì„ ë”í•´ì¤ë‹ˆë‹¤.\n",
      "\n",
      "### ì í•©í•œ ìƒí™©\n",
      "ì´ í–¥ìˆ˜ëŠ” ì£¼ë¡œ ë‚®ì— ì‚¬ìš©í•˜ê¸° ì í•©í•˜ë©°, ì¼ìƒì ì¸ ì™¸ì¶œì´ë‚˜ íŠ¹ë³„í•œ ëª¨ì„ì—ì„œë„ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. íŠ¹íˆ, ê²¨ìš¸ì² ì˜ ì‹¤ë‚´ì—ì„œ ì¹œêµ¬ë“¤ê³¼ì˜ ë§Œë‚¨ì´ë‚˜ ë°ì´íŠ¸ì— ì í•©í•œ ì„ íƒì´ ë  ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "### ê°€ê²©ëŒ€ ë° ìš©ëŸ‰\n",
      "ë”¥í‹°í¬ì˜ í–¥ìˆ˜ëŠ” 100ml ìš©ëŸ‰ìœ¼ë¡œ ì œê³µë˜ë©°, ê°€ê²©ëŒ€ëŠ” ë‹¤ì†Œ ë†’ì€ í¸ì´ì§€ë§Œ, ê·¸ë§Œí¼ í’ˆì§ˆì´ ë›°ì–´ë‚˜ê³  ì˜¤ëœ ì‹œê°„ ì§€ì†ë˜ëŠ” í–¥ì„ ì œê³µí•©ë‹ˆë‹¤. íˆ¬ìí•  ê°€ì¹˜ê°€ ì¶©ë¶„íˆ ìˆëŠ” ì œí’ˆì´ë‹ˆ, ê²¨ìš¸ì² ì— ì˜ ì–´ìš¸ë¦¬ëŠ” í–¥ìˆ˜ë¥¼ ì°¾ê³  ê³„ì‹ ë‹¤ë©´ ê³ ë ¤í•´ë³´ì„¸ìš”!\n",
      "\n",
      "ì´ í–¥ìˆ˜ë¡œ ë”°ëœ»í•˜ê³  ë§¤ë ¥ì ì¸ ê²¨ìš¸ì„ ë³´ë‚´ì‹œê¸¸ ë°”ëë‹ˆë‹¤!\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ì‚¬ìš©ì ì¿¼ë¦¬: ë””ì˜¬ì—ì„œ ë‚˜ì˜¨ í¼í“¸ ì¤‘ì— 30mlì§œë¦¬ë¡œ ì¶”ì²œí•´ì¤˜\n",
      "\n",
      "1ï¸âƒ£ ì¿¼ë¦¬ íŒŒì‹± ì¤‘...\n",
      "íŒŒì‹± ê²°ê³¼: {\n",
      "  \"brand\": \"ë””ì˜¬\",\n",
      "  \"gender\": null,\n",
      "  \"sizes\": \"30\",\n",
      "  \"season_score\": null,\n",
      "  \"concentration\": \"í¼í“¸\",\n",
      "  \"day_night_score\": null\n",
      "}\n",
      "\n",
      "2ï¸âƒ£ ë©”íƒ€í•„í„° ì ìš© ì¤‘...\n",
      "í•„í„°ë§ ê²°ê³¼: {\n",
      "  \"brand\": \"ë””ì˜¬\",\n",
      "  \"concentration\": \"í¼í“¸\",\n",
      "  \"day_night_score\": null,\n",
      "  \"gender\": null,\n",
      "  \"season_score\": null,\n",
      "  \"sizes\": \"30\"\n",
      "}\n",
      "\n",
      "3ï¸âƒ£ ì¿¼ë¦¬ ë²¡í„°í™” ì¤‘...\n",
      "ë²¡í„° ì°¨ì›: 1536\n",
      "\n",
      "4ï¸âƒ£ ë²¡í„° ê²€ìƒ‰ ì¤‘...\n",
      "ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: 0\n",
      "\n",
      "5ï¸âƒ£ ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...\n",
      "\n",
      "ğŸ¯ ìµœì¢… ì¶”ì²œ:\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ë””ì˜¬ì˜ 30ml í¼í“¸ ì¤‘ì—ì„œ ì¶”ì²œí•´ë“œë¦´ ìˆ˜ ìˆëŠ” ì œí’ˆì€ **ë””ì˜¬ ìŸˆë„ë¥´ (Dior J'adore)**ì…ë‹ˆë‹¤. ì´ í–¥ìˆ˜ëŠ” ì •ë§ ë§ì€ ì‚¬ë‘ì„ ë°›ê³  ìˆëŠ” í´ë˜ì‹í•œ í–¥ìˆ˜ë¡œ, ì—¬ëŸ¬ ìƒí™©ì—ì„œ í™œìš©í•˜ê¸° ì¢‹ë‹µë‹ˆë‹¤.\n",
      "\n",
      "1. **ì™œ ì´ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•˜ëŠ”ì§€**: ë””ì˜¬ ìŸˆë„ë¥´ëŠ” ìš°ì•„í•¨ê³¼ ì—¬ì„±ìŠ¤ëŸ¬ì›€ì„ ë™ì‹œì— ëŠë‚„ ìˆ˜ ìˆëŠ” í–¥ìˆ˜ë¡œ, ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ ì‚¬ë‘ë°›ëŠ” ì•„ì´í…œì´ì—ìš”. íŠ¹íˆ, ë‹¤ì–‘í•œ ì—°ë ¹ëŒ€ì˜ ì—¬ì„±ë“¤ì´ ì‚¬ìš©í•˜ê¸°ì— ì í•©í•œ í–¥ì´ì£ .\n",
      "\n",
      "2. **í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ**: ìŸˆë„ë¥´ëŠ” í”Œë¡œëŸ´ ê³„ì—´ì˜ í–¥ìˆ˜ë¡œ, ììŠ¤ë¯¼, ë¡œì¦ˆ, ì¼ë‘ì¼ë‘ ë“±ì˜ ê½ƒí–¥ê¸°ê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, ìƒí¼í•œ ë² ë¥´ê°€ëª»ê³¼ ë³µìˆ­ì•„ì˜ ê³¼ì¼ í–¥ì´ ë”í•´ì ¸ ë¶€ë“œëŸ½ê³  ì„¸ë ¨ëœ ëŠë‚Œì„ ì¤ë‹ˆë‹¤. ì´ í–¥ìˆ˜ëŠ” ë§ˆì¹˜ ê½ƒë°­ì— ì„œ ìˆëŠ” ë“¯í•œ ê¸°ë¶„ì„ ì„ ì‚¬í•˜ë©°, ë”°ëœ»í•˜ê³  ë§¤í˜¹ì ì¸ ì”í–¥ì´ íŠ¹ì§•ì´ì—ìš”.\n",
      "\n",
      "3. **ì–´ë–¤ ìƒí™©ì— ì í•©í•œì§€**: ìŸˆë„ë¥´ëŠ” ë°ì¼ë¦¬ë¡œ ì‚¬ìš©í•˜ê¸°ì—ë„ ì¢‹ê³ , íŠ¹ë³„í•œ ë‚ ì´ë‚˜ ì €ë… ì™¸ì¶œ ì‹œì—ë„ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. ì¹œêµ¬ë“¤ê³¼ì˜ ëª¨ì„ì´ë‚˜ ë°ì´íŠ¸, í˜¹ì€ ì¤‘ìš”í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¯¸íŒ…ì—ì„œë„ ìì‹ ê°ì„ ì£¼ëŠ” í–¥ì´ì£ .\n",
      "\n",
      "4. **ê°€ê²©ëŒ€ë‚˜ ìš©ëŸ‰ ê´€ë ¨ ì¡°ì–¸**: 30ml ìš©ëŸ‰ì€ ì—¬í–‰ì´ë‚˜ ì™¸ì¶œ ì‹œ íœ´ëŒ€í•˜ê¸°ì—ë„ ì ë‹¹í•˜ê³ , ê°€ê²©ëŒ€ëŠ” ëŒ€ëµ 80,000ì›ì—ì„œ 120,000ì› ì‚¬ì´ë¡œ í˜•ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì²˜ìŒ ì‚¬ìš©í•´ë³´ì‹œëŠ” ë¶„ë“¤ì—ê²ŒëŠ” 30mlê°€ ì ë‹¹í•œ ì„ íƒì´ ë  ê²ƒ ê°™ì•„ìš”.\n",
      "\n",
      "ë””ì˜¬ ìŸˆë„ë¥´ë¡œ íŠ¹ë³„í•œ ìˆœê°„ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ğŸ˜Š\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ì‚¬ìš©ì ì¿¼ë¦¬: ë°¤ì— ì‚¬ìš©í•˜ê¸° ì¢‹ì€ ìœ ë‹ˆì„¹ìŠ¤ í–¥ìˆ˜ ì°¾ê³  ìˆì–´\n",
      "\n",
      "1ï¸âƒ£ ì¿¼ë¦¬ íŒŒì‹± ì¤‘...\n",
      "íŒŒì‹± ê²°ê³¼: {\n",
      "  \"brand\": null,\n",
      "  \"gender\": \"ìœ ë‹ˆì„¹ìŠ¤\",\n",
      "  \"sizes\": null,\n",
      "  \"season_score\": null,\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": \"ì•¼ê°„\"\n",
      "}\n",
      "\n",
      "2ï¸âƒ£ ë©”íƒ€í•„í„° ì ìš© ì¤‘...\n",
      "í•„í„°ë§ ê²°ê³¼: {\n",
      "  \"brand\": null,\n",
      "  \"concentration\": null,\n",
      "  \"day_night_score\": null,\n",
      "  \"gender\": null,\n",
      "  \"season_score\": null,\n",
      "  \"sizes\": null\n",
      "}\n",
      "\n",
      "3ï¸âƒ£ ì¿¼ë¦¬ ë²¡í„°í™” ì¤‘...\n",
      "ë²¡í„° ì°¨ì›: 1536\n",
      "\n",
      "4ï¸âƒ£ ë²¡í„° ê²€ìƒ‰ ì¤‘...\n",
      "ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: 5\n",
      "\n",
      "5ï¸âƒ£ ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...\n",
      "\n",
      "ğŸ¯ ìµœì¢… ì¶”ì²œ:\n",
      "ë°¤ì— ì‚¬ìš©í•˜ê¸° ì¢‹ì€ ìœ ë‹ˆì„¹ìŠ¤ í–¥ìˆ˜ë¥¼ ì°¾ê³  ê³„ì‹œêµ°ìš”! ì œê°€ ì¶”ì²œë“œë¦´ í–¥ìˆ˜ëŠ” **ì´ì†**ì˜ ì˜¤ ë“œ í¼í“¸ì…ë‹ˆë‹¤. \n",
      "\n",
      "### ì¶”ì²œ ì´ìœ \n",
      "ì´ì†ì€ ìì—°ì—ì„œ ì˜ê°ì„ ë°›ì€ ê³ ê¸‰ìŠ¤ëŸ¬ìš´ í–¥ìˆ˜ë¡œ ìœ ëª…í•œ ë¸Œëœë“œì…ë‹ˆë‹¤. íŠ¹íˆ ì´ í–¥ìˆ˜ëŠ” ìœ ë‹ˆì„¹ìŠ¤ ì œí’ˆìœ¼ë¡œ, ë‚¨ë…€ ëª¨ë‘ì—ê²Œ ì˜ ì–´ìš¸ë¦¬ëŠ” ë§¤ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "### í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ\n",
      "ì´ í–¥ìˆ˜ëŠ” ê°€ì„ì— ì˜ ì–´ìš¸ë¦¬ëŠ” ë”°ëœ»í•˜ê³  ê¹Šì´ ìˆëŠ” í–¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ìì—°ì˜ ì›ë£Œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶€ë“œëŸ½ê³  ì„¸ë ¨ëœ ëŠë‚Œì„ ì£¼ë©°, ë°¤ì— ì‚¬ìš©í•˜ê¸°ì— ì í•©í•œ ì‹ ë¹„ë¡œìš´ ë§¤ë ¥ì„ ë°œì‚°í•©ë‹ˆë‹¤. \n",
      "\n",
      "### ì í•©í•œ ìƒí™©\n",
      "ì´ í–¥ìˆ˜ëŠ” íŠ¹ë³„í•œ ì €ë… ì™¸ì¶œì´ë‚˜ ë°ì´íŠ¸, í˜¹ì€ ì¹œêµ¬ë“¤ê³¼ì˜ ëª¨ì„ ë“± ë‹¤ì–‘í•œ ë°¤ ì‹œê°„ëŒ€ì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. ë˜í•œ, ì°¨ë¶„í•œ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•˜ê³  ì‹¶ì„ ë•Œë„ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ê°€ê²©ëŒ€ ë° ìš©ëŸ‰\n",
      "ì´ì†ì˜ ì˜¤ ë“œ í¼í“¸ì€ 50ml ìš©ëŸ‰ìœ¼ë¡œ ì œê³µë˜ë©°, ì¼ë°˜ì ìœ¼ë¡œ ì¤‘ê°„ ê°€ê²©ëŒ€ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤. ê³ ê¸‰ìŠ¤ëŸ¬ìš´ í–¥ì„ ê²½í—˜í•˜ë©´ì„œë„ í•©ë¦¬ì ì¸ ê°€ê²©ìœ¼ë¡œ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ì ì´ ë§¤ë ¥ì ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ í–¥ìˆ˜ë¡œ ë©‹ì§„ ë°¤ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, json, re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# LLM ë° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Pinecone ì´ˆê¸°í™”\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(\"perfume-vectordb2\")\n",
    "\n",
    "# ========== LLM íŒŒì„œ ==========\n",
    "parse_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë„ˆëŠ” í–¥ìˆ˜ ì¿¼ë¦¬ íŒŒì„œì•¼.\n",
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜:\n",
    "- brand: ë¸Œëœë“œëª… (ì˜ˆ: ìƒ¤ë„¬, ë””ì˜¬, ì…ìƒë¡œë‘ ë“±)\n",
    "- concentration: (í¼í“¸, ì½”ë¡± ë“±)\n",
    "- day_night_score: ì‚¬ìš©ì‹œê°„ (ì£¼ê°„, ì•¼ê°„, ë°ì¼ë¦¬ ë“±)\n",
    "- gender: ì„±ë³„ (ë‚¨ì„±, ì—¬ì„±, ìœ ë‹ˆì„¹ìŠ¤)\n",
    "- season_score: ê³„ì ˆ (ë´„, ì—¬ë¦„, ê°€ì„, ê²¨ìš¸)\n",
    "- sizes: ìš©ëŸ‰ (30ml, 50ml, 100ml ë“±) ë‹¨ìœ„ëŠ” ë¬´ì‹œí•˜ê³  ìˆ«ìë§Œ\n",
    "\n",
    "ì—†ëŠ” ê°’ì€ nullë¡œ ë‘ê³ , ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì¤˜.\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "{{\"brand\": \"ìƒ¤ë„¬\", \"gender\": null, \"sizes\": \"50\", \"season_score\": null, \"concentration\": null, \"day_night_score\": null}}\"\"\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "def run_llm_parser(query: str):\n",
    "    \"\"\"ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±\"\"\"\n",
    "    try:\n",
    "        chain = parse_prompt | llm\n",
    "        ai_response = chain.invoke({\"query\": query})\n",
    "        response_text = ai_response.content.strip()\n",
    "\n",
    "        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "        if \"```json\" in response_text:\n",
    "            response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in response_text:\n",
    "            response_text = response_text.split(\"```\")[1].strip()\n",
    "\n",
    "        parsed = json.loads(response_text)\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"íŒŒì‹± ì˜¤ë¥˜: {str(e)}\"}\n",
    "\n",
    "# ========== ë©”íƒ€í•„í„° í•¨ìˆ˜ë“¤ ==========\n",
    "def filter_brand(brand_value):\n",
    "    valid_brands = [\n",
    "        'ê²”ë‘', 'êµ¬ì°Œ', 'ëŒë¡œì—', 'ë‚˜ë¥´ì‹œì†Œ ë¡œë“œë¦¬ê²Œì¦ˆ', 'ë‹ˆìƒ¤ë„¤', 'ë„ë¥´ì„¸', 'ë””ì˜¬', 'ë”¥í‹°í¬', 'ë‘ì½¤',\n",
    "        'ë¡œë¼ ë©”ë¥´ì‹œì—', 'ë¡œì—ë² ', 'ë¡ì‹œë•…', 'ë¥´ ë¼ë³´', 'ë©”ëª¨', 'ë©”ì¢… ë§ˆë¥´ì§€ì—˜ë¼', 'ë©”ì¢… í”„ë€ì‹œìŠ¤ ì»¤ì •',\n",
    "        'ë©œë¦°ì•¤ê²Œì¸ ', 'ë¯¸ìš°ë¯¸ìš°', 'ë°”ì´ë ˆë„', 'ë°˜í´ë¦¬í”„ ì•„í ', 'ë²„ë²„ë¦¬', 'ë² ë¥´ì‚¬ì²´', 'ë¶ˆê°€ë¦¬', 'ë¹„ë””ì¼€ì´',\n",
    "        'ì‚°íƒ€ ë§ˆë¦¬ì•„ ë…¸ë²¨ë¼', 'ìƒ¤ë„¬', 'ì„¸ë¥´ì£¼ ë£¨í…', 'ì‹œìŠ¬ë¦¬ ì½”ìŠ¤ë©”í‹±', 'ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ', 'ì—ë”° ë¦¬ë¸Œë¥´ ë„ëŸ‰ì¥¬',\n",
    "        'ì—ë¥´ë©”ìŠ¤', 'ì—ìŠ¤í‹° ë¡œë”', 'ì—‘ìŠ¤ ë‹ˆíë¡œ', 'ì´ë‹ˆì‹œì˜¤ í¼í“¸', 'ì´ì†', 'ì…ìƒë¡œë‘', 'ì œë¥´ì¡°í”„', 'ì¡° ë§ë¡ ',\n",
    "        'ì¡°ë¥´ì§€ì˜¤ ì•„ë¥´ë§ˆë‹ˆ', 'ì¤„ë¦¬ì—£ í—¤ì¦ˆ ì–´ ê±´', 'ì§€ë°©ì‹œ', 'ì§ˆ ìŠ¤íŠœì–´íŠ¸', 'í¬ë¦¬ë“œ', 'í‚¬ë¦¬ì•ˆ', 'í†° í¬ë“œ',\n",
    "        'í‹°íŒŒë‹ˆì•¤ì½”', 'í¼í“¸ ë“œ ë§ë¦¬', 'íœí• ë¦¬ê³¤ìŠ¤', 'í”„ë¼ë‹¤', 'í”„ë ˆë°ë¦­ ë§'\n",
    "    ]\n",
    "    if brand_value is None:\n",
    "        return None\n",
    "    return brand_value if brand_value in valid_brands else None\n",
    "\n",
    "def filter_concentration(concentration_value):\n",
    "    valid_concentrations = ['ì†”ë¦¬ë“œ í¼í“¸', 'ì—‘ìŠ¤íŠ¸ë ˆ ë“œ í¼í“¸', 'ì˜¤ ë“œ ëšœì™ˆë ›', 'ì˜¤ ë“œ ì½”ë¡±', 'ì˜¤ ë“œ í¼í“¸', 'í¼í“¸']\n",
    "    if concentration_value is None:\n",
    "        return None\n",
    "    return concentration_value if concentration_value in valid_concentrations else None\n",
    "\n",
    "def filter_day_night_score(day_night_value):\n",
    "    valid_day_night = [\"day\", \"night\"]\n",
    "    if day_night_value is None:\n",
    "        return None\n",
    "    if isinstance(day_night_value, str) and ',' in day_night_value:\n",
    "        values = [v.strip() for v in day_night_value.split(',')]\n",
    "        filtered_values = [v for v in values if v in valid_day_night]\n",
    "        return ','.join(filtered_values) if filtered_values else None\n",
    "    return day_night_value if day_night_value in valid_day_night else None\n",
    "\n",
    "def filter_gender(gender_value):\n",
    "    valid_genders = ['Female', 'Male', 'Unisex', 'unisex ']\n",
    "    if gender_value is None:\n",
    "        return None\n",
    "    return gender_value if gender_value in valid_genders else None\n",
    "\n",
    "def filter_season_score(season_value):\n",
    "    valid_seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "    if season_value is None:\n",
    "        return None\n",
    "    return season_value if season_value in valid_seasons else None\n",
    "\n",
    "def filter_sizes(sizes_value):\n",
    "    \"\"\"ìˆ«ìë§Œ ì¶”ì¶œí•´ì„œ ìœ íš¨ê°’ì¸ì§€ í™•ì¸\"\"\"\n",
    "    valid_sizes = ['30', '50', '75', '100', '150']\n",
    "    if sizes_value is None:\n",
    "        return None\n",
    "    if isinstance(sizes_value, str):\n",
    "        numbers = re.findall(r'\\d+', sizes_value)\n",
    "        for num in numbers:\n",
    "            if num in valid_sizes:\n",
    "                return num\n",
    "    return str(sizes_value) if str(sizes_value) in valid_sizes else None\n",
    "\n",
    "def apply_meta_filters(parsed_json: dict) -> dict:\n",
    "    \"\"\"íŒŒì‹±ëœ JSONì— ë©”íƒ€í•„í„°ë§ ì ìš©\"\"\"\n",
    "    if not parsed_json or \"error\" in parsed_json:\n",
    "        return parsed_json\n",
    "    \n",
    "    return {\n",
    "        'brand': filter_brand(parsed_json.get('brand')),\n",
    "        'concentration': filter_concentration(parsed_json.get('concentration')),\n",
    "        'day_night_score': filter_day_night_score(parsed_json.get('day_night_score')),\n",
    "        'gender': filter_gender(parsed_json.get('gender')),\n",
    "        'season_score': filter_season_score(parsed_json.get('season_score')),\n",
    "        'sizes': filter_sizes(parsed_json.get('sizes'))\n",
    "    }\n",
    "\n",
    "# ========== Pinecone ê²€ìƒ‰ í•¨ìˆ˜ë“¤ ==========\n",
    "def build_pinecone_filter(filtered_json: dict) -> dict:\n",
    "    \"\"\"ë©”íƒ€í•„í„°ë§ ê²°ê³¼ë¥¼ Pinecone filter dictë¡œ ë³€í™˜\"\"\"\n",
    "    pinecone_filter = {}\n",
    "    if filtered_json.get(\"brand\"):\n",
    "        pinecone_filter[\"brand\"] = {\"$eq\": filtered_json[\"brand\"]}\n",
    "    if filtered_json.get(\"sizes\"):\n",
    "        pinecone_filter[\"sizes\"] = {\"$eq\": filtered_json[\"sizes\"]}\n",
    "    if filtered_json.get(\"season_score\"):\n",
    "        pinecone_filter[\"season_score\"] = {\"$eq\": filtered_json[\"season_score\"]}\n",
    "    if filtered_json.get(\"gender\"):\n",
    "        pinecone_filter[\"gender\"] = {\"$eq\": filtered_json[\"gender\"]}\n",
    "    if filtered_json.get(\"concentration\"):\n",
    "        pinecone_filter[\"concentration\"] = {\"$eq\": filtered_json[\"concentration\"]}\n",
    "    if filtered_json.get(\"day_night_score\"):\n",
    "        pinecone_filter[\"day_night_score\"] = {\"$eq\": filtered_json[\"day_night_score\"]}\n",
    "    return pinecone_filter\n",
    "\n",
    "def query_pinecone(vector, filtered_json: dict, top_k: int = 5):\n",
    "    \"\"\"Pinecone ë²¡í„° ê²€ìƒ‰ + ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©\"\"\"\n",
    "    pinecone_filter = build_pinecone_filter(filtered_json)\n",
    "    \n",
    "    result = index.query(\n",
    "        vector=vector,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        filter=pinecone_filter if pinecone_filter else None\n",
    "    )\n",
    "    return result\n",
    "\n",
    "# ========== RAG ì‘ë‹µ ìƒì„± ==========\n",
    "response_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë„ˆëŠ” í–¥ìˆ˜ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì¶”ì²œì„ í•´ì¤˜.\n",
    "\n",
    "ì¶”ì²œí•  ë•Œ ë‹¤ìŒì„ í¬í•¨í•´ì¤˜:\n",
    "1. ì™œ ì´ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•˜ëŠ”ì§€\n",
    "2. í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ\n",
    "3. ì–´ë–¤ ìƒí™©ì— ì í•©í•œì§€\n",
    "4. ê°€ê²©ëŒ€ë‚˜ ìš©ëŸ‰ ê´€ë ¨ ì¡°ì–¸ (ìˆë‹¤ë©´)\n",
    "\n",
    "ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.\"\"\"),\n",
    "    (\"user\", \"\"\"ì‚¬ìš©ì ì§ˆë¬¸: {original_query}\n",
    "\n",
    "ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´:\n",
    "{search_results}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì¤˜.\"\"\")\n",
    "])\n",
    "\n",
    "def format_search_results(pinecone_results):\n",
    "    \"\"\"Pinecone ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…\"\"\"\n",
    "    if not pinecone_results or not pinecone_results.get('matches'):\n",
    "        return \"ê²€ìƒ‰ëœ í–¥ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    formatted_results = []\n",
    "    for i, match in enumerate(pinecone_results['matches'], 1):\n",
    "        metadata = match.get('metadata', {})\n",
    "        score = match.get('score', 0)\n",
    "        \n",
    "        result_text = f\"\"\"\n",
    "{i}. í–¥ìˆ˜ëª…: {metadata.get('perfume_name', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ë¸Œëœë“œ: {metadata.get('brand', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ì„±ë³„: {metadata.get('gender', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ìš©ëŸ‰: {metadata.get('sizes', 'ì •ë³´ì—†ìŒ')}ml\n",
    "   - ê³„ì ˆ: {metadata.get('season_score', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ì‚¬ìš©ì‹œê°„: {metadata.get('day_night_score', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ë†ë„: {metadata.get('concentration', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ìœ ì‚¬ë„ ì ìˆ˜: {score:.3f}\n",
    "\"\"\"\n",
    "        formatted_results.append(result_text.strip())\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "def generate_response(original_query: str, search_results):\n",
    "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„±\"\"\"\n",
    "    try:\n",
    "        formatted_results = format_search_results(search_results)\n",
    "        \n",
    "        chain = response_prompt | llm\n",
    "        response = chain.invoke({\n",
    "            \"original_query\": original_query,\n",
    "            \"search_results\": formatted_results\n",
    "        })\n",
    "        \n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "# ========== í†µí•© RAG íŒŒì´í”„ë¼ì¸ ==========\n",
    "def perfume_rag_pipeline(user_query: str, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    ì™„ì „í•œ í–¥ìˆ˜ ì¶”ì²œ RAG íŒŒì´í”„ë¼ì¸\n",
    "    \n",
    "    Args:\n",
    "        user_query (str): ì‚¬ìš©ì ì§ˆë¬¸\n",
    "        top_k (int): ë°˜í™˜í•  í–¥ìˆ˜ ê°œìˆ˜\n",
    "    \n",
    "    Returns:\n",
    "        dict: ë‹¨ê³„ë³„ ê²°ê³¼ì™€ ìµœì¢… ì¶”ì²œ\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” ì‚¬ìš©ì ì¿¼ë¦¬: {user_query}\")\n",
    "    \n",
    "    # 1ë‹¨ê³„: LLMìœ¼ë¡œ ì¿¼ë¦¬ íŒŒì‹±\n",
    "    print(\"\\n1ï¸âƒ£ ì¿¼ë¦¬ íŒŒì‹± ì¤‘...\")\n",
    "    parsed_json = run_llm_parser(user_query)\n",
    "    print(f\"íŒŒì‹± ê²°ê³¼: {json.dumps(parsed_json, ensure_ascii=False, indent=2)}\")\n",
    "    \n",
    "    if \"error\" in parsed_json:\n",
    "        return {\n",
    "            \"error\": \"ì¿¼ë¦¬ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\",\n",
    "            \"details\": parsed_json\n",
    "        }\n",
    "    \n",
    "    # 2ë‹¨ê³„: ë©”íƒ€í•„í„° ì ìš©\n",
    "    print(\"\\n2ï¸âƒ£ ë©”íƒ€í•„í„° ì ìš© ì¤‘...\")\n",
    "    filtered_json = apply_meta_filters(parsed_json)\n",
    "    print(f\"í•„í„°ë§ ê²°ê³¼: {json.dumps(filtered_json, ensure_ascii=False, indent=2)}\")\n",
    "    \n",
    "    # 3ë‹¨ê³„: ì¿¼ë¦¬ ë²¡í„°í™”\n",
    "    print(\"\\n3ï¸âƒ£ ì¿¼ë¦¬ ë²¡í„°í™” ì¤‘...\")\n",
    "    try:\n",
    "        query_vector = embeddings.embed_query(user_query)\n",
    "        print(f\"ë²¡í„° ì°¨ì›: {len(query_vector)}\")\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": \"ì¿¼ë¦¬ ë²¡í„°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\",\n",
    "            \"details\": str(e)\n",
    "        }\n",
    "    \n",
    "    # 4ë‹¨ê³„: Pinecone ê²€ìƒ‰\n",
    "    print(\"\\n4ï¸âƒ£ ë²¡í„° ê²€ìƒ‰ ì¤‘...\")\n",
    "    try:\n",
    "        search_results = query_pinecone(query_vector, filtered_json, top_k)\n",
    "        print(f\"ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: {len(search_results.get('matches', []))}\")\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": \"ë²¡í„° ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\",\n",
    "            \"details\": str(e)\n",
    "        }\n",
    "    \n",
    "    # 5ë‹¨ê³„: ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "    print(\"\\n5ï¸âƒ£ ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...\")\n",
    "    final_response = generate_response(user_query, search_results)\n",
    "    \n",
    "    return {\n",
    "        \"original_query\": user_query,\n",
    "        \"parsed_query\": parsed_json,\n",
    "        \"filtered_query\": filtered_json,\n",
    "        \"search_results\": search_results,\n",
    "        \"recommendation\": final_response,\n",
    "        \"status\": \"success\"\n",
    "    }\n",
    "\n",
    "# ========== ì‚¬ìš© ì˜ˆì œ ==========\n",
    "if __name__ == \"__main__\":\n",
    "    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤\n",
    "    test_queries = [\n",
    "        \"ìƒ¤ë„¬ 50ml ì—¬ì„±ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜\",\n",
    "        \"ê²¨ìš¸ì— ì‚¬ìš©í•˜ê¸° ì¢‹ì€ ë‚¨ì„± í–¥ìˆ˜ê°€ ë­ê°€ ìˆì„ê¹Œ?\",\n",
    "        \"ë””ì˜¬ì—ì„œ ë‚˜ì˜¨ í¼í“¸ ì¤‘ì— 30mlì§œë¦¬ë¡œ ì¶”ì²œí•´ì¤˜\",\n",
    "        \"ë°¤ì— ì‚¬ìš©í•˜ê¸° ì¢‹ì€ ìœ ë‹ˆì„¹ìŠ¤ í–¥ìˆ˜ ì°¾ê³  ìˆì–´\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(\"=\"*80)\n",
    "        result = perfume_rag_pipeline(query)\n",
    "        \n",
    "        if result.get(\"status\") == \"success\":\n",
    "            print(f\"\\nğŸ¯ ìµœì¢… ì¶”ì²œ:\\n{result['recommendation']}\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ ì˜¤ë¥˜: {result.get('error')}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# ========== ê°„ë‹¨í•œ ì‹¤í–‰ í•¨ìˆ˜ ==========\n",
    "def ask_perfume(query: str):\n",
    "    \"\"\"ê°„ë‹¨í•œ í–¥ìˆ˜ ê²€ìƒ‰ í•¨ìˆ˜ - DB ê²°ê³¼ë§Œ ë°˜í™˜\"\"\"\n",
    "    result = perfume_rag_pipeline(query)\n",
    "    if result.get(\"status\") == \"success\":\n",
    "        return result[\"formatted_results\"]\n",
    "    else:\n",
    "        return f\"ì£„ì†¡í•©ë‹ˆë‹¤. {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain langgraph langchain-openai tiktoken\n",
    "import os, json\n",
    "from typing import TypedDict, List, Optional, Dict, Any\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "# ---------- 0) Config ----------\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", \"PUT_YOUR_KEY_HERE\")  # or set in env\n",
    "MODEL_NAME = \"gpt-4o-mini\"  # keep it small & fast for routing\n",
    "\n",
    "SUPERVISOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are the â€œPerfume Recommendation Supervisor (Router)â€. Analyze the userâ€™s query (Korean or English) and route to exactly ONE agent below.\n",
    "\n",
    "[Agents]\n",
    "- LLM_parser         : Parses/normalizes multi-facet queries (2+ product facets).\n",
    "- FAQ_agent          : Perfume knowledge / definitions / differences / general questions.\n",
    "- human_fallback     : Non-perfume or off-topic queries.\n",
    "- price_agent        : Price-only intents (cheapest, price, buy, discount, etc.).\n",
    "- ML_agent           : Single-preference recommendations (mood/season vibe like â€œfresh summerâ€, â€œsweetâ€, etc.).\n",
    "\n",
    "[Facets to detect (â€œproduct facetsâ€)]\n",
    "- brand            (e.g., Chanel, Dior, Creed)\n",
    "- season           (spring/summer/fall/winter; â€œfor summer/winterâ€)\n",
    "- gender           (male/female/unisex)\n",
    "- sizes            (volume in ml: 30/50/100 ml)\n",
    "- day_night_score  (day/night/daily/office/club, etc.)\n",
    "- concentration    (EDT/EDP/Extrait/Parfum/Cologne)\n",
    "\n",
    "[Price intent keywords (not exhaustive)]\n",
    "- Korean: ê°€ê²©, ìµœì €ê°€, ì–¼ë§ˆ, ê°€ê²©ëŒ€, êµ¬ë§¤, íŒë§¤, í• ì¸, ì–´ë””ì„œ ì‚¬, ë°°ì†¡ë¹„\n",
    "- English: price, cost, cheapest, buy, purchase, discount\n",
    "\n",
    "[FAQ examples]\n",
    "- Differences between EDP vs EDT, note definitions, longevity/projection, brand/line info.\n",
    "\n",
    "[Single-preference (ML_agent) examples]\n",
    "- â€œRecommend a cool perfume for summerâ€, â€œRecommend a sweet scentâ€, â€œOne citrusy fresh pickâ€\n",
    "  (= 0â€“1 of the above facets mentioned; primarily taste/mood/situation).\n",
    "\n",
    "[Routing rules (priority)]\n",
    "1) Non-perfume / off-topic â†’ human_fallback\n",
    "2) Clear price-only intent (even if one facet is present as context) â†’ price_agent\n",
    "   e.g., â€œChanel No. 5 50ml cheapest price?â€ â†’ price_agent\n",
    "3) Count product facets in the query:\n",
    "   - If facets â‰¥ 2 â†’ LLM_parser\n",
    "4) Otherwise (single-topic queries):\n",
    "   - Perfume knowledge/definitions â†’ FAQ_agent\n",
    "   - Single taste/mood recommendation â†’ ML_agent\n",
    "5) Tie-breakers:\n",
    "   - If price intent is clear â†’ price_agent\n",
    "   - If facets â‰¥ 2 â†’ LLM_parser\n",
    "   - Else: knowledge â†’ FAQ_agent, taste â†’ ML_agent\n",
    "\n",
    "[Output format]\n",
    "Return ONLY this JSON (no extra text):\n",
    "{{\n",
    "  \"next\": \"<LLM_parser|FAQ_agent|human_fallback|price_agent|ML_agent>\",\n",
    "  \"reason\": \"<one short English sentence>\",\n",
    "  \"facet_count\": <integer>,\n",
    "  \"facets\": {{\n",
    "    \"brand\": \"<value or null>\",\n",
    "    \"season\": \"<value or null>\",\n",
    "    \"gender\": \"<value or null>\",\n",
    "    \"sizes\": \"<value or null>\",\n",
    "    \"day_night_score\": \"<value or null>\",\n",
    "    \"concentration\": \"<value or null>\"\n",
    "  }},\n",
    "  \"scent_vibe\": \"<value if detected, else null>\",\n",
    "  \"query_intent\": \"<price|faq|scent_pref|non_perfume|other>\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "# ---------- 1) State ----------\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]           # conversation log\n",
    "    next: Optional[str]                   # routing decision key\n",
    "    router_json: Optional[Dict[str, Any]] # parsed JSON from router\n",
    "\n",
    "# ---------- 2) LLM (Supervisor) ----------\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SUPERVISOR_SYSTEM_PROMPT),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Call the router LLM and return parsed JSON + routing target.\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    chain = router_prompt | llm\n",
    "    ai = chain.invoke({\"query\": user_query})\n",
    "    text = ai.content\n",
    "\n",
    "    # JSON strict parse\n",
    "    chosen = \"human_fallback\"\n",
    "    parsed: Dict[str, Any] = {}\n",
    "    try:\n",
    "        parsed = json.loads(text)\n",
    "        maybe = parsed.get(\"next\")\n",
    "        if isinstance(maybe, str) and maybe in {\"LLM_parser\",\"FAQ_agent\",\"human_fallback\",\"price_agent\",\"ML_agent\"}:\n",
    "            chosen = maybe\n",
    "    except Exception:\n",
    "        parsed = {\"error\": \"invalid_json\", \"raw\": text}\n",
    "\n",
    "    msgs = state[\"messages\"] + [AIMessage(content=text)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": chosen,\n",
    "        \"router_json\": parsed\n",
    "    }\n",
    "\n",
    "# ---------- 3) Mock Agent Nodes (for testing) ----------\n",
    "def passthrough(name: str):\n",
    "    def _node(state: AgentState) -> AgentState:\n",
    "        payload = state.get(\"router_json\") or {}\n",
    "        summary = f\"[{name}] handled. reason={payload.get('reason')} facets={payload.get('facets')} intent={payload.get('query_intent')}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=summary)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "    return _node\n",
    "\n",
    "LLM_parser      = passthrough(\"LLM_parser\")\n",
    "FAQ_agent       = passthrough(\"FAQ_agent\")\n",
    "human_fallback  = passthrough(\"human_fallback\")\n",
    "price_agent     = passthrough(\"price_agent\")\n",
    "ML_agent        = passthrough(\"ML_agent\")\n",
    "\n",
    "# ---------- 4) Build Graph ----------\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"LLM_parser\", LLM_parser)\n",
    "graph.add_node(\"FAQ_agent\", FAQ_agent)\n",
    "graph.add_node(\"human_fallback\", human_fallback)\n",
    "graph.add_node(\"price_agent\", price_agent)\n",
    "graph.add_node(\"ML_agent\", ML_agent)\n",
    "\n",
    "graph.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Conditional routing\n",
    "def router_edge(state: AgentState) -> str:\n",
    "    return state[\"next\"] or \"human_fallback\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    router_edge,\n",
    "    {\n",
    "        \"LLM_parser\": \"LLM_parser\",\n",
    "        \"FAQ_agent\": \"FAQ_agent\",\n",
    "        \"human_fallback\": \"human_fallback\",\n",
    "        \"price_agent\": \"price_agent\",\n",
    "        \"ML_agent\": \"ML_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# End states\n",
    "for node in [\"LLM_parser\", \"FAQ_agent\", \"human_fallback\", \"price_agent\", \"ML_agent\"]:\n",
    "    graph.add_edge(node, END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# ---------- 5) Batch Test ----------\n",
    "TEST_QUERIES = [\n",
    "    \"ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\",                 \n",
    "    \"ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\",                \n",
    "    \"EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?\",                                       \n",
    "    \"íƒ‘ë…¸íŠ¸Â·ë¯¸ë“¤ë…¸íŠ¸Â·ë² ì´ìŠ¤ë…¸íŠ¸ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì´ì•¼?\",               \n",
    "    \"ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?\",                                         \n",
    "    \"ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?\",                                         \n",
    "    \"ìƒ¤ë„¬ ë„˜ë²„5 50ml ìµœì €ê°€ ì•Œë ¤ì¤˜.\",                               \n",
    "    \"ë””ì˜¬ ì†Œë°”ì¥¬ ê°€ê²© ì–¼ë§ˆì•¼? ì–´ë””ì„œ ì‚¬ëŠ” ê²Œ ì œì¼ ì‹¸?\",             \n",
    "    \"ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\",                                 \n",
    "    \"ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.\",                                         \n",
    "]\n",
    "\n",
    "def run_tests():\n",
    "    for q in TEST_QUERIES:\n",
    "        print(\"=\"*80)\n",
    "        print(\"Query:\", q)\n",
    "        init: AgentState = {\n",
    "            \"messages\": [HumanMessage(content=q)],\n",
    "            \"next\": None,\n",
    "            \"router_json\": None\n",
    "        }\n",
    "        out = app.invoke(init)\n",
    "        ai_msgs = [m for m in out[\"messages\"] if isinstance(m, AIMessage)]\n",
    "        router_raw = ai_msgs[-2].content if len(ai_msgs) >= 2 else \"(no router output)\"\n",
    "        agent_summary = ai_msgs[-1].content if ai_msgs else \"(no agent output)\"\n",
    "        print(\"Router JSON:\", router_raw)\n",
    "        print(\"Agent summary:\", agent_summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "befb7801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Query: ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\n",
      "ğŸ” LLM_parser ì‹¤í–‰: ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\n",
      "Router JSON: {\n",
      "  \"next\": \"LLM_parser\",\n",
      "  \"reason\": \"The query contains multiple facets including brand, gender, size, and season.\",\n",
      "  \"facet_count\": 4,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"ì…ìƒë¡œë‘\",\n",
      "    \"season\": \"ê²¨ìš¸\",\n",
      "    \"gender\": \"ì—¬ì„±\",\n",
      "    \"sizes\": \"50ml\",\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"other\"\n",
      "}\n",
      "Agent summary: [LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ âœ…\n",
      "\n",
      "ğŸ“Š íŒŒì‹± ê²°ê³¼: {\"brand\": \"ì…ìƒë¡œë‘\", \"gender\": \"ì—¬ì„±\", \"sizes\": \"50\", \"season_score\": \"ê²¨ìš¸\", \"concentration\": null, \"day_night_score\": null}\n",
      "ğŸ” í•„í„°ë§ ê²°ê³¼: {\"brand\": \"ì…ìƒë¡œë‘\", \"concentration\": null, \"day_night_score\": null, \"gender\": null, \"season_score\": null, \"sizes\": \"50\"}\n",
      "ğŸ¯ ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: 5\n",
      "\n",
      "ğŸ’¬ ì¶”ì²œ ê²°ê³¼:\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ê²¨ìš¸ì— ì‚¬ìš©í•  ì…ìƒë¡œë‘ ì—¬ì„±ìš© í–¥ìˆ˜ë¥¼ ì°¾ê³  ê³„ì‹œêµ°ìš”. ì œê°€ ì¶”ì²œë“œë¦´ í–¥ìˆ˜ëŠ” **ì…ìƒë¡œë‘ì˜ ì˜¤ ë“œ ëšœì™ˆë › 50ml**ì…ë‹ˆë‹¤. \n",
      "\n",
      "### ì¶”ì²œ ì´ìœ \n",
      "ì´ í–¥ìˆ˜ëŠ” ê²¨ìš¸ì² ì— íŠ¹íˆ ì˜ ì–´ìš¸ë¦¬ëŠ” í–¥ìœ¼ë¡œ, ë”°ëœ»í•˜ê³  í¬ê·¼í•œ ëŠë‚Œì„ ì£¼ê¸° ë•Œë¬¸ì— ì°¨ê°€ìš´ ë‚ ì”¨ì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. \n",
      "\n",
      "### í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ\n",
      "ì…ìƒë¡œë‘ì˜ ì˜¤ ë“œ ëšœì™ˆë ›ì€ ìƒí¼í•˜ë©´ì„œë„ ë¶€ë“œëŸ¬ìš´ í”Œë¡œëŸ´ ë…¸íŠ¸ê°€ íŠ¹ì§•ì…ë‹ˆë‹¤. ì²˜ìŒì—ëŠ” ì‹ ì„ í•œ ê³¼ì¼ í–¥ì´ ëŠê»´ì§€ë‹¤ê°€, ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ë”°ëœ»í•œ ìš°ë”” ë…¸íŠ¸ì™€ ì„ì—¬ ê¹Šì´ ìˆëŠ” í–¥ì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤. ì´ ì¡°í™”ë¡œìš´ í–¥ì€ ê¸°ë¶„ì„ ì¢‹ê²Œ í•˜ê³ , ìì‹ ê°ì„ ì£¼ëŠ” ë§¤ë ¥ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ì í•©í•œ ìƒí™©\n",
      "ì´ í–¥ìˆ˜ëŠ” ë°ì¼ë¦¬ë¡œ ì‚¬ìš©í•˜ê¸°ì— ì í•©í•˜ë©°, íŠ¹íˆ ê²¨ìš¸ì² ì˜ ë‚® ì‹œê°„ì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. ì¹œêµ¬ë“¤ê³¼ì˜ ë§Œë‚¨ì´ë‚˜ ì§ì¥ì—ì„œë„ ë¶€ë‹´ ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ìš”. ë˜í•œ, íŠ¹ë³„í•œ ë‚ ì— í¬ì¸íŠ¸ë¡œ ì‚¬ìš©í•˜ê¸°ì—ë„ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ê°€ê²©ëŒ€ ë° ìš©ëŸ‰\n",
      "50ml ìš©ëŸ‰ì€ ì ë‹¹í•œ í¬ê¸°ë¡œ, ì¼ìƒì—ì„œ ì‚¬ìš©í•˜ê¸°ì— ë¶€ë‹´ì´ ì ìŠµë‹ˆë‹¤. ê°€ê²©ëŒ€ëŠ” ë³´í†µ ì¤‘ê°„ì—ì„œ ì•½ê°„ ë†’ì€ í¸ì´ì§€ë§Œ, í’ˆì§ˆê³¼ í–¥ì˜ ì§€ì†ì„±ì„ ê³ ë ¤í–ˆì„ ë•Œ ì¶©ë¶„íˆ ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ í–¥ìˆ˜ê°€ ë‹¹ì‹ ì˜ ê²¨ìš¸ì„ ë”ìš± íŠ¹ë³„í•˜ê²Œ ë§Œë“¤ì–´ì¤„ ê±°ë¼ ë¯¿ì–´ìš”! í–¥ìˆ˜ êµ¬ë§¤ ì‹œ ê¼­ í…ŒìŠ¤íŠ¸í•´ë³´ì‹œê³ , ë³¸ì¸ì—ê²Œ ì˜ ì–´ìš¸ë¦¬ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”. ê¶ê¸ˆí•œ ì ì´ ë” ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\n",
      "================================================================================\n",
      "Query: ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\n",
      "ğŸ” LLM_parser ì‹¤í–‰: ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\n",
      "Router JSON: {\n",
      "  \"next\": \"LLM_parser\",\n",
      "  \"reason\": \"The query contains multiple facets including brand, concentration, season, and day/night score.\",\n",
      "  \"facet_count\": 4,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"Dior\",\n",
      "    \"season\": \"fall\",\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": \"night\",\n",
      "    \"concentration\": \"EDP\"\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"other\"\n",
      "}\n",
      "Agent summary: [LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ âœ…\n",
      "\n",
      "ğŸ“Š íŒŒì‹± ê²°ê³¼: {\"brand\": \"ë””ì˜¬\", \"concentration\": \"EDP\", \"day_night_score\": \"ì•¼ê°„\", \"gender\": null, \"season_score\": \"ê°€ì„\", \"sizes\": null}\n",
      "ğŸ” í•„í„°ë§ ê²°ê³¼: {\"brand\": \"ë””ì˜¬\", \"concentration\": null, \"day_night_score\": null, \"gender\": null, \"season_score\": null, \"sizes\": null}\n",
      "ğŸ¯ ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: 5\n",
      "\n",
      "ğŸ’¬ ì¶”ì²œ ê²°ê³¼:\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ê°€ì„ ë°¤ì— ì–´ìš¸ë¦¬ëŠ” ë””ì˜¬ í–¥ìˆ˜ë¥¼ ì°¾ê³  ê³„ì‹œêµ°ìš”. ë””ì˜¬ì€ ë‹¤ì–‘í•œ ë§¤ë ¥ì„ ê°€ì§„ í–¥ìˆ˜ë¡œ ìœ ëª…í•œ ë¸Œëœë“œì¸ë°ìš”, ê°€ì„ ë°¤ì— ì˜ ì–´ìš¸ë¦¬ëŠ” í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”.\n",
      "\n",
      "### ì¶”ì²œ í–¥ìˆ˜: ë””ì˜¬ \"ë¯¸ìŠ¤ ë””ì˜¬ ì˜¤ ë“œ í¼í“¸\" (Dior Miss Dior Eau de Parfum)\n",
      "\n",
      "1. **ì™œ ì´ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•˜ëŠ”ì§€**: ë¯¸ìŠ¤ ë””ì˜¬ì€ ì—¬ì„±ìŠ¤ëŸ¬ì›€ê³¼ ìš°ì•„í•¨ì„ ë™ì‹œì— ì§€ë‹Œ í–¥ìˆ˜ë¡œ, ê°€ì„ ë°¤ì˜ ë¡œë§¨í‹±í•œ ë¶„ìœ„ê¸°ì™€ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. ì´ í–¥ìˆ˜ëŠ” ê¹Šê³  í’ë¶€í•œ í”Œë¡œëŸ´ ë…¸íŠ¸ê°€ íŠ¹ì§•ìœ¼ë¡œ, ê°€ì„ì˜ ì°¨ë¶„í•œ ëŠë‚Œì„ ì˜ ì‚´ë ¤ì¤ë‹ˆë‹¤.\n",
      "\n",
      "2. **í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ**: ë¯¸ìŠ¤ ë””ì˜¬ì€ ìƒí¼í•œ ë² ë¥´ê°€ëª»ê³¼ ì¥ë¯¸ì˜ ì¡°í™”ë¡œ ì‹œì‘í•´, ì¤‘ê°„ì—ëŠ” ìš°ì•„í•œ ì¬ìŠ¤ë¯¼ê³¼ íŒŒì´ë¦¬ì˜ ë”°ëœ»í•œ í–¥ì´ ë”í•´ì§‘ë‹ˆë‹¤. ë§ˆì§€ë§‰ì—ëŠ” ë¨¸ìŠ¤í¬ì™€ ì•°ë²„ì˜ ë¶€ë“œëŸ¬ìš´ ì”í–¥ì´ ë‚¨ì•„, ê¹Šê³  ë§¤í˜¹ì ì¸ ëŠë‚Œì„ ì¤ë‹ˆë‹¤. ì´ ì¡°í™”ëŠ” ê°€ì„ ë°¤ì˜ ì‹ ë¹„ë¡œìš´ ë¶„ìœ„ê¸°ë¥¼ ì˜ í‘œí˜„í•´ì¤ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì–´ë–¤ ìƒí™©ì— ì í•©í•œì§€**: ì´ í–¥ìˆ˜ëŠ” íŠ¹ë³„í•œ ì €ë… ì™¸ì¶œì´ë‚˜ ë°ì´íŠ¸, í˜¹ì€ ì¹œêµ¬ë“¤ê³¼ì˜ ëª¨ì„ ë“± ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ì‚¬ìš©í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤. íŠ¹íˆ ê°€ì„ì˜ ì„œëŠ˜í•œ ë°¤ì— ë”°ëœ»í•œ ì˜·ê³¼ í•¨ê»˜í•˜ë©´ ë”ìš± ë§¤ë ¥ì ì¸ ì¡°í™”ë¥¼ ì´ë£° ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "4. **ê°€ê²©ëŒ€ë‚˜ ìš©ëŸ‰ ê´€ë ¨ ì¡°ì–¸**: ë¯¸ìŠ¤ ë””ì˜¬ ì˜¤ ë“œ í¼í“¸ì€ ë³´í†µ 50mlì™€ 100ml ìš©ëŸ‰ìœ¼ë¡œ ì¶œì‹œë˜ë©°, ê°€ê²©ëŒ€ëŠ” ì•½ 100,000ì›ì—ì„œ 150,000ì› ì‚¬ì´ì…ë‹ˆë‹¤. ì²˜ìŒ ì‚¬ìš©í•´ë³´ì‹ ë‹¤ë©´ 50ml ìš©ëŸ‰ì„ ì¶”ì²œë“œë¦¬ë©°, ì‚¬ìš©í•´ë³´ì‹œê³  ë§ˆìŒì— ë“œì‹œë©´ 100mlë¡œ êµ¬ë§¤í•˜ì‹œëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê°€ì„ ë°¤ì— ì–´ìš¸ë¦¬ëŠ” ì´ í–¥ìˆ˜ë¡œ íŠ¹ë³„í•œ ìˆœê°„ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”.\n",
      "================================================================================\n",
      "Query: EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?\n",
      "Router JSON: {\n",
      "  \"next\": \"FAQ_agent\",\n",
      "  \"reason\": \"The query is asking for a definition and difference between EDP and EDT.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"faq\"\n",
      "}\n",
      "Agent summary: [FAQ_agent] handled. reason=The query is asking for a definition and difference between EDP and EDT. facets={'brand': None, 'season': None, 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=faq\n",
      "================================================================================\n",
      "Query: íƒ‘ë…¸íŠ¸Â·ë¯¸ë“¤ë…¸íŠ¸Â·ë² ì´ìŠ¤ë…¸íŠ¸ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì´ì•¼?\n",
      "Router JSON: {\n",
      "  \"next\": \"FAQ_agent\",\n",
      "  \"reason\": \"User is asking for definitions related to perfume notes.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"faq\"\n",
      "}\n",
      "Agent summary: [FAQ_agent] handled. reason=User is asking for definitions related to perfume notes. facets={'brand': None, 'season': None, 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=faq\n",
      "================================================================================\n",
      "Query: ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?\n",
      "Router JSON: {\n",
      "  \"next\": \"human_fallback\",\n",
      "  \"reason\": \"The query is off-topic and not related to perfume.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"non_perfume\"\n",
      "}\n",
      "Agent summary: [human_fallback] handled. reason=The query is off-topic and not related to perfume. facets={'brand': None, 'season': None, 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=non_perfume\n",
      "================================================================================\n",
      "Query: ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?\n",
      "Router JSON: {\n",
      "  \"next\": \"human_fallback\",\n",
      "  \"reason\": \"The query is off-topic and not related to perfume.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"non_perfume\"\n",
      "}\n",
      "Agent summary: [human_fallback] handled. reason=The query is off-topic and not related to perfume. facets={'brand': None, 'season': None, 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=non_perfume\n",
      "================================================================================\n",
      "Query: ìƒ¤ë„¬ ë„˜ë²„5 50ml ìµœì €ê°€ ì•Œë ¤ì¤˜.\n",
      "Router JSON: {\n",
      "  \"next\": \"price_agent\",\n",
      "  \"reason\": \"Clear price intent detected.\",\n",
      "  \"facet_count\": 1,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"Chanel\",\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": \"50 ml\",\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"price\"\n",
      "}\n",
      "Agent summary: [price_agent] handled. reason=Clear price intent detected. facets={'brand': 'Chanel', 'season': None, 'gender': None, 'sizes': '50 ml', 'day_night_score': None, 'concentration': None} intent=price\n",
      "================================================================================\n",
      "Query: ë””ì˜¬ ì†Œë°”ì¥¬ ê°€ê²© ì–¼ë§ˆì•¼? ì–´ë””ì„œ ì‚¬ëŠ” ê²Œ ì œì¼ ì‹¸?\n",
      "Router JSON: {\n",
      "  \"next\": \"price_agent\",\n",
      "  \"reason\": \"Clear price intent detected.\",\n",
      "  \"facet_count\": 1,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"Dior\",\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"price\"\n",
      "}\n",
      "Agent summary: [price_agent] handled. reason=Clear price intent detected. facets={'brand': 'Dior', 'season': None, 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=price\n",
      "================================================================================\n",
      "Query: ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\n",
      "Router JSON: {\n",
      "  \"next\": \"ML_agent\",\n",
      "  \"reason\": \"User is asking for a scent recommendation for summer.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": \"summer\",\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": \"cool\",\n",
      "  \"query_intent\": \"scent_pref\"\n",
      "}\n",
      "Agent summary: [ML_agent] handled. reason=User is asking for a scent recommendation for summer. facets={'brand': None, 'season': 'summer', 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=scent_pref\n",
      "================================================================================\n",
      "Query: ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.\n",
      "Router JSON: {\n",
      "  \"next\": \"ML_agent\",\n",
      "  \"reason\": \"User is asking for a sweet scent recommendation.\",\n",
      "  \"facet_count\": 0,\n",
      "  \"facets\": {\n",
      "    \"brand\": null,\n",
      "    \"season\": null,\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": \"sweet\",\n",
      "  \"query_intent\": \"scent_pref\"\n",
      "}\n",
      "Agent summary: [ML_agent] handled. reason=User is asking for a sweet scent recommendation. facets={'brand': None, 'season': None, 'gender': None, 'sizes': None, 'day_night_score': None, 'concentration': None} intent=scent_pref\n"
     ]
    }
   ],
   "source": [
    "# ì—°ê²°ë²„ì „\n",
    "# pip install -U langchain langgraph langchain-openai tiktoken python-dotenv pinecone-client\n",
    "import os, json, re\n",
    "from typing import TypedDict, List, Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# ---------- 0) Config ----------\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", \"PUT_YOUR_KEY_HERE\")  # or set in env\n",
    "MODEL_NAME = \"gpt-4o-mini\"  # keep it small & fast for routing\n",
    "\n",
    "SUPERVISOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are the \"Perfume Recommendation Supervisor (Router)\". Analyze the user's query (Korean or English) and route to exactly ONE agent below.\n",
    "\n",
    "[Agents]\n",
    "- LLM_parser         : Parses/normalizes multi-facet queries (2+ product facets).\n",
    "- FAQ_agent          : Perfume knowledge / definitions / differences / general questions.\n",
    "- human_fallback     : Non-perfume or off-topic queries.\n",
    "- price_agent        : Price-only intents (cheapest, price, buy, discount, etc.).\n",
    "- ML_agent           : Single-preference recommendations (mood/season vibe like \"fresh summer\", \"sweet\", etc.).\n",
    "\n",
    "[Facets to detect (\"product facets\")]\n",
    "- brand            (e.g., Chanel, Dior, Creed)\n",
    "- season           (spring/summer/fall/winter; \"for summer/winter\")\n",
    "- gender           (male/female/unisex)\n",
    "- sizes            (volume in ml: 30/50/100 ml)\n",
    "- day_night_score  (day/night/daily/office/club, etc.)\n",
    "- concentration    (EDT/EDP/Extrait/Parfum/Cologne)\n",
    "\n",
    "[Price intent keywords (not exhaustive)]\n",
    "- Korean: ê°€ê²©, ìµœì €ê°€, ì–¼ë§ˆ, ê°€ê²©ëŒ€, êµ¬ë§¤, íŒë§¤, í• ì¸, ì–´ë””ì„œ ì‚¬, ë°°ì†¡ë¹„\n",
    "- English: price, cost, cheapest, buy, purchase, discount\n",
    "\n",
    "[FAQ examples]\n",
    "- Differences between EDP vs EDT, note definitions, longevity/projection, brand/line info.\n",
    "\n",
    "[Single-preference (ML_agent) examples]\n",
    "- \"Recommend a cool perfume for summer\", \"Recommend a sweet scent\", \"One citrusy fresh pick\"\n",
    "  (= 0â€“1 of the above facets mentioned; primarily taste/mood/situation).\n",
    "\n",
    "[Routing rules (priority)]\n",
    "1) Non-perfume / off-topic â†’ human_fallback\n",
    "2) Clear price-only intent (even if one facet is present as context) â†’ price_agent\n",
    "   e.g., \"Chanel No. 5 50ml cheapest price?\" â†’ price_agent\n",
    "3) Count product facets in the query:\n",
    "   - If facets â‰¥ 2 â†’ LLM_parser\n",
    "4) Otherwise (single-topic queries):\n",
    "   - Perfume knowledge/definitions â†’ FAQ_agent\n",
    "   - Single taste/mood recommendation â†’ ML_agent\n",
    "5) Tie-breakers:\n",
    "   - If price intent is clear â†’ price_agent\n",
    "   - If facets â‰¥ 2 â†’ LLM_parser\n",
    "   - Else: knowledge â†’ FAQ_agent, taste â†’ ML_agent\n",
    "\n",
    "[Output format]\n",
    "Return ONLY this JSON (no extra text):\n",
    "{{\n",
    "  \"next\": \"<LLM_parser|FAQ_agent|human_fallback|price_agent|ML_agent>\",\n",
    "  \"reason\": \"<one short English sentence>\",\n",
    "  \"facet_count\": <integer>,\n",
    "  \"facets\": {{\n",
    "    \"brand\": \"<value or null>\",\n",
    "    \"season\": \"<value or null>\",\n",
    "    \"gender\": \"<value or null>\",\n",
    "    \"sizes\": \"<value or null>\",\n",
    "    \"day_night_score\": \"<value or null>\",\n",
    "    \"concentration\": \"<value or null>\"\n",
    "  }},\n",
    "  \"scent_vibe\": \"<value if detected, else null>\",\n",
    "  \"query_intent\": \"<price|faq|scent_pref|non_perfume|other>\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "# ---------- 1) State ----------\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]           # conversation log\n",
    "    next: Optional[str]                   # routing decision key\n",
    "    router_json: Optional[Dict[str, Any]] # parsed JSON from router\n",
    "\n",
    "# ---------- 2) LLM ì´ˆê¸°í™” ----------\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Pinecone ì´ˆê¸°í™”\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(\"perfume-vectordb2\")\n",
    "\n",
    "router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SUPERVISOR_SYSTEM_PROMPT),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Call the router LLM and return parsed JSON + routing target.\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    chain = router_prompt | llm\n",
    "    ai = chain.invoke({\"query\": user_query})\n",
    "    text = ai.content\n",
    "\n",
    "    # JSON strict parse\n",
    "    chosen = \"human_fallback\"\n",
    "    parsed: Dict[str, Any] = {}\n",
    "    try:\n",
    "        parsed = json.loads(text)\n",
    "        maybe = parsed.get(\"next\")\n",
    "        if isinstance(maybe, str) and maybe in {\"LLM_parser\",\"FAQ_agent\",\"human_fallback\",\"price_agent\",\"ML_agent\"}:\n",
    "            chosen = maybe\n",
    "    except Exception:\n",
    "        parsed = {\"error\": \"invalid_json\", \"raw\": text}\n",
    "\n",
    "    msgs = state[\"messages\"] + [AIMessage(content=text)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": chosen,\n",
    "        \"router_json\": parsed\n",
    "    }\n",
    "\n",
    "# ---------- 3) RAG Pipeline Functions ----------\n",
    "parse_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë„ˆëŠ” í–¥ìˆ˜ ì¿¼ë¦¬ íŒŒì„œì•¼.\n",
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜:\n",
    "- brand: ë¸Œëœë“œëª… (ì˜ˆ: ìƒ¤ë„¬, ë””ì˜¬, ì…ìƒë¡œë‘ ë“±)\n",
    "- concentration: (í¼í“¸, ì½”ë¡± ë“±)\n",
    "- day_night_score: ì‚¬ìš©ì‹œê°„ (ì£¼ê°„, ì•¼ê°„, ë°ì¼ë¦¬ ë“±)\n",
    "- gender: ì„±ë³„ (ë‚¨ì„±, ì—¬ì„±, ìœ ë‹ˆì„¹ìŠ¤)\n",
    "- season_score: ê³„ì ˆ (ë´„, ì—¬ë¦„, ê°€ì„, ê²¨ìš¸)\n",
    "- sizes: ìš©ëŸ‰ (30ml, 50ml, 100ml ë“±) ë‹¨ìœ„ëŠ” ë¬´ì‹œí•˜ê³  ìˆ«ìë§Œ\n",
    "\n",
    "ì—†ëŠ” ê°’ì€ nullë¡œ ë‘ê³ , ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì¤˜.\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "{{\"brand\": \"ìƒ¤ë„¬\", \"gender\": null, \"sizes\": \"50\", \"season_score\": null, \"concentration\": null, \"day_night_score\": null}}\"\"\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "def run_llm_parser(query: str):\n",
    "    \"\"\"ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±\"\"\"\n",
    "    try:\n",
    "        chain = parse_prompt | llm\n",
    "        ai_response = chain.invoke({\"query\": query})\n",
    "        response_text = ai_response.content.strip()\n",
    "\n",
    "        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "        if \"```json\" in response_text:\n",
    "            response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in response_text:\n",
    "            response_text = response_text.split(\"```\")[1].strip()\n",
    "\n",
    "        parsed = json.loads(response_text)\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"íŒŒì‹± ì˜¤ë¥˜: {str(e)}\"}\n",
    "\n",
    "# ë©”íƒ€í•„í„° í•¨ìˆ˜ë“¤\n",
    "def filter_brand(brand_value):\n",
    "    valid_brands = [\n",
    "        'ê²”ë‘', 'êµ¬ì°Œ', 'ëŒë¡œì—', 'ë‚˜ë¥´ì‹œì†Œ ë¡œë“œë¦¬ê²Œì¦ˆ', 'ë‹ˆìƒ¤ë„¤', 'ë„ë¥´ì„¸', 'ë””ì˜¬', 'ë”¥í‹°í¬', 'ë‘ì½¤',\n",
    "        'ë¡œë¼ ë©”ë¥´ì‹œì—', 'ë¡œì—ë² ', 'ë¡ì‹œë•…', 'ë¥´ ë¼ë³´', 'ë©”ëª¨', 'ë©”ì¢… ë§ˆë¥´ì§€ì—˜ë¼', 'ë©”ì¢… í”„ë€ì‹œìŠ¤ ì»¤ì •',\n",
    "        'ë©œë¦°ì•¤ê²Œì¸ ', 'ë¯¸ìš°ë¯¸ìš°', 'ë°”ì´ë ˆë„', 'ë°˜í´ë¦¬í”„ ì•„í ', 'ë²„ë²„ë¦¬', 'ë² ë¥´ì‚¬ì²´', 'ë¶ˆê°€ë¦¬', 'ë¹„ë””ì¼€ì´',\n",
    "        'ì‚°íƒ€ ë§ˆë¦¬ì•„ ë…¸ë²¨ë¼', 'ìƒ¤ë„¬', 'ì„¸ë¥´ì£¼ ë£¨í…', 'ì‹œìŠ¬ë¦¬ ì½”ìŠ¤ë©”í‹±', 'ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ', 'ì—ë”° ë¦¬ë¸Œë¥´ ë„ëŸ‰ì¥¬',\n",
    "        'ì—ë¥´ë©”ìŠ¤', 'ì—ìŠ¤í‹° ë¡œë”', 'ì—‘ìŠ¤ ë‹ˆíë¡œ', 'ì´ë‹ˆì‹œì˜¤ í¼í“¸', 'ì´ì†', 'ì…ìƒë¡œë‘', 'ì œë¥´ì¡°í”„', 'ì¡° ë§ë¡ ',\n",
    "        'ì¡°ë¥´ì§€ì˜¤ ì•„ë¥´ë§ˆë‹ˆ', 'ì¤„ë¦¬ì—£ í—¤ì¦ˆ ì–´ ê±´', 'ì§€ë°©ì‹œ', 'ì§ˆ ìŠ¤íŠœì–´íŠ¸', 'í¬ë¦¬ë“œ', 'í‚¬ë¦¬ì•ˆ', 'í†° í¬ë“œ',\n",
    "        'í‹°íŒŒë‹ˆì•¤ì½”', 'í¼í“¸ ë“œ ë§ë¦¬', 'íœí• ë¦¬ê³¤ìŠ¤', 'í”„ë¼ë‹¤', 'í”„ë ˆë°ë¦­ ë§'\n",
    "    ]\n",
    "    if brand_value is None:\n",
    "        return None\n",
    "    return brand_value if brand_value in valid_brands else None\n",
    "\n",
    "def filter_concentration(concentration_value):\n",
    "    valid_concentrations = ['ì†”ë¦¬ë“œ í¼í“¸', 'ì—‘ìŠ¤íŠ¸ë ˆ ë“œ í¼í“¸', 'ì˜¤ ë“œ ëšœì™ˆë ›', 'ì˜¤ ë“œ ì½”ë¡±', 'ì˜¤ ë“œ í¼í“¸', 'í¼í“¸']\n",
    "    if concentration_value is None:\n",
    "        return None\n",
    "    return concentration_value if concentration_value in valid_concentrations else None\n",
    "\n",
    "def filter_day_night_score(day_night_value):\n",
    "    valid_day_night = [\"day\", \"night\"]\n",
    "    if day_night_value is None:\n",
    "        return None\n",
    "    if isinstance(day_night_value, str) and ',' in day_night_value:\n",
    "        values = [v.strip() for v in day_night_value.split(',')]\n",
    "        filtered_values = [v for v in values if v in valid_day_night]\n",
    "        return ','.join(filtered_values) if filtered_values else None\n",
    "    return day_night_value if day_night_value in valid_day_night else None\n",
    "\n",
    "def filter_gender(gender_value):\n",
    "    valid_genders = ['Female', 'Male', 'Unisex', 'unisex ']\n",
    "    if gender_value is None:\n",
    "        return None\n",
    "    return gender_value if gender_value in valid_genders else None\n",
    "\n",
    "def filter_season_score(season_value):\n",
    "    valid_seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "    if season_value is None:\n",
    "        return None\n",
    "    return season_value if season_value in valid_seasons else None\n",
    "\n",
    "def filter_sizes(sizes_value):\n",
    "    valid_sizes = ['30', '50', '75', '100', '150']\n",
    "    if sizes_value is None:\n",
    "        return None\n",
    "    if isinstance(sizes_value, str):\n",
    "        numbers = re.findall(r'\\d+', sizes_value)\n",
    "        for num in numbers:\n",
    "            if num in valid_sizes:\n",
    "                return num\n",
    "    return str(sizes_value) if str(sizes_value) in valid_sizes else None\n",
    "\n",
    "def apply_meta_filters(parsed_json: dict) -> dict:\n",
    "    \"\"\"íŒŒì‹±ëœ JSONì— ë©”íƒ€í•„í„°ë§ ì ìš©\"\"\"\n",
    "    if not parsed_json or \"error\" in parsed_json:\n",
    "        return parsed_json\n",
    "    \n",
    "    return {\n",
    "        'brand': filter_brand(parsed_json.get('brand')),\n",
    "        'concentration': filter_concentration(parsed_json.get('concentration')),\n",
    "        'day_night_score': filter_day_night_score(parsed_json.get('day_night_score')),\n",
    "        'gender': filter_gender(parsed_json.get('gender')),\n",
    "        'season_score': filter_season_score(parsed_json.get('season_score')),\n",
    "        'sizes': filter_sizes(parsed_json.get('sizes'))\n",
    "    }\n",
    "\n",
    "def build_pinecone_filter(filtered_json: dict) -> dict:\n",
    "    \"\"\"ë©”íƒ€í•„í„°ë§ ê²°ê³¼ë¥¼ Pinecone filter dictë¡œ ë³€í™˜\"\"\"\n",
    "    pinecone_filter = {}\n",
    "    if filtered_json.get(\"brand\"):\n",
    "        pinecone_filter[\"brand\"] = {\"$eq\": filtered_json[\"brand\"]}\n",
    "    if filtered_json.get(\"sizes\"):\n",
    "        pinecone_filter[\"sizes\"] = {\"$eq\": filtered_json[\"sizes\"]}\n",
    "    if filtered_json.get(\"season_score\"):\n",
    "        pinecone_filter[\"season_score\"] = {\"$eq\": filtered_json[\"season_score\"]}\n",
    "    if filtered_json.get(\"gender\"):\n",
    "        pinecone_filter[\"gender\"] = {\"$eq\": filtered_json[\"gender\"]}\n",
    "    if filtered_json.get(\"concentration\"):\n",
    "        pinecone_filter[\"concentration\"] = {\"$eq\": filtered_json[\"concentration\"]}\n",
    "    if filtered_json.get(\"day_night_score\"):\n",
    "        pinecone_filter[\"day_night_score\"] = {\"$eq\": filtered_json[\"day_night_score\"]}\n",
    "    return pinecone_filter\n",
    "\n",
    "def query_pinecone(vector, filtered_json: dict, top_k: int = 5):\n",
    "    \"\"\"Pinecone ë²¡í„° ê²€ìƒ‰ + ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©\"\"\"\n",
    "    pinecone_filter = build_pinecone_filter(filtered_json)\n",
    "    \n",
    "    result = index.query(\n",
    "        vector=vector,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        filter=pinecone_filter if pinecone_filter else None\n",
    "    )\n",
    "    return result\n",
    "\n",
    "response_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë„ˆëŠ” í–¥ìˆ˜ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì¶”ì²œì„ í•´ì¤˜.\n",
    "\n",
    "ì¶”ì²œí•  ë•Œ ë‹¤ìŒì„ í¬í•¨í•´ì¤˜:\n",
    "1. ì™œ ì´ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•˜ëŠ”ì§€\n",
    "2. í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ\n",
    "3. ì–´ë–¤ ìƒí™©ì— ì í•©í•œì§€\n",
    "4. ê°€ê²©ëŒ€ë‚˜ ìš©ëŸ‰ ê´€ë ¨ ì¡°ì–¸ (ìˆë‹¤ë©´)\n",
    "\n",
    "ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.\"\"\"),\n",
    "    (\"user\", \"\"\"ì‚¬ìš©ì ì§ˆë¬¸: {original_query}\n",
    "\n",
    "ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´:\n",
    "{search_results}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì¤˜.\"\"\")\n",
    "])\n",
    "\n",
    "def format_search_results(pinecone_results):\n",
    "    \"\"\"Pinecone ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…\"\"\"\n",
    "    if not pinecone_results or not pinecone_results.get('matches'):\n",
    "        return \"ê²€ìƒ‰ëœ í–¥ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    formatted_results = []\n",
    "    for i, match in enumerate(pinecone_results['matches'], 1):\n",
    "        metadata = match.get('metadata', {})\n",
    "        score = match.get('score', 0)\n",
    "        \n",
    "        result_text = f\"\"\"\n",
    "{i}. í–¥ìˆ˜ëª…: {metadata.get('perfume_name', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ë¸Œëœë“œ: {metadata.get('brand', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ì„±ë³„: {metadata.get('gender', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ìš©ëŸ‰: {metadata.get('sizes', 'ì •ë³´ì—†ìŒ')}ml\n",
    "   - ê³„ì ˆ: {metadata.get('season_score', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ì‚¬ìš©ì‹œê°„: {metadata.get('day_night_score', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ë†ë„: {metadata.get('concentration', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ìœ ì‚¬ë„ ì ìˆ˜: {score:.3f}\n",
    "\"\"\"\n",
    "        formatted_results.append(result_text.strip())\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "def generate_response(original_query: str, search_results):\n",
    "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„±\"\"\"\n",
    "    try:\n",
    "        formatted_results = format_search_results(search_results)\n",
    "        \n",
    "        chain = response_prompt | llm\n",
    "        response = chain.invoke({\n",
    "            \"original_query\": original_query,\n",
    "            \"search_results\": formatted_results\n",
    "        })\n",
    "        \n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "# ---------- 4) Agent Nodes ----------\n",
    "def LLM_parser_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” LLM_parser ë…¸ë“œ\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸ” LLM_parser ì‹¤í–‰: {user_query}\")\n",
    "        \n",
    "        # 1ë‹¨ê³„: LLMìœ¼ë¡œ ì¿¼ë¦¬ íŒŒì‹±\n",
    "        parsed_json = run_llm_parser(user_query)\n",
    "        if \"error\" in parsed_json:\n",
    "            error_msg = f\"[LLM_parser] ì¿¼ë¦¬ íŒŒì‹± ì˜¤ë¥˜: {parsed_json['error']}\"\n",
    "            msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "            return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "        \n",
    "        # 2ë‹¨ê³„: ë©”íƒ€í•„í„° ì ìš©\n",
    "        filtered_json = apply_meta_filters(parsed_json)\n",
    "        \n",
    "        # 3ë‹¨ê³„: ì¿¼ë¦¬ ë²¡í„°í™”\n",
    "        query_vector = embeddings.embed_query(user_query)\n",
    "        \n",
    "        # 4ë‹¨ê³„: Pinecone ê²€ìƒ‰\n",
    "        search_results = query_pinecone(query_vector, filtered_json, top_k=5)\n",
    "        \n",
    "        # 5ë‹¨ê³„: ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "        final_response = generate_response(user_query, search_results)\n",
    "        \n",
    "        # ê²°ê³¼ ìš”ì•½\n",
    "        summary = f\"\"\"[LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ âœ…\n",
    "\n",
    "ğŸ“Š íŒŒì‹± ê²°ê³¼: {json.dumps(parsed_json, ensure_ascii=False)}\n",
    "ğŸ” í•„í„°ë§ ê²°ê³¼: {json.dumps(filtered_json, ensure_ascii=False)}\n",
    "ğŸ¯ ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: {len(search_results.get('matches', []))}\n",
    "\n",
    "ğŸ’¬ ì¶”ì²œ ê²°ê³¼:\n",
    "{final_response}\"\"\"\n",
    "\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=summary)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"[LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "\n",
    "def passthrough(name: str):\n",
    "    def _node(state: AgentState) -> AgentState:\n",
    "        payload = state.get(\"router_json\") or {}\n",
    "        summary = f\"[{name}] handled. reason={payload.get('reason')} facets={payload.get('facets')} intent={payload.get('query_intent')}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=summary)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "    return _node\n",
    "\n",
    "FAQ_agent       = passthrough(\"FAQ_agent\")\n",
    "human_fallback  = passthrough(\"human_fallback\")\n",
    "price_agent     = passthrough(\"price_agent\")\n",
    "ML_agent        = passthrough(\"ML_agent\")\n",
    "\n",
    "# ---------- 5) Build Graph ----------\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"LLM_parser\", LLM_parser_node)  # ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ ì—°ê²°\n",
    "graph.add_node(\"FAQ_agent\", FAQ_agent)\n",
    "graph.add_node(\"human_fallback\", human_fallback)\n",
    "graph.add_node(\"price_agent\", price_agent)\n",
    "graph.add_node(\"ML_agent\", ML_agent)\n",
    "\n",
    "graph.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Conditional routing\n",
    "def router_edge(state: AgentState) -> str:\n",
    "    return state[\"next\"] or \"human_fallback\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    router_edge,\n",
    "    {\n",
    "        \"LLM_parser\": \"LLM_parser\",\n",
    "        \"FAQ_agent\": \"FAQ_agent\",\n",
    "        \"human_fallback\": \"human_fallback\",\n",
    "        \"price_agent\": \"price_agent\",\n",
    "        \"ML_agent\": \"ML_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# End states\n",
    "for node in [\"LLM_parser\", \"FAQ_agent\", \"human_fallback\", \"price_agent\", \"ML_agent\"]:\n",
    "    graph.add_edge(node, END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# ---------- 6) Batch Test ----------\n",
    "TEST_QUERIES = [\n",
    "    \"ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\",                 \n",
    "    \"ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\",                \n",
    "    \"EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?\",                                       \n",
    "    \"íƒ‘ë…¸íŠ¸Â·ë¯¸ë“¤ë…¸íŠ¸Â·ë² ì´ìŠ¤ë…¸íŠ¸ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì´ì•¼?\",               \n",
    "    \"ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?\",                                         \n",
    "    \"ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?\",                                         \n",
    "    \"ìƒ¤ë„¬ ë„˜ë²„5 50ml ìµœì €ê°€ ì•Œë ¤ì¤˜.\",                               \n",
    "    \"ë””ì˜¬ ì†Œë°”ì¥¬ ê°€ê²© ì–¼ë§ˆì•¼? ì–´ë””ì„œ ì‚¬ëŠ” ê²Œ ì œì¼ ì‹¸?\",             \n",
    "    \"ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\",                                 \n",
    "    \"ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.\",                                         \n",
    "]\n",
    "\n",
    "def run_tests():\n",
    "    for q in TEST_QUERIES:\n",
    "        print(\"=\"*80)\n",
    "        print(\"Query:\", q)\n",
    "        init: AgentState = {\n",
    "            \"messages\": [HumanMessage(content=q)],\n",
    "            \"next\": None,\n",
    "            \"router_json\": None\n",
    "        }\n",
    "        out = app.invoke(init)\n",
    "        ai_msgs = [m for m in out[\"messages\"] if isinstance(m, AIMessage)]\n",
    "        router_raw = ai_msgs[-2].content if len(ai_msgs) >= 2 else \"(no router output)\"\n",
    "        agent_summary = ai_msgs[-1].content if ai_msgs else \"(no agent output)\"\n",
    "        print(\"Router JSON:\", router_raw)\n",
    "        print(\"Agent summary:\", agent_summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ae72e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3917280898.py, line 52)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mìœ„ì˜ ì½”ë“œì—ë‹¤ê°€ ë¶„ê¸°ì— ë§ëŠ” í•¨ìˆ˜ë¥¼ ì €í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•´ì„œ ë¶™ì—¬ì£¼ê³ \u001b[39m\n       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ML ëª¨ë¸ ë²„ì „\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "\n",
    "class PerfumeRecommender:\n",
    "    \"\"\"í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_pkl_path: str = \"./models.pkl\", \n",
    "                 perfume_json_path: str = \"perfumes.json\",\n",
    "                 model_name: str = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "                 max_len: int = 256):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.max_len = max_len\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"[Device] {self.device}\")\n",
    "        \n",
    "        # ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ\n",
    "        self._load_ml_model(model_pkl_path)\n",
    "        self._load_transformer_model()\n",
    "        self._load_perfume_data(perfume_json_path)\n",
    "        self._build_bm25_index()\n",
    "    \n",
    "    def _load_ml_model(self, pkl_path: str):\n",
    "        \"\"\"ì €ì¥ëœ ML ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\"\"\"\n",
    "        data = joblib.load(pkl_path)\n",
    "        self.clf = data[\"classifier\"]\n",
    "        self.mlb = data[\"mlb\"]\n",
    "        self.thresholds = data[\"thresholds\"]\n",
    "        \n",
    "        print(f\"[Loaded model from {pkl_path}]\")\n",
    "        print(f\"Labels: {list(self.mlb.classes_)}\")\n",
    "    \n",
    "    def _load_transformer_model(self):\n",
    "        \"\"\"Transformer ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.base_model = AutoModel.from_pretrained(self.model_name).to(self.device)\n",
    "        self.base_model.eval()\n",
    "    \n",
    "    def _load_perfume_data(self, json_path: str):\n",
    "        \"\"\"í–¥ìˆ˜ ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.perfumes = json.load(f)\n",
    "        print(f\"[Loaded {len(self.perfumes)} perfumes from {json_path}]\")\n",
    "    \n",
    "    def _build_bm25_index(self):\n",
    "        \"\"\"BM25 ì¸ë±ìŠ¤ êµ¬ì¶•\"\"\"\n",
    "        self.corpus = [item.get(\"fragrances\", \"\") for item in self.perfumes]\n",
    "        tokenized_corpus = [doc.lower().split() for doc in self.corpus]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        print(\"[BM25 index built]\")\n",
    "    \n",
    "    def encode_texts(self, texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
    "        \"\"\"í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "        all_embeddings = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            enc = self.tokenizer(\n",
    "                batch, \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                max_length=self.max_len, \n",
    "                return_tensors=\"pt\"\n",
    "            ).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model_out = self.base_model(**enc)\n",
    "                emb = model_out.last_hidden_state.mean(dim=1)\n",
    "            \n",
    "            all_embeddings.append(emb.cpu().numpy())\n",
    "        \n",
    "        return np.vstack(all_embeddings)\n",
    "    \n",
    "    def predict_labels(self, text: str, topk: int = 3, use_thresholds: bool = True) -> List[str]:\n",
    "        \"\"\"í…ìŠ¤íŠ¸ì—ì„œ í–¥ìˆ˜ ë¼ë²¨ ì˜ˆì¸¡\"\"\"\n",
    "        emb = self.encode_texts([text], batch_size=1)\n",
    "        proba = self.clf.predict_proba(emb)[0]\n",
    "        \n",
    "        if use_thresholds and self.thresholds:\n",
    "            # threshold ê¸°ë°˜ ì„ íƒ\n",
    "            pick = [\n",
    "                i for i, p in enumerate(proba) \n",
    "                if p >= self.thresholds.get(self.mlb.classes_[i], 0.5)\n",
    "            ]\n",
    "            # thresholdë¥¼ ë„˜ëŠ” ê²ƒì´ ì—†ìœ¼ë©´ topk ì„ íƒ\n",
    "            if not pick:\n",
    "                pick = np.argsort(-proba)[:topk]\n",
    "        else:\n",
    "            # ìƒìœ„ topk ì„ íƒ\n",
    "            pick = np.argsort(-proba)[:topk]\n",
    "        \n",
    "        return [self.mlb.classes_[i] for i in pick]\n",
    "    \n",
    "    def search_perfumes(self, labels: List[str], top_n: int = 5) -> List[Tuple[int, float, Dict]]:\n",
    "        \"\"\"BM25ë¥¼ ì‚¬ìš©í•´ í–¥ìˆ˜ ê²€ìƒ‰\"\"\"\n",
    "        query = \" \".join(labels)\n",
    "        tokenized_query = query.lower().split()\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        # ìƒìœ„ Nê°œ ì¸ë±ìŠ¤ ì„ íƒ\n",
    "        top_idx = np.argsort(scores)[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_idx:\n",
    "            results.append((idx, scores[idx], self.perfumes[idx]))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def recommend(self, \n",
    "                  user_text: str, \n",
    "                  topk_labels: int = 4, \n",
    "                  top_n_perfumes: int = 5,\n",
    "                  use_thresholds: bool = True,\n",
    "                  verbose: bool = True) -> Dict:\n",
    "        \"\"\"ì „ì²´ ì¶”ì²œ íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "        \n",
    "        # 1. ML ëª¨ë¸ë¡œ ë¼ë²¨ ì˜ˆì¸¡\n",
    "        predicted_labels = self.predict_labels(\n",
    "            user_text, \n",
    "            topk=topk_labels, \n",
    "            use_thresholds=use_thresholds\n",
    "        )\n",
    "        \n",
    "        # 2. BM25ë¡œ í–¥ìˆ˜ ê²€ìƒ‰\n",
    "        search_results = self.search_perfumes(predicted_labels, top_n=top_n_perfumes)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=== ML ì˜ˆì¸¡ ë¼ë²¨ ===\")\n",
    "            print(predicted_labels)\n",
    "            print(f\"\\n=== BM25 Top-{top_n_perfumes} ê²°ê³¼ ===\")\n",
    "            \n",
    "            for rank, (idx, score, perfume) in enumerate(search_results, 1):\n",
    "                print(f\"[Rank {rank}] Score: {score:.2f}\")\n",
    "                print(f\"  Brand      : {perfume.get('brand', 'N/A')}\")\n",
    "                print(f\"  Name       : {perfume.get('name_perfume', 'N/A')}\")\n",
    "                print(f\"  Fragrances : {perfume.get('fragrances', 'N/A')}\")\n",
    "                print()\n",
    "        \n",
    "        return {\n",
    "            \"user_input\": user_text,\n",
    "            \"predicted_labels\": predicted_labels,\n",
    "            \"recommendations\": [\n",
    "                {\n",
    "                    \"rank\": rank,\n",
    "                    \"score\": score,\n",
    "                    \"brand\": perfume.get('brand', 'N/A'),\n",
    "                    \"name\": perfume.get('name_perfume', 'N/A'),\n",
    "                    \"fragrances\": perfume.get('fragrances', 'N/A'),\n",
    "                    \"perfume_data\": perfume\n",
    "                }\n",
    "                for rank, (idx, score, perfume) in enumerate(search_results, 1)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "def main():\n",
    "    # ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "    recommender = PerfumeRecommender()\n",
    "    \n",
    "    # ì‚¬ìš©ì ì…ë ¥ ì˜ˆì‹œë“¤\n",
    "    test_inputs = [\n",
    "        \"ì‹œíŠ¸ëŸ¬ìŠ¤í•˜ê³  í”„ë£¨í‹°í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜\",\n",
    "        \"ë¡œë§¨í‹±í•˜ê³  í”Œë¡œë„í•œ í–¥ ì›í•´\",\n",
    "        \"ìš°ë””í•˜ê³  ìŠ¤íŒŒì´ì‹œí•œ í–¥ìˆ˜\",\n",
    "        \"ê¹”ë”í•˜ê³  ìƒì¾Œí•œ í–¥\"\n",
    "    ]\n",
    "    \n",
    "    for user_input in test_inputs:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ì‚¬ìš©ì ì…ë ¥: {user_input}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # ì¶”ì²œ ì‹¤í–‰\n",
    "        result = recommender.recommend(\n",
    "            user_text=user_input,\n",
    "            topk_labels=4,\n",
    "            top_n_perfumes=3,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "ì´ê±¸ ì‚¬ìš©í•´ì„œ ë‚˜ë¨¸ì§€ agentë“¤ì„ í†µí•©í•´ì¤˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ab684e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ í™˜ê²½ ë³€ìˆ˜ í™•ì¸:\n",
      "OPENAI_API_KEY: âœ… ì„¤ì •ë¨\n",
      "PINECONE_API_KEY: âœ… ì„¤ì •ë¨\n",
      "NAVER_CLIENT_ID: âœ… ì„¤ì •ë¨\n",
      "NAVER_CLIENT_SECRET: âœ… ì„¤ì •ë¨\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Query: ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\n",
      "ğŸ” LLM_parser ì‹¤í–‰: ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\n",
      "Router JSON: {\n",
      "  \"next\": \"LLM_parser\",\n",
      "  \"reason\": \"The query contains multiple facets including brand, gender, size, and season.\",\n",
      "  \"facet_count\": 4,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"ì…ìƒë¡œë‘\",\n",
      "    \"season\": \"ê²¨ìš¸\",\n",
      "    \"gender\": \"ì—¬ì„±\",\n",
      "    \"sizes\": \"50ml\",\n",
      "    \"day_night_score\": null,\n",
      "    \"concentration\": null\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"other\"\n",
      "}\n",
      "Agent summary: [LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ âœ…\n",
      "\n",
      "ğŸ“Š íŒŒì‹± ê²°ê³¼: {\"brand\": \"ì…ìƒë¡œë‘\", \"gender\": \"ì—¬ì„±\", \"sizes\": \"50\", \"season_score\": \"ê²¨ìš¸\", \"concentration\": null, \"day_night_score\": null}\n",
      "ğŸ” í•„í„°ë§ ê²°ê³¼: {\"brand\": \"ì…ìƒë¡œë‘\", \"concentration\": null, \"day_night_score\": null, \"gender\": null, \"season_score\": null, \"sizes\": \"50\"}\n",
      "ğŸ¯ ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: 5\n",
      "\n",
      "ğŸ’¬ ì¶”ì²œ ê²°ê³¼:\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ì…ìƒë¡œë‘ì˜ ê²¨ìš¸ìš© ì—¬ì„± í–¥ìˆ˜ë¥¼ ì°¾ê³  ê³„ì‹œêµ°ìš”. ì œê°€ ì¶”ì²œë“œë¦´ í–¥ìˆ˜ëŠ” ì…ìƒë¡œë‘ì˜ **ì˜¤ ë“œ ëšœì™ˆë ›** 50mlì…ë‹ˆë‹¤. \n",
      "\n",
      "### ì¶”ì²œ ì´ìœ \n",
      "ì´ í–¥ìˆ˜ëŠ” ê²¨ìš¸ì² ì— íŠ¹íˆ ì˜ ì–´ìš¸ë¦¬ëŠ” í–¥ìœ¼ë¡œ, ë”°ëœ»í•˜ê³  í¬ê·¼í•œ ëŠë‚Œì„ ì£¼ê¸° ë•Œë¬¸ì— ì¶”ìš´ ë‚ ì”¨ì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. \n",
      "\n",
      "### í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ\n",
      "ì…ìƒë¡œë‘ì˜ ì˜¤ ë“œ ëšœì™ˆë ›ì€ ìƒí¼í•˜ë©´ì„œë„ ë¶€ë“œëŸ¬ìš´ í”Œë¡œëŸ´ ë…¸íŠ¸ê°€ íŠ¹ì§•ì…ë‹ˆë‹¤. ì²˜ìŒì—ëŠ” ì‹ ì„ í•œ ê³¼ì¼ í–¥ì´ ëŠê»´ì§€ë‹¤ê°€, ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ ë”°ëœ»í•œ ìš°ë”” ë…¸íŠ¸ì™€ ì„ì—¬ ê¹Šì´ ìˆëŠ” í–¥ì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤. ì´ ì¡°í™”ë¡œìš´ í–¥ì€ ê¸°ë¶„ì„ ì¢‹ê²Œ í•˜ê³ , ìì‹ ê°ì„ ì£¼ëŠ” ë§¤ë ¥ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ì í•©í•œ ìƒí™©\n",
      "ì´ í–¥ìˆ˜ëŠ” ë°ì¼ë¦¬ë¡œ ì‚¬ìš©í•˜ê¸°ì— ì í•©í•˜ë©°, íŠ¹íˆ ê²¨ìš¸ì² ì˜ ë‚® ì‹œê°„ì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. ì¹œêµ¬ë“¤ê³¼ì˜ ë§Œë‚¨ì´ë‚˜ ì§ì¥ì—ì„œë„ ë¶€ë‹´ ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ìš”. ë˜í•œ, íŠ¹ë³„í•œ ë‚ ì˜ ë°ì´íŠ¸ì—ë„ ì˜ ì–´ìš¸ë¦¬ëŠ” í–¥ì…ë‹ˆë‹¤.\n",
      "\n",
      "### ê°€ê²©ëŒ€ ë° ìš©ëŸ‰ ì¡°ì–¸\n",
      "50ml ìš©ëŸ‰ì€ ì ë‹¹í•œ í¬ê¸°ë¡œ, ì¼ìƒì—ì„œ ìì£¼ ì‚¬ìš©í•˜ê¸°ì— ì¢‹ìŠµë‹ˆë‹¤. ê°€ê²©ëŒ€ëŠ” ë³´í†µ ì¤‘ê°„ì—ì„œ ë†’ì€ í¸ì— ì†í•˜ì§€ë§Œ, ì…ìƒë¡œë‘ì˜ í’ˆì§ˆì„ ê³ ë ¤í–ˆì„ ë•Œ ì¶©ë¶„íˆ ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì´ í–¥ìˆ˜ê°€ ë§ˆìŒì— ë“œì…¨ìœ¼ë©´ ì¢‹ê² ì–´ìš”! í˜¹ì‹œ ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ğŸ˜Š\n",
      "================================================================================\n",
      "Query: ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\n",
      "ğŸ” LLM_parser ì‹¤í–‰: ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\n",
      "Router JSON: {\n",
      "  \"next\": \"LLM_parser\",\n",
      "  \"reason\": \"The query contains multiple facets including brand, season, and day/night score.\",\n",
      "  \"facet_count\": 3,\n",
      "  \"facets\": {\n",
      "    \"brand\": \"Dior\",\n",
      "    \"season\": \"fall\",\n",
      "    \"gender\": null,\n",
      "    \"sizes\": null,\n",
      "    \"day_night_score\": \"night\",\n",
      "    \"concentration\": \"EDP\"\n",
      "  },\n",
      "  \"scent_vibe\": null,\n",
      "  \"query_intent\": \"other\"\n",
      "}\n",
      "Agent summary: [LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ âœ…\n",
      "\n",
      "ğŸ“Š íŒŒì‹± ê²°ê³¼: {\"brand\": \"ë””ì˜¬\", \"concentration\": \"EDP\", \"day_night_score\": \"ì•¼ê°„\", \"gender\": null, \"season_score\": \"ê°€ì„\", \"sizes\": null}\n",
      "ğŸ” í•„í„°ë§ ê²°ê³¼: {\"brand\": \"ë””ì˜¬\", \"concentration\": null, \"day_night_score\": null, \"gender\": null, \"season_score\": null, \"sizes\": null}\n",
      "ğŸ¯ ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: 5\n",
      "\n",
      "ğŸ’¬ ì¶”ì²œ ê²°ê³¼:\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ê°€ì„ ë°¤ì— ì–´ìš¸ë¦¬ëŠ” ë””ì˜¬ í–¥ìˆ˜ë¥¼ ì°¾ê³  ê³„ì‹œêµ°ìš”. ë””ì˜¬ì€ ë‹¤ì–‘í•œ ë§¤ë ¥ì„ ê°€ì§„ í–¥ìˆ˜ë¡œ ìœ ëª…í•œ ë¸Œëœë“œì¸ë°ìš”, ê°€ì„ ë°¤ì— ì˜ ì–´ìš¸ë¦¬ëŠ” í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”.\n",
      "\n",
      "### ì¶”ì²œ í–¥ìˆ˜: ë””ì˜¬ \"ë¯¸ìŠ¤ ë””ì˜¬\" ì˜¤ ë“œ í¼í“¸ (Miss Dior Eau de Parfum)\n",
      "\n",
      "1. **ì™œ ì´ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•˜ëŠ”ì§€**: ë¯¸ìŠ¤ ë””ì˜¬ì€ í´ë˜ì‹í•˜ë©´ì„œë„ ì„¸ë ¨ëœ ë§¤ë ¥ì„ ì§€ë‹Œ í–¥ìˆ˜ë¡œ, ê°€ì„ ë°¤ì˜ ìš°ì•„í•¨ê³¼ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤. ì´ í–¥ìˆ˜ëŠ” ì—¬ì„±ìŠ¤ëŸ¬ì›€ì„ ê°•ì¡°í•˜ë©´ì„œë„ ê¹Šì´ ìˆëŠ” í–¥ì„ ê°€ì§€ê³  ìˆì–´, íŠ¹ë³„í•œ ìˆœê°„ì— ìì‹ ê°ì„ ë”í•´ì¤„ ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "2. **í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ**: ë¯¸ìŠ¤ ë””ì˜¬ì€ ìƒí¼í•œ ì‹œíŠ¸ëŸ¬ìŠ¤ ë…¸íŠ¸ë¡œ ì‹œì‘í•´, ì¥ë¯¸ì™€ ì¬ìŠ¤ë¯¼ì˜ í”Œë¡œëŸ´í•œ í–¥ì´ ì´ì–´ì§€ë©°, ë§ˆì§€ë§‰ì—ëŠ” ìš°ë””í•œ ë¨¸ìŠ¤í¬ì™€ íŒŒì´ë¦¬ì˜ ë”°ëœ»í•œ ëŠë‚Œì´ ë‚¨ìŠµë‹ˆë‹¤. ì´ ì¡°í™”ë¡œìš´ í–¥ì€ ê°€ì„ì˜ ìŒ€ìŒ€í•œ ê³µê¸° ì†ì—ì„œë„ ë”°ëœ»í•¨ì„ ëŠë¼ê²Œ í•´ì¤ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì–´ë–¤ ìƒí™©ì— ì í•©í•œì§€**: ì´ í–¥ìˆ˜ëŠ” ì €ë… ì™¸ì¶œ, ë°ì´íŠ¸, íŠ¹ë³„í•œ í–‰ì‚¬ ë“± ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ì‚¬ìš©í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤. íŠ¹íˆ ê°€ì„ ë°¤ì˜ ë¡œë§¨í‹±í•œ ë¶„ìœ„ê¸°ì™€ ì˜ ì–´ìš¸ë ¤, ìƒëŒ€ë°©ì—ê²Œ ê¹Šì€ ì¸ìƒì„ ë‚¨ê¸¸ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "4. **ê°€ê²©ëŒ€ë‚˜ ìš©ëŸ‰ ê´€ë ¨ ì¡°ì–¸**: ë¯¸ìŠ¤ ë””ì˜¬ ì˜¤ ë“œ í¼í“¸ì€ ë³´í†µ 50ml ë˜ëŠ” 100ml ìš©ëŸ‰ìœ¼ë¡œ íŒë§¤ë˜ë©°, ê°€ê²©ëŒ€ëŠ” ì•½ 100,000ì›ì—ì„œ 150,000ì› ì‚¬ì´ì…ë‹ˆë‹¤. ì²˜ìŒ ì‚¬ìš©í•´ë³´ì‹ ë‹¤ë©´ 50ml ìš©ëŸ‰ì„ ì¶”ì²œë“œë¦¬ë©°, ì‚¬ìš©í•´ë³´ì‹œê³  ë§ˆìŒì— ë“œì‹œë©´ 100mlë¡œ êµ¬ë§¤í•˜ì‹œëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê°€ì„ ë°¤ì— ì–´ìš¸ë¦¬ëŠ” ë©‹ì§„ í–¥ìˆ˜ë¡œ ë¯¸ìŠ¤ ë””ì˜¬ì„ ê³ ë ¤í•´ë³´ì„¸ìš”! í–¥ìˆ˜ëŠ” ê°œì¸ì˜ ì·¨í–¥ì— ë”°ë¼ ë‹¤ë¥´ë‹ˆ, ê¼­ í…ŒìŠ¤íŠ¸í•´ë³´ì‹œê³  ê²°ì •í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤. ì¢‹ì€ ì„ íƒ ë˜ì„¸ìš”!\n",
      "================================================================================\n",
      "Query: EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 552\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m    550\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m \u001b[43mrun_tests\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 534\u001b[39m, in \u001b[36mrun_tests\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    528\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mQuery:\u001b[39m\u001b[33m\"\u001b[39m, q)\n\u001b[32m    529\u001b[39m init: AgentState = {\n\u001b[32m    530\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=q)],\n\u001b[32m    531\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mnext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    532\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrouter_json\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    533\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m out = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m ai_msgs = [m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m out[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, AIMessage)]\n\u001b[32m    536\u001b[39m router_raw = ai_msgs[-\u001b[32m2\u001b[39m].content \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ai_msgs) >= \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m(no router output)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3024\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3026\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\langgraph\\pregel\\main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata2\\miniconda3\\envs\\final-env\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 464\u001b[39m, in \u001b[36mFAQ_agent_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mFAQ_agent_node\u001b[39m(state: AgentState) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m    463\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"FAQ_agent_nodet í˜¸ì¶œ\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     result = \u001b[43mFAQ_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m(state)\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: result[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]}\n",
      "\u001b[31mAttributeError\u001b[39m: 'function' object has no attribute 'invoke'",
      "During task with name 'FAQ_agent' and id '6ac0a91e-abff-d92c-e682-f8224843be93'"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain langgraph langchain-openai tiktoken python-dotenv pinecone-client\n",
    "import os, json, re\n",
    "from typing import TypedDict, List, Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# ---------- 0) Config ----------\n",
    "os.environ.setdefault(\"OPENAI_API_KEY\", \"PUT_YOUR_KEY_HERE\")  # or set in env\n",
    "MODEL_NAME = \"gpt-4o-mini\"  # keep it small & fast for routing\n",
    "\n",
    "SUPERVISOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are the \"Perfume Recommendation Supervisor (Router)\". Analyze the user's query (Korean or English) and route to exactly ONE agent below.\n",
    "\n",
    "[Agents]\n",
    "- LLM_parser         : Parses/normalizes multi-facet queries (2+ product facets).\n",
    "- FAQ_agent          : Perfume knowledge / definitions / differences / general questions.\n",
    "- human_fallback     : Non-perfume or off-topic queries.\n",
    "- price_agent        : Price-only intents (cheapest, price, buy, discount, etc.).\n",
    "- ML_agent           : Single-preference recommendations (mood/season vibe like \"fresh summer\", \"sweet\", etc.).\n",
    "\n",
    "[Facets to detect (\"product facets\")]\n",
    "- brand            (e.g., Chanel, Dior, Creed)\n",
    "- season           (spring/summer/fall/winter; \"for summer/winter\")\n",
    "- gender           (male/female/unisex)\n",
    "- sizes            (volume in ml: 30/50/100 ml)\n",
    "- day_night_score  (day/night/daily/office/club, etc.)\n",
    "- concentration    (EDT/EDP/Extrait/Parfum/Cologne)\n",
    "\n",
    "[Price intent keywords (not exhaustive)]\n",
    "- Korean: ê°€ê²©, ìµœì €ê°€, ì–¼ë§ˆ, ê°€ê²©ëŒ€, êµ¬ë§¤, íŒë§¤, í• ì¸, ì–´ë””ì„œ ì‚¬, ë°°ì†¡ë¹„\n",
    "- English: price, cost, cheapest, buy, purchase, discount\n",
    "\n",
    "[FAQ examples]\n",
    "- Differences between EDP vs EDT, note definitions, longevity/projection, brand/line info.\n",
    "\n",
    "[Single-preference (ML_agent) examples]\n",
    "- \"Recommend a cool perfume for summer\", \"Recommend a sweet scent\", \"One citrusy fresh pick\"\n",
    "  (= 0â€“1 of the above facets mentioned; primarily taste/mood/situation).\n",
    "\n",
    "[Routing rules (priority)]\n",
    "1) Non-perfume / off-topic â†’ human_fallback\n",
    "2) Clear price-only intent (even if one facet is present as context) â†’ price_agent\n",
    "   e.g., \"Chanel No. 5 50ml cheapest price?\" â†’ price_agent\n",
    "3) Count product facets in the query:\n",
    "   - If facets â‰¥ 2 â†’ LLM_parser\n",
    "4) Otherwise (single-topic queries):\n",
    "   - Perfume knowledge/definitions â†’ FAQ_agent\n",
    "   - Single taste/mood recommendation â†’ ML_agent\n",
    "5) Tie-breakers:\n",
    "   - If price intent is clear â†’ price_agent\n",
    "   - If facets â‰¥ 2 â†’ LLM_parser\n",
    "   - Else: knowledge â†’ FAQ_agent, taste â†’ ML_agent\n",
    "\n",
    "[Output format]\n",
    "Return ONLY this JSON (no extra text):\n",
    "{{\n",
    "  \"next\": \"<LLM_parser|FAQ_agent|human_fallback|price_agent|ML_agent>\",\n",
    "  \"reason\": \"<one short English sentence>\",\n",
    "  \"facet_count\": <integer>,\n",
    "  \"facets\": {{\n",
    "    \"brand\": \"<value or null>\",\n",
    "    \"season\": \"<value or null>\",\n",
    "    \"gender\": \"<value or null>\",\n",
    "    \"sizes\": \"<value or null>\",\n",
    "    \"day_night_score\": \"<value or null>\",\n",
    "    \"concentration\": \"<value or null>\"\n",
    "  }},\n",
    "  \"scent_vibe\": \"<value if detected, else null>\",\n",
    "  \"query_intent\": \"<price|faq|scent_pref|non_perfume|other>\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "# ---------- 1) State ----------\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]           # conversation log\n",
    "    next: Optional[str]                   # routing decision key\n",
    "    router_json: Optional[Dict[str, Any]] # parsed JSON from router\n",
    "\n",
    "# ---------- 2) LLM ì´ˆê¸°í™” ----------\n",
    "llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Pinecone ì´ˆê¸°í™”\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index = pc.Index(\"perfume-vectordb2\")\n",
    "\n",
    "router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SUPERVISOR_SYSTEM_PROMPT),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Call the router LLM and return parsed JSON + routing target.\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    chain = router_prompt | llm\n",
    "    ai = chain.invoke({\"query\": user_query})\n",
    "    text = ai.content\n",
    "\n",
    "    # JSON strict parse\n",
    "    chosen = \"human_fallback\"\n",
    "    parsed: Dict[str, Any] = {}\n",
    "    try:\n",
    "        parsed = json.loads(text)\n",
    "        maybe = parsed.get(\"next\")\n",
    "        if isinstance(maybe, str) and maybe in {\"LLM_parser\",\"FAQ_agent\",\"human_fallback\",\"price_agent\",\"ML_agent\"}:\n",
    "            chosen = maybe\n",
    "    except Exception:\n",
    "        parsed = {\"error\": \"invalid_json\", \"raw\": text}\n",
    "\n",
    "    msgs = state[\"messages\"] + [AIMessage(content=text)]\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"next\": chosen,\n",
    "        \"router_json\": parsed\n",
    "    }\n",
    "\n",
    "# ---------- 3) RAG Pipeline Functions ----------\n",
    "parse_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë„ˆëŠ” í–¥ìˆ˜ ì¿¼ë¦¬ íŒŒì„œì•¼.\n",
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜:\n",
    "- brand: ë¸Œëœë“œëª… (ì˜ˆ: ìƒ¤ë„¬, ë””ì˜¬, ì…ìƒë¡œë‘ ë“±)\n",
    "- concentration: (í¼í“¸, ì½”ë¡± ë“±)\n",
    "- day_night_score: ì‚¬ìš©ì‹œê°„ (ì£¼ê°„, ì•¼ê°„, ë°ì¼ë¦¬ ë“±)\n",
    "- gender: ì„±ë³„ (ë‚¨ì„±, ì—¬ì„±, ìœ ë‹ˆì„¹ìŠ¤)\n",
    "- season_score: ê³„ì ˆ (ë´„, ì—¬ë¦„, ê°€ì„, ê²¨ìš¸)\n",
    "- sizes: ìš©ëŸ‰ (30ml, 50ml, 100ml ë“±) ë‹¨ìœ„ëŠ” ë¬´ì‹œí•˜ê³  ìˆ«ìë§Œ\n",
    "\n",
    "ì—†ëŠ” ê°’ì€ nullë¡œ ë‘ê³ , ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì¤˜.\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "{{\"brand\": \"ìƒ¤ë„¬\", \"gender\": null, \"sizes\": \"50\", \"season_score\": null, \"concentration\": null, \"day_night_score\": null}}\"\"\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "def run_llm_parser(query: str):\n",
    "    \"\"\"ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±\"\"\"\n",
    "    try:\n",
    "        chain = parse_prompt | llm\n",
    "        ai_response = chain.invoke({\"query\": query})\n",
    "        response_text = ai_response.content.strip()\n",
    "\n",
    "        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "        if \"```json\" in response_text:\n",
    "            response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in response_text:\n",
    "            response_text = response_text.split(\"```\")[1].strip()\n",
    "\n",
    "        parsed = json.loads(response_text)\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"íŒŒì‹± ì˜¤ë¥˜: {str(e)}\"}\n",
    "\n",
    "# ë©”íƒ€í•„í„° í•¨ìˆ˜ë“¤\n",
    "def filter_brand(brand_value):\n",
    "    valid_brands = [\n",
    "        'ê²”ë‘', 'êµ¬ì°Œ', 'ëŒë¡œì—', 'ë‚˜ë¥´ì‹œì†Œ ë¡œë“œë¦¬ê²Œì¦ˆ', 'ë‹ˆìƒ¤ë„¤', 'ë„ë¥´ì„¸', 'ë””ì˜¬', 'ë”¥í‹°í¬', 'ë‘ì½¤',\n",
    "        'ë¡œë¼ ë©”ë¥´ì‹œì—', 'ë¡œì—ë² ', 'ë¡ì‹œë•…', 'ë¥´ ë¼ë³´', 'ë©”ëª¨', 'ë©”ì¢… ë§ˆë¥´ì§€ì—˜ë¼', 'ë©”ì¢… í”„ë€ì‹œìŠ¤ ì»¤ì •',\n",
    "        'ë©œë¦°ì•¤ê²Œì¸ ', 'ë¯¸ìš°ë¯¸ìš°', 'ë°”ì´ë ˆë„', 'ë°˜í´ë¦¬í”„ ì•„í ', 'ë²„ë²„ë¦¬', 'ë² ë¥´ì‚¬ì²´', 'ë¶ˆê°€ë¦¬', 'ë¹„ë””ì¼€ì´',\n",
    "        'ì‚°íƒ€ ë§ˆë¦¬ì•„ ë…¸ë²¨ë¼', 'ìƒ¤ë„¬', 'ì„¸ë¥´ì£¼ ë£¨í…', 'ì‹œìŠ¬ë¦¬ ì½”ìŠ¤ë©”í‹±', 'ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ', 'ì—ë”° ë¦¬ë¸Œë¥´ ë„ëŸ‰ì¥¬',\n",
    "        'ì—ë¥´ë©”ìŠ¤', 'ì—ìŠ¤í‹° ë¡œë”', 'ì—‘ìŠ¤ ë‹ˆíë¡œ', 'ì´ë‹ˆì‹œì˜¤ í¼í“¸', 'ì´ì†', 'ì…ìƒë¡œë‘', 'ì œë¥´ì¡°í”„', 'ì¡° ë§ë¡ ',\n",
    "        'ì¡°ë¥´ì§€ì˜¤ ì•„ë¥´ë§ˆë‹ˆ', 'ì¤„ë¦¬ì—£ í—¤ì¦ˆ ì–´ ê±´', 'ì§€ë°©ì‹œ', 'ì§ˆ ìŠ¤íŠœì–´íŠ¸', 'í¬ë¦¬ë“œ', 'í‚¬ë¦¬ì•ˆ', 'í†° í¬ë“œ',\n",
    "        'í‹°íŒŒë‹ˆì•¤ì½”', 'í¼í“¸ ë“œ ë§ë¦¬', 'íœí• ë¦¬ê³¤ìŠ¤', 'í”„ë¼ë‹¤', 'í”„ë ˆë°ë¦­ ë§'\n",
    "    ]\n",
    "    if brand_value is None:\n",
    "        return None\n",
    "    return brand_value if brand_value in valid_brands else None\n",
    "\n",
    "def filter_concentration(concentration_value):\n",
    "    valid_concentrations = ['ì†”ë¦¬ë“œ í¼í“¸', 'ì—‘ìŠ¤íŠ¸ë ˆ ë“œ í¼í“¸', 'ì˜¤ ë“œ ëšœì™ˆë ›', 'ì˜¤ ë“œ ì½”ë¡±', 'ì˜¤ ë“œ í¼í“¸', 'í¼í“¸']\n",
    "    if concentration_value is None:\n",
    "        return None\n",
    "    return concentration_value if concentration_value in valid_concentrations else None\n",
    "\n",
    "def filter_day_night_score(day_night_value):\n",
    "    valid_day_night = [\"day\", \"night\"]\n",
    "    if day_night_value is None:\n",
    "        return None\n",
    "    if isinstance(day_night_value, str) and ',' in day_night_value:\n",
    "        values = [v.strip() for v in day_night_value.split(',')]\n",
    "        filtered_values = [v for v in values if v in valid_day_night]\n",
    "        return ','.join(filtered_values) if filtered_values else None\n",
    "    return day_night_value if day_night_value in valid_day_night else None\n",
    "\n",
    "def filter_gender(gender_value):\n",
    "    valid_genders = ['Female', 'Male', 'Unisex', 'unisex ']\n",
    "    if gender_value is None:\n",
    "        return None\n",
    "    return gender_value if gender_value in valid_genders else None\n",
    "\n",
    "def filter_season_score(season_value):\n",
    "    valid_seasons = ['winter', 'spring', 'summer', 'fall']\n",
    "    if season_value is None:\n",
    "        return None\n",
    "    return season_value if season_value in valid_seasons else None\n",
    "\n",
    "def filter_sizes(sizes_value):\n",
    "    valid_sizes = ['30', '50', '75', '100', '150']\n",
    "    if sizes_value is None:\n",
    "        return None\n",
    "    if isinstance(sizes_value, str):\n",
    "        numbers = re.findall(r'\\d+', sizes_value)\n",
    "        for num in numbers:\n",
    "            if num in valid_sizes:\n",
    "                return num\n",
    "    return str(sizes_value) if str(sizes_value) in valid_sizes else None\n",
    "\n",
    "def apply_meta_filters(parsed_json: dict) -> dict:\n",
    "    \"\"\"íŒŒì‹±ëœ JSONì— ë©”íƒ€í•„í„°ë§ ì ìš©\"\"\"\n",
    "    if not parsed_json or \"error\" in parsed_json:\n",
    "        return parsed_json\n",
    "    \n",
    "    return {\n",
    "        'brand': filter_brand(parsed_json.get('brand')),\n",
    "        'concentration': filter_concentration(parsed_json.get('concentration')),\n",
    "        'day_night_score': filter_day_night_score(parsed_json.get('day_night_score')),\n",
    "        'gender': filter_gender(parsed_json.get('gender')),\n",
    "        'season_score': filter_season_score(parsed_json.get('season_score')),\n",
    "        'sizes': filter_sizes(parsed_json.get('sizes'))\n",
    "    }\n",
    "\n",
    "def build_pinecone_filter(filtered_json: dict) -> dict:\n",
    "    \"\"\"ë©”íƒ€í•„í„°ë§ ê²°ê³¼ë¥¼ Pinecone filter dictë¡œ ë³€í™˜\"\"\"\n",
    "    pinecone_filter = {}\n",
    "    if filtered_json.get(\"brand\"):\n",
    "        pinecone_filter[\"brand\"] = {\"$eq\": filtered_json[\"brand\"]}\n",
    "    if filtered_json.get(\"sizes\"):\n",
    "        pinecone_filter[\"sizes\"] = {\"$eq\": filtered_json[\"sizes\"]}\n",
    "    if filtered_json.get(\"season_score\"):\n",
    "        pinecone_filter[\"season_score\"] = {\"$eq\": filtered_json[\"season_score\"]}\n",
    "    if filtered_json.get(\"gender\"):\n",
    "        pinecone_filter[\"gender\"] = {\"$eq\": filtered_json[\"gender\"]}\n",
    "    if filtered_json.get(\"concentration\"):\n",
    "        pinecone_filter[\"concentration\"] = {\"$eq\": filtered_json[\"concentration\"]}\n",
    "    if filtered_json.get(\"day_night_score\"):\n",
    "        pinecone_filter[\"day_night_score\"] = {\"$eq\": filtered_json[\"day_night_score\"]}\n",
    "    return pinecone_filter\n",
    "@tool\n",
    "def price_tool(user_query: str) -> str: #ì´ê±° price_agent í•¨ìˆ˜ì•¼\n",
    "    \"\"\"A tool that uses the Naver Shopping API to look up perfume prices (results are returned as formatted strings)\"\"\"\n",
    "    \n",
    "    url = \"https://openapi.naver.com/v1/search/shop.json\"\n",
    "    headers = {\n",
    "        \"X-Naver-Client-Id\": naver_client_id,\n",
    "        \"X-Naver-Client-Secret\": naver_client_secret\n",
    "    }\n",
    "    params = {\"query\": user_query, \"display\": 5, \"sort\": \"sim\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "    except Exception as e:\n",
    "        return f\"âŒ ìš”ì²­ ì˜¤ë¥˜: {e}\"\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f\"âŒ API ì˜¤ë¥˜: {response.status_code}\"\n",
    "    \n",
    "    data = response.json()\n",
    "    if not data or \"items\" not in data or len(data[\"items\"]) == 0:\n",
    "        return f\"ğŸ˜” '{user_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    # HTML íƒœê·¸ ì œê±° í•¨ìˆ˜\n",
    "    def remove_html_tags(text: str) -> str:\n",
    "        return re.sub(r\"<[^>]+>\", \"\", text)\n",
    "    \n",
    "    # ìƒìœ„ 3ê°œë§Œ ì •ë¦¬\n",
    "    products = data[\"items\"][:3]\n",
    "    output = f\"ğŸ” '{user_query}' ê²€ìƒ‰ ê²°ê³¼:\\n\\n\"\n",
    "    for i, item in enumerate(products, 1):\n",
    "        title = remove_html_tags(item.get(\"title\", \"\"))\n",
    "        lprice = item.get(\"lprice\", \"0\")\n",
    "        mall = item.get(\"mallName\", \"ì •ë³´ ì—†ìŒ\")\n",
    "        link = item.get(\"link\", \"ì •ë³´ ì—†ìŒ\")\n",
    "        \n",
    "        output += f\"ğŸ“¦ {i}. {title}\\n\"\n",
    "        if lprice != \"0\":\n",
    "            output += f\"   ğŸ’° ê°€ê²©: {int(lprice):,}ì›\\n\"\n",
    "        output += f\"   ğŸª íŒë§¤ì²˜: {mall}\\n\"\n",
    "        output += f\"   ğŸ”— ë§í¬: {link}\\n\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "def human_fallback(state: dict) -> str:\n",
    "    \"\"\"í–¥ìˆ˜ ê´€ë ¨ ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ê¸°ë³¸ ì‘ë‹µ\"\"\"\n",
    "    query = state.get(\"input\", \"\")\n",
    "    return (\n",
    "        f\"â“ '{query}' ë” ëª…í™•í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\\n\"\n",
    "        f\"ğŸ‘‰ ì§ˆë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\\n\"\n",
    "        f\"ğŸ’¡ ë˜ëŠ” í–¥ìˆ˜ì— ê´€í•œ ë©‹ì§„ ì§ˆë¬¸ì„ í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?\")\n",
    "\n",
    "def query_pinecone(vector, filtered_json: dict, top_k: int = 5):\n",
    "    \"\"\"Pinecone ë²¡í„° ê²€ìƒ‰ + ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©\"\"\"\n",
    "    pinecone_filter = build_pinecone_filter(filtered_json)\n",
    "    \n",
    "    result = index.query(\n",
    "        vector=vector,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        filter=pinecone_filter if pinecone_filter else None\n",
    "    )\n",
    "    return result\n",
    "\n",
    "response_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"ë„ˆëŠ” í–¥ìˆ˜ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì¶”ì²œì„ í•´ì¤˜.\n",
    "\n",
    "ì¶”ì²œí•  ë•Œ ë‹¤ìŒì„ í¬í•¨í•´ì¤˜:\n",
    "1. ì™œ ì´ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•˜ëŠ”ì§€\n",
    "2. í–¥ì˜ íŠ¹ì§•ê³¼ ëŠë‚Œ\n",
    "3. ì–´ë–¤ ìƒí™©ì— ì í•©í•œì§€\n",
    "4. ê°€ê²©ëŒ€ë‚˜ ìš©ëŸ‰ ê´€ë ¨ ì¡°ì–¸ (ìˆë‹¤ë©´)\n",
    "\n",
    "ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.\"\"\"),\n",
    "    (\"user\", \"\"\"ì‚¬ìš©ì ì§ˆë¬¸: {original_query}\n",
    "\n",
    "ê²€ìƒ‰ëœ í–¥ìˆ˜ ì •ë³´:\n",
    "{search_results}\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì¤˜.\"\"\")\n",
    "])\n",
    "\n",
    "def format_search_results(pinecone_results):\n",
    "    \"\"\"Pinecone ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…\"\"\"\n",
    "    if not pinecone_results or not pinecone_results.get('matches'):\n",
    "        return \"ê²€ìƒ‰ëœ í–¥ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    formatted_results = []\n",
    "    for i, match in enumerate(pinecone_results['matches'], 1):\n",
    "        metadata = match.get('metadata', {})\n",
    "        score = match.get('score', 0)\n",
    "        \n",
    "        result_text = f\"\"\"\n",
    "{i}. í–¥ìˆ˜ëª…: {metadata.get('perfume_name', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ë¸Œëœë“œ: {metadata.get('brand', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ì„±ë³„: {metadata.get('gender', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ìš©ëŸ‰: {metadata.get('sizes', 'ì •ë³´ì—†ìŒ')}ml\n",
    "   - ê³„ì ˆ: {metadata.get('season_score', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ì‚¬ìš©ì‹œê°„: {metadata.get('day_night_score', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ë†ë„: {metadata.get('concentration', 'ì •ë³´ì—†ìŒ')}\n",
    "   - ìœ ì‚¬ë„ ì ìˆ˜: {score:.3f}\n",
    "\"\"\"\n",
    "        formatted_results.append(result_text.strip())\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "def generate_response(original_query: str, search_results):\n",
    "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„±\"\"\"\n",
    "    try:\n",
    "        formatted_results = format_search_results(search_results)\n",
    "        \n",
    "        chain = response_prompt | llm\n",
    "        response = chain.invoke({\n",
    "            \"original_query\": original_query,\n",
    "            \"search_results\": formatted_results\n",
    "        })\n",
    "        \n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "# ---------- 4) Agent Nodes ----------\n",
    "def LLM_parser_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” LLM_parser ë…¸ë“œ\"\"\"\n",
    "    user_query = None\n",
    "    for m in reversed(state[\"messages\"]):\n",
    "        if isinstance(m, HumanMessage):\n",
    "            user_query = m.content\n",
    "            break\n",
    "    if not user_query:\n",
    "        user_query = \"(empty)\"\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸ” LLM_parser ì‹¤í–‰: {user_query}\")\n",
    "        \n",
    "        # 1ë‹¨ê³„: LLMìœ¼ë¡œ ì¿¼ë¦¬ íŒŒì‹±\n",
    "        parsed_json = run_llm_parser(user_query)\n",
    "        if \"error\" in parsed_json:\n",
    "            error_msg = f\"[LLM_parser] ì¿¼ë¦¬ íŒŒì‹± ì˜¤ë¥˜: {parsed_json['error']}\"\n",
    "            msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "            return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "        \n",
    "        # 2ë‹¨ê³„: ë©”íƒ€í•„í„° ì ìš©\n",
    "        filtered_json = apply_meta_filters(parsed_json)\n",
    "        \n",
    "        # 3ë‹¨ê³„: ì¿¼ë¦¬ ë²¡í„°í™”\n",
    "        query_vector = embeddings.embed_query(user_query)\n",
    "        \n",
    "        # 4ë‹¨ê³„: Pinecone ê²€ìƒ‰\n",
    "        search_results = query_pinecone(query_vector, filtered_json, top_k=5)\n",
    "        \n",
    "        # 5ë‹¨ê³„: ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "        final_response = generate_response(user_query, search_results)\n",
    "        \n",
    "        # ê²°ê³¼ ìš”ì•½\n",
    "        summary = f\"\"\"[LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ âœ…\n",
    "\n",
    "ğŸ“Š íŒŒì‹± ê²°ê³¼: {json.dumps(parsed_json, ensure_ascii=False)}\n",
    "ğŸ” í•„í„°ë§ ê²°ê³¼: {json.dumps(filtered_json, ensure_ascii=False)}\n",
    "ğŸ¯ ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: {len(search_results.get('matches', []))}\n",
    "\n",
    "ğŸ’¬ ì¶”ì²œ ê²°ê³¼:\n",
    "{final_response}\"\"\"\n",
    "\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=summary)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"[LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=error_msg)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "\n",
    "def passthrough(name: str):\n",
    "    def _node(state: AgentState) -> AgentState:\n",
    "        payload = state.get(\"router_json\") or {}\n",
    "        summary = f\"[{name}] handled. reason={payload.get('reason')} facets={payload.get('facets')} intent={payload.get('query_intent')}\"\n",
    "        msgs = state[\"messages\"] + [AIMessage(content=summary)]\n",
    "        return {\"messages\": msgs, \"next\": None, \"router_json\": state.get(\"router_json\")}\n",
    "    return _node\n",
    "\n",
    "price_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a perfume price specialist assistant.\n",
    "    \n",
    "When users ask about perfume prices:\n",
    "1. Use the price_tool to search for current prices\n",
    "2. Always respond in Korean\n",
    "3. Format results nicely with emojis and clear information\n",
    "4. Be helpful and friendly\n",
    "    \n",
    "If you can't find price information, politely explain and suggest alternative searches.\"\"\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "price_agent = create_react_agent(\n",
    "    llm, \n",
    "    [price_tool],\n",
    "    prompt=price_prompt\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 7) ì—ì´ì „íŠ¸ í˜¸ì¶œ ë˜í¼ ---\n",
    "def price_agent_node(state: AgentState) -> dict:\n",
    "    \"\"\"Price agent í˜¸ì¶œ\"\"\"\n",
    "    result = price_agent.invoke(state)\n",
    "    return {\"messages\": result[\"messages\"]}\n",
    "\n",
    "def FAQ_agent_node(state: AgentState) -> dict:\n",
    "    \"\"\"FAQ_agent_nodet í˜¸ì¶œ\"\"\"\n",
    "    result = FAQ_agent.invoke(state)\n",
    "    return {\"messages\": result[\"messages\"]}\n",
    "\n",
    "def ML_agent_node(state: AgentState) -> dict:\n",
    "    \"\"\"ML_agent í˜¸ì¶œ\"\"\"\n",
    "    result = ML_agent.invoke(state)\n",
    "    return {\"messages\": result[\"messages\"]}\n",
    "\n",
    "# FAQ_agent       = passthrough(\"FAQ_agent\")\n",
    "# human_fallback  = passthrough(\"human_fallback\")\n",
    "# price_agent     = passthrough(\"price_agent\")\n",
    "# ML_agent        = passthrough(\"ML_agent\")\n",
    "\n",
    "# ---------- 5) Build Graph ----------\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"LLM_parser\", LLM_parser_node)  # ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ ì—°ê²°\n",
    "graph.add_node(\"FAQ_agent\", FAQ_agent_node)\n",
    "graph.add_node(\"human_fallback\", human_fallback)\n",
    "graph.add_node(\"price_agent\", price_agent_node)\n",
    "graph.add_node(\"ML_agent\", ML_agent_node)\n",
    "\n",
    "graph.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Conditional routing\n",
    "def router_edge(state: AgentState) -> str:\n",
    "    return state[\"next\"] or \"human_fallback\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    router_edge,\n",
    "    {\n",
    "        \"LLM_parser\": \"LLM_parser\",\n",
    "        \"FAQ_agent\": \"FAQ_agent\",\n",
    "        \"human_fallback\": \"human_fallback\",\n",
    "        \"price_agent\": \"price_agent\",\n",
    "        \"ML_agent\": \"ML_agent\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# End states\n",
    "for node in [\"LLM_parser\", \"FAQ_agent\", \"human_fallback\", \"price_agent\", \"ML_agent\"]:\n",
    "    graph.add_edge(node, END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# ---------- 6) Batch Test ----------\n",
    "TEST_QUERIES = [\n",
    "    \"ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\",                 \n",
    "    \"ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?\",                \n",
    "    \"EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?\",                                       \n",
    "    \"íƒ‘ë…¸íŠ¸Â·ë¯¸ë“¤ë…¸íŠ¸Â·ë² ì´ìŠ¤ë…¸íŠ¸ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì´ì•¼?\",               \n",
    "    \"ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?\",                                         \n",
    "    \"ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?\",                                         \n",
    "    \"ìƒ¤ë„¬ ë„˜ë²„5 50ml ìµœì €ê°€ ì•Œë ¤ì¤˜.\",                               \n",
    "    \"ë””ì˜¬ ì†Œë°”ì¥¬ ê°€ê²© ì–¼ë§ˆì•¼? ì–´ë””ì„œ ì‚¬ëŠ” ê²Œ ì œì¼ ì‹¸?\",             \n",
    "    \"ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.\",                                 \n",
    "    \"ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.\",                                         \n",
    "]\n",
    "\n",
    "def run_tests():\n",
    "    for q in TEST_QUERIES:\n",
    "        print(\"=\"*80)\n",
    "        print(\"Query:\", q)\n",
    "        init: AgentState = {\n",
    "            \"messages\": [HumanMessage(content=q)],\n",
    "            \"next\": None,\n",
    "            \"router_json\": None\n",
    "        }\n",
    "        out = app.invoke(init)\n",
    "        ai_msgs = [m for m in out[\"messages\"] if isinstance(m, AIMessage)]\n",
    "        router_raw = ai_msgs[-2].content if len(ai_msgs) >= 2 else \"(no router output)\"\n",
    "        agent_summary = ai_msgs[-1].content if ai_msgs else \"(no agent output)\"\n",
    "        print(\"Router JSON:\", router_raw)\n",
    "        print(\"Agent summary:\", agent_summary)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "    print(\"ğŸ”§ í™˜ê²½ ë³€ìˆ˜ í™•ì¸:\")\n",
    "    print(f\"OPENAI_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('OPENAI_API_KEY') else 'âŒ ë¯¸ì„¤ì •'}\")\n",
    "    print(f\"PINECONE_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('PINECONE_API_KEY') else 'âŒ ë¯¸ì„¤ì •'}\")\n",
    "    print(f\"NAVER_CLIENT_ID: {'âœ… ì„¤ì •ë¨' if os.getenv('NAVER_CLIENT_ID') else 'âŒ ë¯¸ì„¤ì •'}\")\n",
    "    print(f\"NAVER_CLIENT_SECRET: {'âœ… ì„¤ì •ë¨' if os.getenv('NAVER_CLIENT_SECRET') else 'âŒ ë¯¸ì„¤ì •'}\")\n",
    "    print()\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e7d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
