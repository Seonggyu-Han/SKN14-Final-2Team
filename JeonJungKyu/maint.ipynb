{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "493c8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Optional, Annotated, Sequence\n",
    "import operator\n",
    "\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from function import price_tool, human_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e60a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0) ENV ---\n",
    "load_dotenv()\n",
    "\n",
    "# --- 1) State ì •ì˜ ---\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: Optional[str]\n",
    "\n",
    "# --- 2) LLM ---\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# --- 3) Supervisor ---\n",
    "members = [\"price_agent\", \"consultation_agent\", \"human_fallback\"]\n",
    "\n",
    "supervisor_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a supervisor managing a perfume specialist team.\n",
    "\n",
    "Your team members:\n",
    "- price_agent: Handles perfume price/cost inquiries (has access to Naver Shopping API)\n",
    "- consultation_agent: Handles general perfume advice and recommendations  \n",
    "- human_fallback: Handles non-perfume topics or unclear questions\n",
    "\n",
    "Routing Rules:\n",
    "- If query is about perfume price/cost (ê°€ê²©, ìµœì €ê°€, ì–¼ë§ˆ, price, cost, êµ¬ë§¤, íŒë§¤), choose \"price_agent\"\n",
    "- If query is perfume-related advice/recommendation (ì¶”ì²œ, í–¥ìˆ˜, ëƒ„ìƒˆ, í–¥, fragrance), choose \"consultation_agent\"  \n",
    "- If query is NOT about perfumes or is unclear/vague, choose \"human_fallback\"\n",
    "     \n",
    "\n",
    "Respond with ONLY the agent name.\"\"\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "def supervisor_node(state: AgentState) -> dict:\n",
    "    \"\"\"Supervisor ë…¸ë“œ\"\"\"\n",
    "    chain = supervisor_prompt | llm\n",
    "    result = chain.invoke(state)\n",
    "    \n",
    "    next_agent = result.content.strip()\n",
    "    if next_agent not in members:\n",
    "        next_agent = \"human_fallback\"  # ê¸°ë³¸ê°’\n",
    "    \n",
    "    return {\"next\": next_agent}\n",
    "\n",
    "# --- 4) Price Agent (ë„êµ¬ í¬í•¨) ---\n",
    "price_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a perfume price specialist assistant.\n",
    "    \n",
    "When users ask about perfume prices:\n",
    "1. Use the price_tool to search for current prices\n",
    "2. Always respond in Korean\n",
    "3. Format results nicely with emojis and clear information\n",
    "4. Be helpful and friendly\n",
    "    \n",
    "If you can't find price information, politely explain and suggest alternative searches.\"\"\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "price_agent = create_react_agent(\n",
    "    llm, \n",
    "    [price_tool],\n",
    "    prompt=price_prompt\n",
    ")\n",
    "\n",
    "# --- 5) Consultation Agent (ì¼ë°˜ ìƒë‹´) ---\n",
    "consultation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a knowledgeable and friendly perfume consultant.\n",
    "    \n",
    "Your expertise includes:\n",
    "- Perfume recommendations based on preferences, occasions, seasons\n",
    "- Fragrance families and notes explanation\n",
    "- Perfume wearing tips and application advice\n",
    "- Brand and fragrance history knowledge\n",
    "\n",
    "Always respond in Korean with:\n",
    "- Warmth and professionalism\n",
    "- Helpful and detailed advice\n",
    "- Relevant examples and suggestions\n",
    "- Encouraging tone\n",
    "\n",
    "If questions are too vague, politely ask for more specific information to provide better recommendations.\"\"\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "consultation_agent = create_react_agent(\n",
    "    llm,\n",
    "    [],  # ë„êµ¬ ì—†ìŒ\n",
    "    prompt=consultation_prompt\n",
    ")\n",
    "\n",
    "# --- 6) Human Fallback Node ---\n",
    "def human_fallback_node(state: AgentState) -> dict:\n",
    "    \"\"\"í–¥ìˆ˜ì™€ ê´€ë ¨ ì—†ê±°ë‚˜ ë¶ˆëª…í™•í•œ ì§ˆë¬¸ ì²˜ë¦¬\"\"\"\n",
    "    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ì—ì„œ ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ\n",
    "    messages = state.get(\"messages\", [])\n",
    "    user_input = \"\"\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            user_input = msg.content\n",
    "            break\n",
    "    \n",
    "    # human_fallback í•¨ìˆ˜ í˜¸ì¶œ (state dict í˜•íƒœë¡œ ì „ë‹¬)\n",
    "    fallback_result = human_fallback({\"input\": user_input})\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì‘ë‹µ ìƒì„±\n",
    "    response_msg = HumanMessage(content=fallback_result)\n",
    "    \n",
    "    return {\"messages\": [response_msg]}\n",
    "\n",
    "# --- 7) ì—ì´ì „íŠ¸ í˜¸ì¶œ ë˜í¼ ---\n",
    "def price_agent_node(state: AgentState) -> dict:\n",
    "    \"\"\"Price agent í˜¸ì¶œ\"\"\"\n",
    "    result = price_agent.invoke(state)\n",
    "    return {\"messages\": result[\"messages\"]}\n",
    "\n",
    "def consultation_agent_node(state: AgentState) -> dict:\n",
    "    \"\"\"Consultation agent í˜¸ì¶œ\"\"\"\n",
    "    result = consultation_agent.invoke(state)\n",
    "    return {\"messages\": result[\"messages\"]}\n",
    "\n",
    "# --- 8) Graph êµ¬ì„± ---\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"supervisor\", supervisor_node)\n",
    "workflow.add_node(\"price_agent\", price_agent_node)\n",
    "workflow.add_node(\"consultation_agent\", consultation_agent_node)\n",
    "workflow.add_node(\"human_fallback\", human_fallback_node)\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€: supervisor â†’ agents\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"price_agent\": \"price_agent\",\n",
    "        \"consultation_agent\": \"consultation_agent\",\n",
    "        \"human_fallback\": \"human_fallback\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# ê° ì—ì´ì „íŠ¸ì—ì„œ ENDë¡œ\n",
    "workflow.add_edge(\"price_agent\", END)\n",
    "workflow.add_edge(\"consultation_agent\", END)\n",
    "workflow.add_edge(\"human_fallback\", END)\n",
    "\n",
    "# ì‹œì‘ì \n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "# ì»´íŒŒì¼\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9b6d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Query] ì˜¤ëŠ˜ ì ì‹¬ ë­ì•¼\n",
      "\n",
      "--- Node: supervisor ---\n",
      "next: human_fallback\n",
      "\n",
      "--- Node: human_fallback ---\n",
      "messages: [HumanMessage(content=\"â“ 'ì˜¤ëŠ˜ ì ì‹¬ ë­ì•¼' ë” ëª…í™•í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\\nğŸ‘‰ ì§ˆë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\\nğŸ’¡ ë˜ëŠ” í–¥ìˆ˜ì— ê´€í•œ ë©‹ì§„ ì§ˆë¬¸ì„ í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?\", additional_kwargs={}, response_metadata={})]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 9) ì‹¤í–‰ í…ŒìŠ¤íŠ¸ ---\n",
    "\n",
    "query = \"ì˜¤ëŠ˜ ì ì‹¬ ë­ì•¼\"\n",
    "print(f\"\\n[Query] {query}\\n\")\n",
    "\n",
    "for step in app.stream({\"messages\": [HumanMessage(content=query)]}, stream_mode=\"updates\"):\n",
    "    for node, state in step.items():\n",
    "        print(f\"--- Node: {node} ---\")\n",
    "        for k, v in state.items():\n",
    "            print(f\"{k}: {v}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884d6554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Raw State ===\n",
      "{'messages': [HumanMessage(content='20ë§Œì›ëŒ€ í–¥ìˆ˜ ì¶”ì²œì¢€ ê°€ê²©ê³¼í•¨ê»˜ ì•Œë ¤ì¤„ë˜', additional_kwargs={}, response_metadata={}, id='2d74fb16-24b3-48e6-9cf8-cc78361d169a'), HumanMessage(content='20ë§Œì›ëŒ€ í–¥ìˆ˜ ì¶”ì²œì¢€ ê°€ê²©ê³¼í•¨ê»˜ ì•Œë ¤ì¤„ë˜', additional_kwargs={}, response_metadata={}, id='2d74fb16-24b3-48e6-9cf8-cc78361d169a'), AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! 20ë§Œì›ëŒ€ì˜ í–¥ìˆ˜ë¥¼ ì°¾ê³  ê³„ì‹œêµ°ìš”. ì—¬ëŸ¬ ê°€ì§€ ë©‹ì§„ ì„ íƒì§€ê°€ ìˆìŠµë‹ˆë‹¤. ëª‡ ê°€ì§€ ì¶”ì²œë“œë¦´ê²Œìš”.\\n\\n1. **ì¡°ë§ë¡  ëŸ°ë˜ - í”¼ì˜¤ë‹ˆ ì•¤ ë¸”ëŸ¬ì‰¬ ìŠ¤ì›¨ì´ë“œ (Peony & Blush Suede)**\\n   - ê°€ê²©: ì•½ 18ë§Œì›\\n   - íŠ¹ì§•: ë¶€ë“œëŸ¬ìš´ í”¼ì˜¤ë‹ˆì™€ ì‚¬ê³¼ì˜ ì¡°í™”ê°€ ë§¤ë ¥ì ì¸ í”Œë¡œëŸ´ ê³„ì—´ì˜ í–¥ìˆ˜ì…ë‹ˆë‹¤. ìš°ì•„í•˜ê³  ì—¬ì„±ìŠ¤ëŸ¬ìš´ ëŠë‚Œì„ ì£¼ë©°, ë°ì¼ë¦¬ë¡œ ì‚¬ìš©í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤.\\n\\n2. **ë””ì˜¬ - ë¯¸ìŠ¤ ë””ì˜¬ ë¸”ë£¨ë° ë¶€ì¼€ (Miss Dior Blooming Bouquet)**\\n   - ê°€ê²©: ì•½ 19ë§Œì›\\n   - íŠ¹ì§•: ìƒí¼í•œ ê³¼ì¼ê³¼ í”Œë¡œëŸ´ ë…¸íŠ¸ê°€ ì–´ìš°ëŸ¬ì ¸ ì‚¬ë‘ìŠ¤ëŸ½ê³  ê²½ì¾Œí•œ ëŠë‚Œì„ ì¤ë‹ˆë‹¤. ë´„ê³¼ ì—¬ë¦„ì— íŠ¹íˆ ì˜ ì–´ìš¸ë¦¬ëŠ” í–¥ìˆ˜ì…ë‹ˆë‹¤.\\n\\n3. **ê²ì¡° - í”Œë¼ì›Œë°”ì´ê²ì¡° (Flower by Kenzo)**\\n   - ê°€ê²©: ì•½ 17ë§Œì›\\n   - íŠ¹ì§•: íŒŒìš°ë”ë¦¬í•œ í”Œë¡œëŸ´ í–¥ìœ¼ë¡œ, ë…íŠ¹í•œ ë§¤ë ¥ì„ ì§€ë‹ˆê³  ìˆìŠµë‹ˆë‹¤. íŠ¹ë³„í•œ ë‚ ì´ë‚˜ ì €ë… ì™¸ì¶œì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤.\\n\\n4. **ìƒ¤ë„¬ - ìƒ¹ìŠ¤ ì˜¤ ë•…ë“œë ˆ (Chance Eau Tendre)**\\n   - ê°€ê²©: ì•½ 20ë§Œì›\\n   - íŠ¹ì§•: ìƒí¼í•˜ê³  ë¶€ë“œëŸ¬ìš´ ê³¼ì¼ê³¼ í”Œë¡œëŸ´ ë…¸íŠ¸ê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, ê²½ì¾Œí•œ ëŠë‚Œì„ ì¤ë‹ˆë‹¤. ë°ì¼ë¦¬ë¡œ ì‚¬ìš©í•˜ê¸°ì— ì í•©í•©ë‹ˆë‹¤.\\n\\nì´ ì™¸ì—ë„ ë‹¤ì–‘í•œ í–¥ìˆ˜ê°€ ìˆìœ¼ë‹ˆ, ì–´ë–¤ í–¥ì„ ì„ í˜¸í•˜ì‹œëŠ”ì§€, ë˜ëŠ” ì–´ë–¤ ìƒí™©ì—ì„œ ì‚¬ìš©í•˜ê³  ì‹¶ìœ¼ì‹ ì§€ ë§ì”€í•´ ì£¼ì‹œë©´ ë” êµ¬ì²´ì ì¸ ì¶”ì²œì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í–¥ìˆ˜ëŠ” ê°œì¸ì˜ ì·¨í–¥ì— ë”°ë¼ ë‹¤ë¥´ê¸° ë•Œë¬¸ì—, ì—¬ëŸ¬ ê°€ì§€ë¥¼ ì‹œí–¥í•´ ë³´ì‹œëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 433, 'prompt_tokens': 120, 'total_tokens': 553, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CAqUwR2xJijlvTBoIqO7hIj0mptg1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b3cdca78-a572-42d3-b1cc-cda61959a416-0', usage_metadata={'input_tokens': 120, 'output_tokens': 433, 'total_tokens': 553, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'next': 'consultation_agent'}\n",
      "\n",
      "=== Final Answer ===\n",
      "ì•ˆë…•í•˜ì„¸ìš”! 20ë§Œì›ëŒ€ì˜ í–¥ìˆ˜ë¥¼ ì°¾ê³  ê³„ì‹œêµ°ìš”. ì—¬ëŸ¬ ê°€ì§€ ë©‹ì§„ ì„ íƒì§€ê°€ ìˆìŠµë‹ˆë‹¤. ëª‡ ê°€ì§€ ì¶”ì²œë“œë¦´ê²Œìš”.\n",
      "\n",
      "1. **ì¡°ë§ë¡  ëŸ°ë˜ - í”¼ì˜¤ë‹ˆ ì•¤ ë¸”ëŸ¬ì‰¬ ìŠ¤ì›¨ì´ë“œ (Peony & Blush Suede)**\n",
      "   - ê°€ê²©: ì•½ 18ë§Œì›\n",
      "   - íŠ¹ì§•: ë¶€ë“œëŸ¬ìš´ í”¼ì˜¤ë‹ˆì™€ ì‚¬ê³¼ì˜ ì¡°í™”ê°€ ë§¤ë ¥ì ì¸ í”Œë¡œëŸ´ ê³„ì—´ì˜ í–¥ìˆ˜ì…ë‹ˆë‹¤. ìš°ì•„í•˜ê³  ì—¬ì„±ìŠ¤ëŸ¬ìš´ ëŠë‚Œì„ ì£¼ë©°, ë°ì¼ë¦¬ë¡œ ì‚¬ìš©í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ë””ì˜¬ - ë¯¸ìŠ¤ ë””ì˜¬ ë¸”ë£¨ë° ë¶€ì¼€ (Miss Dior Blooming Bouquet)**\n",
      "   - ê°€ê²©: ì•½ 19ë§Œì›\n",
      "   - íŠ¹ì§•: ìƒí¼í•œ ê³¼ì¼ê³¼ í”Œë¡œëŸ´ ë…¸íŠ¸ê°€ ì–´ìš°ëŸ¬ì ¸ ì‚¬ë‘ìŠ¤ëŸ½ê³  ê²½ì¾Œí•œ ëŠë‚Œì„ ì¤ë‹ˆë‹¤. ë´„ê³¼ ì—¬ë¦„ì— íŠ¹íˆ ì˜ ì–´ìš¸ë¦¬ëŠ” í–¥ìˆ˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "3. **ê²ì¡° - í”Œë¼ì›Œë°”ì´ê²ì¡° (Flower by Kenzo)**\n",
      "   - ê°€ê²©: ì•½ 17ë§Œì›\n",
      "   - íŠ¹ì§•: íŒŒìš°ë”ë¦¬í•œ í”Œë¡œëŸ´ í–¥ìœ¼ë¡œ, ë…íŠ¹í•œ ë§¤ë ¥ì„ ì§€ë‹ˆê³  ìˆìŠµë‹ˆë‹¤. íŠ¹ë³„í•œ ë‚ ì´ë‚˜ ì €ë… ì™¸ì¶œì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤.\n",
      "\n",
      "4. **ìƒ¤ë„¬ - ìƒ¹ìŠ¤ ì˜¤ ë•…ë“œë ˆ (Chance Eau Tendre)**\n",
      "   - ê°€ê²©: ì•½ 20ë§Œì›\n",
      "   - íŠ¹ì§•: ìƒí¼í•˜ê³  ë¶€ë“œëŸ¬ìš´ ê³¼ì¼ê³¼ í”Œë¡œëŸ´ ë…¸íŠ¸ê°€ ì¡°í™”ë¥¼ ì´ë£¨ë©°, ê²½ì¾Œí•œ ëŠë‚Œì„ ì¤ë‹ˆë‹¤. ë°ì¼ë¦¬ë¡œ ì‚¬ìš©í•˜ê¸°ì— ì í•©í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì™¸ì—ë„ ë‹¤ì–‘í•œ í–¥ìˆ˜ê°€ ìˆìœ¼ë‹ˆ, ì–´ë–¤ í–¥ì„ ì„ í˜¸í•˜ì‹œëŠ”ì§€, ë˜ëŠ” ì–´ë–¤ ìƒí™©ì—ì„œ ì‚¬ìš©í•˜ê³  ì‹¶ìœ¼ì‹ ì§€ ë§ì”€í•´ ì£¼ì‹œë©´ ë” êµ¬ì²´ì ì¸ ì¶”ì²œì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í–¥ìˆ˜ëŠ” ê°œì¸ì˜ ì·¨í–¥ì— ë”°ë¼ ë‹¤ë¥´ê¸° ë•Œë¬¸ì—, ì—¬ëŸ¬ ê°€ì§€ë¥¼ ì‹œí–¥í•´ ë³´ì‹œëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "query = \"20ë§Œì›ëŒ€ í–¥ìˆ˜ ì¶”ì²œì¢€ ê°€ê²©ê³¼í•¨ê»˜ ì•Œë ¤ì¤„ë˜\"\n",
    "\n",
    "result = app.invoke({\"messages\": [HumanMessage(content=query)]})\n",
    "\n",
    "# ì „ì²´ state í™•ì¸\n",
    "print(\"=== Raw State ===\")\n",
    "print(result)\n",
    "\n",
    "# ë§ˆì§€ë§‰ AI ì‘ë‹µë§Œ ì¶”ì¶œ\n",
    "msgs = result.get(\"messages\", [])\n",
    "last_ai = next((m for m in reversed(msgs) if isinstance(m, AIMessage)), None)\n",
    "if last_ai:\n",
    "    print(\"\\n=== Final Answer ===\")\n",
    "    print(last_ai.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
