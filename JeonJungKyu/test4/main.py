# --- stdlib ---
import json
import os
# --- typing ---
from typing import TypedDict, List, Optional, Dict, Any

# --- env ---
from dotenv import load_dotenv
from config import llm, embeddings, index, MODEL_NAME, pc


# --- langchain / langgraph ---
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, END

# --- services (ì¿¼ë¦¬ íŒŒì‹±/í•„í„°/ê²€ìƒ‰/ì‘ë‹µ/ê°€ê²© í‚¤ì›Œë“œ) ---
from tools import run_llm_parser
from tools import apply_meta_filters
from tools import query_pinecone
from tools import generate_response
from tools import extract_price_search_keywords

# --- tools (Naver ê°€ê²©/ML ì¶”ì²œ) ---
from tools import price_tool, recommend_perfume_simple
load_dotenv()


SUPERVISOR_SYSTEM_PROMPT = """
You are the "Perfume Recommendation Supervisor (Router)". Analyze the user's query (Korean or English) and route to exactly ONE agent below.

[Agents]
- LLM_parser         : Parses/normalizes multi-facet queries (2+ product facets).
- FAQ_agent          : Perfume knowledge / definitions / differences / general questions.
- human_fallback     : Non-perfume or off-topic queries.
- price_agent        : Price-only intents (cheapest, price, buy, discount, etc.).
- ML_agent           : Single-preference recommendations (mood/season vibe like "fresh summer", "sweet", etc.).

[Facets to detect ("product facets")]
- brand            (e.g., Chanel, Dior, Creed)
- season           (spring/summer/fall/winter; "for summer/winter")
- gender           (male/female/unisex)
- sizes            (volume in ml: 30/50/100 ml)
- day_night_score  (day/night/daily/office/club, etc.)
- concentration    (EDT/EDP/Extrait/Parfum/Cologne)

[Price intent keywords (not exhaustive)]
- Korean: ê°€ê²©, ì–¼ë§ˆ, ê°€ê²©ëŒ€, êµ¬ë§¤, íŒë§¤, í• ì¸, ì–´ë””ì„œ ì‚¬, ë°°ì†¡ë¹„
- English: price, cost, cheapest, buy, purchase, discount

[FAQ examples]
- Differences between EDP vs EDT, note definitions, longevity/projection, brand/line info.

[Single-preference (ML_agent) examples]
- "Recommend a cool perfume for summer", "Recommend a sweet scent", "One citrusy fresh pick"
  (= 0â€“1 of the above facets mentioned; primarily taste/mood/situation).


[Routing rules (priority)]
1) Non-perfume / off-topic â†’ human_fallback
2) Pure price-only intent (no product facets mentioned) â†’ price_agent
   e.g., "í–¥ìˆ˜ ê°€ê²© ì•Œë ¤ì¤˜" â†’ price_agent
3) Count product facets in the query:
   - If facets â‰¥ 2 â†’ LLM_parser (can handle price intent within multi-facet queries)
   - If facets = 1 AND has price intent â†’ LLM_parser (e.g., "ìƒ¤ë„¬ í–¥ìˆ˜ ê°€ê²©")
4) Otherwise (single-topic queries):
   - Pure price query with specific brand/product â†’ price_agent
   - Perfume knowledge/definitions â†’ FAQ_agent
   - Single taste/mood recommendation â†’ ML_agent
5) Tie-breakers:
   - If complex query (multiple aspects) â†’ LLM_parser
   - If pure price intent â†’ price_agent
   - Else: knowledge â†’ FAQ_agent, taste â†’ ML_agent

[Output format]
Return ONLY this JSON (no extra text):
{{
  "next": "<LLM_parser|FAQ_agent|human_fallback|price_agent|ML_agent>",
  "reason": "<one short English sentence>",
  "facet_count": <integer>,
  "facets": {{
    "brand": "<value or null>",
    "season": "<value or null>",
    "gender": "<value or null>",
    "sizes": "<value or null>",
    "day_night_score": "<value or null>",
    "concentration": "<value or null>"
  }},
  "scent_vibe": "<value if detected, else null>",
  "query_intent": "<price|faq|scent_pref|non_perfume|other>"
}}
""".strip()

# ---------- 1) State ----------
class AgentState(TypedDict):
    messages: List[BaseMessage]           # conversation log
    next: Optional[str]                   # routing decision key 
    router_json: Optional[Dict[str, Any]] # parsed JSON from router

router_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", SUPERVISOR_SYSTEM_PROMPT),
        ("user", "{query}")
    ]
)

def supervisor_node(state: AgentState) -> AgentState:
    """Call the router LLM and return parsed JSON + routing target."""
    user_query = None
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break
    if not user_query:
        user_query = "(empty)"

    chain = router_prompt | llm
    ai = chain.invoke({"query": user_query})
    text = ai.content

    # JSON strict parse
    chosen = "human_fallback"
    parsed: Dict[str, Any] = {}
    try:
        parsed = json.loads(text)
        maybe = parsed.get("next")
        if isinstance(maybe, str) and maybe in {"LLM_parser","FAQ_agent","human_fallback","price_agent","ML_agent"}:
            chosen = maybe
    except Exception:
        parsed = {"error": "invalid_json", "raw": text}

    msgs = state["messages"] + [AIMessage(content=text)]
    return {
        "messages": msgs,
        "next": chosen,
        "router_json": parsed
    }

# ---------- 4) Agent Nodes ----------
import re, json

BRAND_ALIASES = BRAND_ALIASES = {
    "ê²”ë‘": ["ê²”ë‘", "ê²Œë‘", "Guerlain"],
    "êµ¬ì°Œ": ["êµ¬ì°Œ", "Gucci"],
    "ëŒë¡œì—": ["ëŒë¡œì—", "ëŒë¡œ ì—", "ChloÃ©", "Chloe"],
    "ë‚˜ë¥´ì‹œì†Œ ë¡œë“œë¦¬ê²Œì¦ˆ": ["ë‚˜ë¥´ì‹œì†Œë¡œë“œë¦¬ê²Œì¦ˆ", "ë‚˜ë¥´ì‹œì†Œ ë¡œë“œë¦¬ê²Œì¦ˆ", "ë‚˜ë¥´ì‹œì†Œ", "ë¡œë“œë¦¬ê²Œì¦ˆ", "Narciso Rodriguez"],
    "ë‹ˆìƒ¤ë„¤": ["ë‹ˆìƒ¤ë„¤", "Nishane"],
    "ë„ë¥´ì„¸": ["ë„ë¥´ì„¸", "ë„ ë¥´ì„¸", "Dâ€™ORSAY", "D'ORSAY", "DORSAY"],
    "ë””ì˜¬": ["ë””ì˜¬", "í¬ë¦¬ìŠ¤ì°¬ë””ì˜¬", "í¬ë¦¬ìŠ¤ì°¬ ë””ì˜¬", "Dior", "Christian Dior"],
    "ë”¥í‹°í¬": ["ë”¥í‹°í¬", "Diptyque"],
    "ë‘ì½¤": ["ë‘ì½¤", "LancÃ´me", "Lancome"],
    "ë¡œë¼ ë©”ë¥´ì‹œì—": ["ë¡œë¼ë©”ë¥´ì‹œì—", "ë¡œë¼ ë©”ë¥´ì‹œì—", "Laura Mercier"],
    "ë¡œì—ë² ": ["ë¡œì—ë² ", "Loewe"],
    "ë¡ì‹œë•…": ["ë¡ì‹œë•…", "ë¡ì‹œíƒ•", "ë¡ ì‹œë•…", "Lâ€™Occitane", "L'Occitane", "LOccitane", "Lâ€™Occitane en Provence"],
    "ë¥´ ë¼ë³´": ["ë¥´ë¼ë³´", "ë¥´ ë¼ë³´", "Le Labo"],
    "ë©”ëª¨": ["ë©”ëª¨", "Memo", "Memo Paris"],
    "ë©”ì¢… ë§ˆë¥´ì§€ì—˜ë¼": ["ë©”ì¢…ë§ˆë¥´ì§€ì—˜ë¼", "ë©”ì¢… ë§ˆë¥´ì§€ì—˜ë¼", "ë§ˆë¥´ì§€ì—˜ë¼", "Maison Margiela"],
    "ë©”ì¢… í”„ë€ì‹œìŠ¤ ì»¤ì •": ["ë©”ì¢…í”„ë€ì‹œìŠ¤ì»¤ì •", "ë©”ì¢… í”„ë€ì‹œìŠ¤ ì»¤ì •", "í”„ë€ì‹œìŠ¤ ì»¤ì •", "ì— ì—í”„ì¼€ì´", "MFK", "Maison Francis Kurkdjian"],
    "ë©œë¦°ì•¤ê²Œì¸ ": ["ë©œë¦°ì•¤ê²Œì¸ ", "ë§ë¦°ì•¤ê²Œì¸ ", "ë©œë¦° ì•¤ ê²Œì¸ ", "Malin+Goetz", "Malin and Goetz", "Malin & Goetz"],
    "ë¯¸ìš°ë¯¸ìš°": ["ë¯¸ìš°ë¯¸ìš°", "ë¯¸ìš° ë¯¸ìš°", "Miu Miu"],
    "ë°”ì´ë ˆë„": ["ë°”ì´ë ˆë„", "Byredo"],
    "ë°˜í´ë¦¬í”„ ì•„í ": ["ë°˜í´ë¦¬í”„ì•„í ", "ë°˜í´ë¦¬í”„ ì•„í ", "ë°˜í´ë¦¬í”„ì•¤ì•„í ", "Van Cleef & Arpels", "Van Cleef and Arpels", "VCA"],
    "ë²„ë²„ë¦¬": ["ë²„ë²„ë¦¬", "Burberry"],
    "ë² ë¥´ì‚¬ì²´": ["ë² ë¥´ì‚¬ì²´", "Versace"],
    "ë¶ˆê°€ë¦¬": ["ë¶ˆê°€ë¦¬", "ë²Œê°€ë¦¬", "Bulgari", "BVLGARI"],
    "ë¹„ë””ì¼€ì´": ["ë¹„ë””ì¼€ì´", "BDK", "BDK Parfums"],
    "ì‚°íƒ€ ë§ˆë¦¬ì•„ ë…¸ë²¨ë¼": ["ì‚°íƒ€ë§ˆë¦¬ì•„ë…¸ë²¨ë¼", "ì‚°íƒ€ ë§ˆë¦¬ì•„ ë…¸ë²¨ë¼", "ë…¸ë²¨ë¼", "Santa Maria Novella", "SMN"],
    "ìƒ¤ë„¬": ["ìƒ¤ë„¬", "Chanel"],
    "ì„¸ë¥´ì£¼ ë£¨í…": ["ì„¸ë¥´ì£¼ë£¨í…", "ì„¸ë¥´ì£¼ ë£¨í…", "Serge Lutens"],
    "ì‹œìŠ¬ë¦¬ ì½”ìŠ¤ë©”í‹±": ["ì‹œìŠ¬ë¦¬", "ì‹œìŠ¬ë¦¬ì½”ìŠ¤ë©”í‹±", "ì‹œìŠ¬ë¦¬ ì½”ìŠ¤ë©”í‹±", "Sisley", "Sisley Paris"],
    "ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ": ["ì•„ì¿ ì•„ë””íŒŒë¥´ë§ˆ", "ì•„ì¿ ì•„ ë”” íŒŒë¥´ë§ˆ", "Acqua di Parma", "AdP"],
    "ì—ë”° ë¦¬ë¸Œë¥´ ë„ëŸ‰ì¥¬": ["ì—ë”°ë¦¬ë¸Œë¥´ë„ë‘ì¥¬", "ì—ë”° ë¦¬ë¸Œë¥´ ë„ëŸ‰ì¥¬", "ì—ë”°ë¦¬ë¸Œë¥´", "Etat Libre dâ€™Orange", "Etat Libre d'Orange", "ELDO"],
    "ì—ë¥´ë©”ìŠ¤": ["ì—ë¥´ë©”ìŠ¤", "HermÃ¨s", "Hermes"],
    "ì—ìŠ¤í‹° ë¡œë”": ["ì—ìŠ¤í‹°ë¡œë”", "ì—ìŠ¤í‹° ë¡œë”", "Estee Lauder", "EstÃ©e Lauder"],
    "ì—‘ìŠ¤ ë‹ˆíë¡œ": ["ì—‘ìŠ¤ë‹ˆíë¡œ", "ì—‘ìŠ¤ ë‹ˆíë¡œ", "Ex Nihilo"],
    "ì´ë‹ˆì‹œì˜¤ í¼í“¸": ["ì´ë‹ˆì‹œì˜¤", "ì´ë‹ˆì‹œì˜¤ í¼í“¸", "Initio", "Initio Parfums Prives"],
    "ì´ì†": ["ì´ì†", "Aesop"],
    "ì…ìƒë¡œë‘": ["ì…ìƒë¡œë‘", "ì… ìƒë¡œë‘", "ì´ë¸Œìƒë¡œë‘", "ì´ë¸Œ ìƒ ë¡œë‘", "ìƒë¡œë‘", "YSL", "Yves Saint Laurent", "Saint Laurent"],
    "ì œë¥´ì¡°í”„": ["ì œë¥´ì¡°í”„", "Xerjoff"],
    "ì¡° ë§ë¡ ": ["ì¡°ë§ë¡ ", "ì¡° ë§ë¡ ", "Jo Malone", "Jo Malone London", "JML"],
    "ì¡°ë¥´ì§€ì˜¤ ì•„ë¥´ë§ˆë‹ˆ": ["ì¡°ë¥´ì§€ì˜¤ì•„ë¥´ë§ˆë‹ˆ", "ì¡°ë¥´ì§€ì˜¤ ì•„ë¥´ë§ˆë‹ˆ", "ì•„ë¥´ë§ˆë‹ˆ", "Giorgio Armani", "Armani"],
    "ì¤„ë¦¬ì—£ í—¤ì¦ˆ ì–´ ê±´": ["ì¤„ë¦¬ì—£í—¤ì¦ˆì–´ê±´", "ì¤„ë¦¬ì—£ í—¤ì¦ˆ ì–´ ê±´", "Juliette Has A Gun", "JHAG"],
    "ì§€ë°©ì‹œ": ["ì§€ë°©ì‹œ", "Givenchy"],
    "ì§ˆ ìŠ¤íŠœì–´íŠ¸": ["ì§ˆìŠ¤íŠœì–´íŠ¸", "ì§ˆ ìŠ¤íŠœì–´íŠ¸", "Jill Stuart"],
    "í¬ë¦¬ë“œ": ["í¬ë¦¬ë“œ", "Creed"],
    "í‚¬ë¦¬ì•ˆ": ["í‚¬ë¦¬ì•ˆ", "Kilian", "Kilian Paris"],
    "í†° í¬ë“œ": ["í†°í¬ë“œ", "í†° í¬ë“œ", "í†°í¬ ë“œ", "í†° í¬ ë“œ", "Tom Ford"],
    "í‹°íŒŒë‹ˆì•¤ì½”": ["í‹°íŒŒë‹ˆì•¤ì½”", "í‹°íŒŒë‹ˆ ì•¤ ì½”", "í‹°íŒŒë‹ˆ", "Tiffany & Co.", "Tiffany and Co.", "Tiffany"],
    "í¼í“¸ ë“œ ë§ë¦¬": ["í¼í“¸ë“œë§ë¦¬", "í¼í“¸ ë“œ ë§ë¦¬", "ë§ë¦¬", "Parfums de Marly", "PDM"],
    "íœí• ë¦¬ê³¤ìŠ¤": ["íœí• ë¦¬ê³¤ìŠ¤", "íœí• ë¦¬ê³¤ì¦ˆ", "Penhaligonâ€™s", "Penhaligon's", "Penhaligons"],
    "í”„ë¼ë‹¤": ["í”„ë¼ë‹¤", "Prada"],
    "í”„ë ˆë°ë¦­ ë§": ["í”„ë ˆë°ë¦­ë§", "í”„ë ˆë°ë¦­ ë§", "Frederic Malle", "FrÃ©dÃ©ric Malle"],
}
CONC_SYNONYMS = {
    "ì˜¤ ë“œ í¼í“¸": ["ì˜¤ ë“œ í¼í“¸", "ì˜¤ë“œí¼í“¸", "EDP", "eau de parfum"],
    "ì˜¤ ë“œ ëšœì™ˆë ›": ["ì˜¤ ë“œ ëšœì™ˆë ›", "ì˜¤ë“œëšœì™ˆë ›", "EDT", "eau de toilette"],
    "ì˜¤ ë“œ ê¼´ë¡œë‰´": ["ì˜¤ ë“œ ê¼´ë¡œë‰´", "EDC", "eau de cologne"],
    "íŒŒë¥´í­": ["íŒŒë¥´í­", "Parfum", "Extrait", "Extrait de Parfum"],
}

def _normalize_size(size_val):
    """'50' -> '50ml', '50 ml' -> '50ml'"""
    if not size_val:
        return None
    s = str(size_val).strip().lower().replace(" ", "")
    if s.endswith("ml"):
        return s
    if re.fullmatch(r"\d{1,4}", s):
        return s + "ml"
    return s

def _expand_brand(brand):
    if not brand:
        return []
    return BRAND_ALIASES.get(brand, [brand])

def _expand_concentration(conc):
    if not conc:
        return []
    c = str(conc)
    for k, syns in CONC_SYNONYMS.items():
        if k.replace(" ", "") in c.replace(" ", "") or c in syns:
            return syns
    return [c]

def _extract_matches(search_results: dict):
    """Pinecone matches -> list of metadata dict"""
    matches = (search_results or {}).get("matches") or []
    return [m.get("metadata") or {} for m in matches]

def _make_display_name(meta, size=None):
    brand = (meta.get("brand") or "").strip()
    name  = (meta.get("name") or "").strip()
    conc  = (meta.get("concentration") or "").strip()
    toks = [brand, name, conc, size]
    return " ".join([t for t in toks if t])

def build_item_queries_from_vectordb(
    search_results: dict,
    facets: dict | None = None,
    top_n_items: int = 5,
) -> list[dict]:
    """
    ë°˜í™˜: [{item_label, queries}] ë¦¬ìŠ¤íŠ¸
    - item_label: ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë¼ë²¨(brand name conc size)
    - queries: ì´ ì•„ì´í…œë§Œì„ ê²¨ëƒ¥í•œ ë„¤ì´ë²„ ê²€ìƒ‰ í›„ë³´ë“¤(ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸)
    (â€» ë¸Œëœë“œ+ì œí’ˆëª… í•„ìˆ˜. ë‹¤ë¥¸ ì œí’ˆìœ¼ë¡œ ìƒ ì—¬ì§€ë¥¼ ìµœì†Œí™”)
    """
    facets = facets or {}
    target_size = _normalize_size(facets.get("sizes"))
    metas = _extract_matches(search_results)[:top_n_items]

    results = []
    seen_items = set()  # (brand|name)ë¡œ ì¤‘ë³µ ì œê±°

    for meta in metas:
        brand = meta.get("brand")
        name  = meta.get("name")
        conc  = meta.get("concentration")
        sizes = meta.get("sizes")

        if not brand or not name:
            continue

        key = f"{brand}|{name}"
        if key in seen_items:
            continue
        seen_items.add(key)

        size_for_query = target_size
        if not size_for_query:
            if isinstance(sizes, (list, tuple)) and sizes:
                if "50" in sizes or "50ml" in sizes:
                    size_for_query = "50ml"
                else:
                    size_for_query = _normalize_size(sizes[0])

        brand_variants = _expand_brand(brand)
        conc_variants  = _expand_concentration(conc) if conc else []

        def join(*toks): return " ".join([t for t in toks if t and str(t).strip()])
        qs = []

        # A. ë¸Œëœë“œ + ì œí’ˆëª… + ë†ë„ + ì‚¬ì´ì¦ˆ
        if brand_variants and name and conc_variants and size_for_query:
            for b in brand_variants:
                for c in conc_variants:
                    qs.append(join(b, name, c, size_for_query))

        # B. ë¸Œëœë“œ + ì œí’ˆëª… + ì‚¬ì´ì¦ˆ
        if brand_variants and name and size_for_query:
            for b in brand_variants:
                qs.append(join(b, name, size_for_query))

        # C. ë¸Œëœë“œ + ì œí’ˆëª… (ë°±ì—…)
        if brand_variants and name:
            for b in brand_variants:
                qs.append(join(b, name))

        # ì¤‘ë³µ ì œê±°
        seen, deduped = set(), []
        for q in qs:
            if q not in seen:
                seen.add(q)
                deduped.append(q)

        results.append({
            "item_label": _make_display_name(meta, size_for_query),
            "queries": deduped[:6],
        })

    return results


# ========= LLM_parser_node (ê°€ê²© ê²€ìƒ‰ íŒŒíŠ¸: vectorDB ì•„ì´í…œë§Œ ì‚¬ìš©) =========
def LLM_parser_node(state: AgentState) -> AgentState:
    """ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ëŠ” LLM_parser ë…¸ë“œ + ê°€ê²© ê²€ìƒ‰(ë²¡í„°DB í•œì •) í†µí•©"""
    user_query = None
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break
    if not user_query:
        user_query = "(empty)"

    try:
        print(f"ğŸ” LLM_parser ì‹¤í–‰: {user_query}")
        
        # 1ë‹¨ê³„: LLMìœ¼ë¡œ ì¿¼ë¦¬ íŒŒì‹±
        parsed_json = run_llm_parser(user_query)
        if "error" in parsed_json:
            error_msg = f"[LLM_parser] ì¿¼ë¦¬ íŒŒì‹± ì˜¤ë¥˜: {parsed_json['error']}"
            msgs = state["messages"] + [AIMessage(content=error_msg)]
            return {"messages": msgs, "next": None, "router_json": state.get("router_json")}
        
        # 2ë‹¨ê³„: ë©”íƒ€í•„í„° ì ìš©
        filtered_json = apply_meta_filters(parsed_json)
        
        # 3ë‹¨ê³„: ì¿¼ë¦¬ ë²¡í„°í™”
        query_vector = embeddings.embed_query(user_query)
        
        # 4ë‹¨ê³„: Pinecone ê²€ìƒ‰
        search_results = query_pinecone(query_vector, filtered_json, top_k=5)
        
        # 5ë‹¨ê³„: ìµœì¢… ì‘ë‹µ ìƒì„±
        final_response = generate_response(user_query, search_results)
        
        # 6ë‹¨ê³„: ê°€ê²© ì˜ë„ ê°ì§€
        price_keywords_ko = ['ê°€ê²©', 'ì–¼ë§ˆ', 'ê°€ê²©ëŒ€', 'êµ¬ë§¤', 'íŒë§¤', 'í• ì¸', 'ì–´ë””ì„œ ì‚¬', 'ì–´ë””ì„œì‚¬', 'ë°°ì†¡ë¹„', 'ìµœì €ê°€']
        price_keywords_en = ['price', 'cost', 'cheapest', 'buy', 'purchase', 'discount']
        lower = user_query.lower()
        has_price_intent = any(k in user_query for k in price_keywords_ko) or any(k in lower for k in price_keywords_en)
        
        if has_price_intent:
            # ğŸ”’ vectorDBì—ì„œ ê²€ìƒ‰ëœ ì•„ì´í…œë§Œìœ¼ë¡œ ê°€ê²© ì¿¼ë¦¬ ìƒì„±
            item_query_bundles = build_item_queries_from_vectordb(
                search_results=search_results,
                facets=parsed_json,
                top_n_items=5
            )
            print("ğŸ’° ê°€ê²© ê²€ìƒ‰(ë²¡í„°DB í•œì •) ëŒ€ìƒ:")
            for b in item_query_bundles:
                print(f" - {b['item_label']} :: {b['queries'][:3]}")

            price_sections = []
            for bundle in item_query_bundles:
                label = bundle["item_label"]
                queries = bundle["queries"]
                found_block = None

                for q in queries:
                    try:
                        res = price_tool.invoke({"user_query": q})
                        if res:  # í•„ìš”ì‹œ res í¬ë§·ì— ë§ì¶˜ ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€
                            found_block = f"ğŸ” **{label}**\n(ê²€ìƒ‰ì–´: `{q}`)\n{res}"
                            break
                    except Exception as price_error:
                        print(f"âŒ ê°€ê²© ê²€ìƒ‰ ì˜¤ë¥˜({q}): {price_error}")
                        continue

                if found_block:
                    price_sections.append(found_block)

            if price_sections:
                final_response_with_price = f"""{final_response}

---

ğŸ’° **ê°€ê²© ì •ë³´ (vectorDB ì¶”ì²œë§Œ)**
{'\n\n'.join(price_sections)}"""
            else:
                final_response_with_price = f"""{final_response}

---

ğŸ’° **ê°€ê²© ì •ë³´ (vectorDB ì¶”ì²œë§Œ)**
ğŸ” ë²¡í„°DBì—ì„œ ì¶”ì²œëœ ì œí’ˆëª…ìœ¼ë¡œ ê²€ìƒ‰í–ˆì§€ë§Œ, ì¼ì¹˜ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”.
ì›í•˜ì‹œëŠ” **ì œí’ˆëª… + ë†ë„ + ìš©ëŸ‰(ì˜ˆ: 50ml)** ì¡°í•©ìœ¼ë¡œ ë‹¤ì‹œ ì•Œë ¤ì£¼ì„¸ìš”."""
        else:
            final_response_with_price = final_response
        
        # ê²°ê³¼ ìš”ì•½
        summary = f"""[LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ âœ…

ğŸ“Š íŒŒì‹± ê²°ê³¼: {json.dumps(parsed_json, ensure_ascii=False)}
ğŸ” í•„í„°ë§ ê²°ê³¼: {json.dumps(filtered_json, ensure_ascii=False)}
ğŸ¯ ê²€ìƒ‰ëœ í–¥ìˆ˜ ê°œìˆ˜: {len(search_results.get('matches', []))}

ğŸ’¬ ì¶”ì²œ ê²°ê³¼:
{final_response_with_price}"""

        msgs = state["messages"] + [AIMessage(content=summary)]
        return {"messages": msgs, "next": None, "router_json": state.get("router_json")}
        
    except Exception as e:
        error_msg = f"[LLM_parser] RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        print(f"âŒ LLM_parser ì „ì²´ ì˜¤ë¥˜: {e}")
        msgs = state["messages"] + [AIMessage(content=error_msg)]
        return {"messages": msgs, "next": None, "router_json": state.get("router_json")}
    
    
def human_fallback_node(state: AgentState) -> AgentState:
    """í–¥ìˆ˜ ê´€ë ¨ ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ê¸°ë³¸ ì‘ë‹µ"""
    user_query = None
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break
    if not user_query:
        user_query = "(empty)"
    
    fallback_response = (
        f"â“ '{user_query}' ë” ëª…í™•í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n"
        f"ğŸ‘‰ ì§ˆë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n"
        f"ğŸ’¡ ë˜ëŠ” í–¥ìˆ˜ì— ê´€í•œ ë©‹ì§„ ì§ˆë¬¸ì„ í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?"
    )
    
    msgs = state["messages"] + [AIMessage(content=fallback_response)]
    return {"messages": msgs, "next": None, "router_json": state.get("router_json")}

# ---------- 5) ì§ì ‘ ë„êµ¬ í˜¸ì¶œ ë°©ì‹ìœ¼ë¡œ ì—ì´ì „íŠ¸ êµ¬í˜„ ----------
def price_agent_node(state: AgentState) -> AgentState:
    """Price agent - ì§ì ‘ ë„êµ¬ í˜¸ì¶œ"""
    user_query = None
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break
    if not user_query:
        user_query = "(empty)"
    
    try:
        # ì§ì ‘ price_tool í˜¸ì¶œ
        price_result = price_tool.invoke({"user_query": user_query})
        
        # ê²°ê³¼ë¥¼ ë” ìì—°ìŠ¤ëŸ½ê²Œ í¬ë§·íŒ…
        final_answer = f"ğŸ’° **ê°€ê²© ì •ë³´**\n\n{price_result}"
        
        msgs = state["messages"] + [AIMessage(content=final_answer)]
        return {
            "messages": msgs, 
            "next": None, 
            "router_json": state.get("router_json")
        }
    except Exception as e:
        error_msg = f"âŒ ê°€ê²© ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        msgs = state["messages"] + [AIMessage(content=error_msg)]
        return {
            "messages": msgs, 
            "next": None, 
            "router_json": state.get("router_json")
        }

def FAQ_agent_node(state: AgentState) -> AgentState:
    """FAQ agent - LLM ê¸°ë³¸ ì§€ì‹ìœ¼ë¡œ í–¥ìˆ˜ ê´€ë ¨ ì§ˆë¬¸ ë‹µë³€"""
    user_query = None
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break
    if not user_query:
        user_query = "(empty)"
    
    try:
        # LLMì—ê²Œ í–¥ìˆ˜ ì§€ì‹ ì „ë¬¸ê°€ë¡œì„œ ë‹µë³€í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        faq_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a perfume expert. Provide accurate and helpful information for usersâ€™ perfume-related questions.

You can cover topics such as:
- Perfume types and concentrations (EDT, EDP, Parfum, etc.)
- Fragrance notes and ingredients (top/middle/base) and their roles
- Brand characteristics and signature fragrances
- How to apply and store perfumes properly
- Tips for choosing perfumes by season and occasion
- Longevity (lasting power) and projection/sillage

Keep your tone friendly, explanations easy to understand, and include practical, actionable advice.
Please answer in Korean."""),
            ("user", "{question}")
        ])
        
        chain = faq_prompt | llm
        result = chain.invoke({"question": user_query})
        
        # ê²°ê³¼ë¥¼ í¬ë§·íŒ…
        final_answer = f"ğŸ“š **í–¥ìˆ˜ ì§€ì‹**\n\n{result.content}"
        
        msgs = state["messages"] + [AIMessage(content=final_answer)]
        return {
            "messages": msgs, 
            "next": None, 
            "router_json": state.get("router_json")
        }
    except Exception as e:
        error_msg = f"âŒ í–¥ìˆ˜ ì§€ì‹ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        msgs = state["messages"] + [AIMessage(content=error_msg)]
        return {
            "messages": msgs, 
            "next": None, 
            "router_json": state.get("router_json")
        }

def ML_agent_node(state: AgentState) -> AgentState:
    """ML agent - recommend_perfume_simple ë„êµ¬ í˜¸ì¶œ í›„, LLMì´ ì„¤ëª…ë¬¸ ìƒì„±ê¹Œì§€ ìˆ˜í–‰"""
    user_query = None
    for m in reversed(state["messages"]):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break
    if not user_query:
        user_query = "(empty)"

    try:
        # 1) ML ë„êµ¬ í˜¸ì¶œ (êµ¬ì¡°í™” ë°ì´í„° ë³´ì¡´)
        ml_result = recommend_perfume_simple.invoke({"user_text": user_query})
        # ì˜ˆìƒ êµ¬ì¡°: {"recommendations": [...], "predicted_labels": [...]}
        ml_json_str = json.dumps(ml_result, ensure_ascii=False)

        # 2) LLMì— ì»¨í…ìŠ¤íŠ¸ë¡œ ì „ë‹¬í•˜ì—¬ ìì—°ì–´ ë‹µë³€ ìƒì„±
        system_prompt = """
You are a perfume recommendation explainer. The JSON below is the ML model's recommendation output; base your response solely on that information and craft a concise, friendly answer.

- Summarize the top 3 picks aligned with the user's intent, each with a key reason.
- If predicted scent attributes are present, show them in one line.
- Suggest about two similar alternatives and a next step (e.g., ask about season/time-of-day/longevity preferences).
- Do not exaggerate or invent any facts not present in the JSON.

Please answer in Korean.
"""
        human_prompt = (
            f"ì‚¬ìš©ì ì§ˆë¬¸:\n{user_query}\n\n"
            f"ML ì¶”ì²œ JSON:\n```json\n{ml_json_str}\n```"
        )

        llm_out = llm.invoke([SystemMessage(content=system_prompt),
                              HumanMessage(content=human_prompt)])

        # 3) ìµœì¢… ë‹µë³€ì„ ëŒ€í™”ì— ì¶”ê°€
        msgs = state["messages"] + [AIMessage(content=llm_out.content)]
        return {
            "messages": msgs,
            "next": None,
            "router_json": state.get("router_json")
        }

    except Exception as e:
        error_msg = f"âŒ ML ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        msgs = state["messages"] + [AIMessage(content=error_msg)]
        return {
            "messages": msgs,
            "next": None,
            "router_json": state.get("router_json")
        }
# ---------- 7) Build Graph ----------
graph = StateGraph(AgentState)

# ë…¸ë“œ ì¶”ê°€
graph.add_node("supervisor", supervisor_node)
graph.add_node("LLM_parser", LLM_parser_node)
graph.add_node("FAQ_agent", FAQ_agent_node)
graph.add_node("human_fallback", human_fallback_node)
graph.add_node("price_agent", price_agent_node)
graph.add_node("ML_agent", ML_agent_node)

# ì‹œì‘ì  ì„¤ì •
graph.set_entry_point("supervisor")

# ì¡°ê±´ë¶€ ë¼ìš°íŒ… í•¨ìˆ˜
def router_edge(state: AgentState) -> str:
    return state["next"] or "human_fallback"

# ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€ (supervisorì—ì„œ ê° agentë¡œ)
graph.add_conditional_edges(
    "supervisor",
    router_edge,
    {
        "LLM_parser": "LLM_parser",
        "FAQ_agent": "FAQ_agent",
        "human_fallback": "human_fallback",
        "price_agent": "price_agent",
        "ML_agent": "ML_agent",
    },
)

# ê° ì—ì´ì „íŠ¸ì—ì„œ ENDë¡œ ê°€ëŠ” ì—£ì§€ ì¶”ê°€
for node in ["LLM_parser", "FAQ_agent", "human_fallback", "price_agent", "ML_agent"]:
    graph.add_edge(node, END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
app = graph.compile()


TEST_QUERIES = [
    

    # ê¸°íƒ€ (ë…¸ì´ì¦ˆì„±/ì‹¤í—˜ìš©)
    "ë”¥í‹°ë„ no5 ì¶”ì²œí•´ì¤˜"
]
OUTPUT_FILE = "results.txt"

def run_tests():
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for q in TEST_QUERIES:
            f.write("="*80 + "\n")
            f.write("Query: " + q + "\n")
            init: AgentState = {
                "messages": [HumanMessage(content=q)],
                "next": None,
                "router_json": None
            }
            try:
                out = app.invoke(init)
                ai_msgs = [m for m in out["messages"] if isinstance(m, AIMessage)]
                router_raw = ai_msgs[-2].content if len(ai_msgs) >= 2 else "(no router output)"
                agent_summary = ai_msgs[-1].content if ai_msgs else "(no agent output)"
                f.write("Router JSON: " + router_raw + "\n")
                f.write("Agent summary: " + agent_summary + "\n\n")
            except Exception as e:
                f.write(f"Error processing query: {e}\n\n")

def run_single_query(query: str):
    with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
        f.write(f"ğŸ” Query: {query}\n")
        f.write("-" * 50 + "\n")
        
        init: AgentState = {
            "messages": [HumanMessage(content=query)],
            "next": None,
            "router_json": None
        }
        
        try:
            out = app.invoke(init)
            ai_msgs = [m for m in out["messages"] if isinstance(m, AIMessage)]
            
            if len(ai_msgs) >= 2:
                f.write("ğŸ¤– Router Decision:\n")
                f.write(ai_msgs[-2].content + "\n")
                f.write("\nğŸ“ Final Response:\n")
                f.write(ai_msgs[-1].content + "\n\n")
            elif len(ai_msgs) == 1:
                f.write("ğŸ“ Response:\n")
                f.write(ai_msgs[-1].content + "\n\n")
            else:
                f.write("âŒ No response generated\n\n")
                
        except Exception as e:
            f.write(f"âŒ Error: {e}\n\n")

if __name__ == "__main__":
    print("ğŸ”§ í™˜ê²½ ë³€ìˆ˜ í™•ì¸:")
    print(f"OPENAI_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('OPENAI_API_KEY') else 'âŒ ë¯¸ì„¤ì •'}")
    print(f"PINECONE_API_KEY: {'âœ… ì„¤ì •ë¨' if os.getenv('PINECONE_API_KEY') else 'âŒ ë¯¸ì„¤ì •'}")
    print(f"NAVER_CLIENT_ID: {'âœ… ì„¤ì •ë¨' if os.getenv('NAVER_CLIENT_ID') else 'âŒ ë¯¸ì„¤ì •'}")
    print(f"NAVER_CLIENT_SECRET: {'âœ… ì„¤ì •ë¨' if os.getenv('NAVER_CLIENT_SECRET') else 'âŒ ë¯¸ì„¤ì •'}")
    print()
    
    print("ğŸš€ í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘... ê²°ê³¼ëŠ” results.txt íŒŒì¼ì— ì €ì¥ë©ë‹ˆë‹¤.")
    print()
    
    run_tests()