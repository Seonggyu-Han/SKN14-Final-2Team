# main.py
import os
from dotenv import load_dotenv
from typing import TypedDict, Optional, Annotated, Sequence
import operator

from langgraph.graph import StateGraph, END, START
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate

# ì‹œê°í™”ë¥¼ ìœ„í•œ ì¶”ê°€ import
try:
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')  # GUI ì—†ì´ ì‚¬ìš©
    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False
    print("âš ï¸ matplotlib ì—†ìŒ. ì‹œê°í™” ê¸°ëŠ¥ ë¹„í™œì„±í™”")

from function import price_tool, human_fallback

# --- 0) ENV ---
load_dotenv()

# --- 1) State ì •ì˜ ---
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    next: Optional[str]

# --- 2) LLM ---
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# --- 3) Supervisor ---
members = ["price_agent", "consultation_agent", "human_fallback"]

supervisor_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a supervisor managing a perfume specialist team.

Your team members:
- price_agent: Handles perfume price/cost inquiries (has access to Naver Shopping API)
- consultation_agent: Handles general perfume advice and recommendations  
- human_fallback: Handles non-perfume topics or unclear questions

Routing Rules:
- If query is about perfume price/cost (ê°€ê²©, ìµœì €ê°€, ì–¼ë§ˆ, price, cost, êµ¬ë§¤, íŒë§¤), choose "price_agent"
- If query is perfume-related advice/recommendation (ì¶”ì²œ, í–¥ìˆ˜, ëƒ„ìƒˆ, í–¥, fragrance), choose "consultation_agent"  
- If query is NOT about perfumes or is unclear/vague, choose "human_fallback"

Respond with ONLY the agent name."""),
    ("placeholder", "{messages}"),
])

def supervisor_node(state: AgentState) -> dict:
    """Supervisor ë…¸ë“œ"""
    chain = supervisor_prompt | llm
    result = chain.invoke(state)
    
    next_agent = result.content.strip()
    if next_agent not in members:
        next_agent = "human_fallback"  # ê¸°ë³¸ê°’
    
    return {"next": next_agent}

# --- 4) Price Agent (ë„êµ¬ í¬í•¨) ---
price_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a perfume price specialist assistant.
    
When users ask about perfume prices:
1. Use the price_tool to search for current prices
2. Always respond in Korean
3. Format results nicely with emojis and clear information
4. Be helpful and friendly
    
If you can't find price information, politely explain and suggest alternative searches."""),
    ("placeholder", "{messages}"),
])

price_agent = create_react_agent(
    llm, 
    [price_tool],
    prompt=price_prompt
)

# --- 5) Consultation Agent (ì¼ë°˜ ìƒë‹´) ---
consultation_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a knowledgeable and friendly perfume consultant.
    
Your expertise includes:
- Perfume recommendations based on preferences, occasions, seasons
- Fragrance families and notes explanation
- Perfume wearing tips and application advice
- Brand and fragrance history knowledge

Always respond in Korean with:
- Warmth and professionalism
- Helpful and detailed advice
- Relevant examples and suggestions
- Encouraging tone

If questions are too vague, politely ask for more specific information to provide better recommendations."""),
    ("placeholder", "{messages}"),
])

consultation_agent = create_react_agent(
    llm,
    [],  # ë„êµ¬ ì—†ìŒ
    prompt=consultation_prompt
)

# --- 6) Human Fallback Node ---
def human_fallback_node(state: AgentState) -> dict:
    """í–¥ìˆ˜ì™€ ê´€ë ¨ ì—†ê±°ë‚˜ ë¶ˆëª…í™•í•œ ì§ˆë¬¸ ì²˜ë¦¬"""
    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ì—ì„œ ì‚¬ìš©ì ì…ë ¥ ì¶”ì¶œ
    messages = state.get("messages", [])
    user_input = ""
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            user_input = msg.content
            break
    
    # human_fallback í•¨ìˆ˜ í˜¸ì¶œ (state dict í˜•íƒœë¡œ ì „ë‹¬)
    fallback_result = human_fallback({"input": user_input})
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì‘ë‹µ ìƒì„±
    response_msg = HumanMessage(content=fallback_result)
    
    return {"messages": [response_msg]}

# --- 7) ì—ì´ì „íŠ¸ í˜¸ì¶œ ë˜í¼ ---
def price_agent_node(state: AgentState) -> dict:
    """Price agent í˜¸ì¶œ"""
    result = price_agent.invoke(state)
    return {"messages": result["messages"]}

def consultation_agent_node(state: AgentState) -> dict:
    """Consultation agent í˜¸ì¶œ"""
    result = consultation_agent.invoke(state)
    return {"messages": result["messages"]}

# --- 8) Graph êµ¬ì„± ---
workflow = StateGraph(AgentState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("supervisor", supervisor_node)
workflow.add_node("price_agent", price_agent_node)
workflow.add_node("consultation_agent", consultation_agent_node)
workflow.add_node("human_fallback", human_fallback_node)

# ì¡°ê±´ë¶€ ì—£ì§€: supervisor â†’ agents
workflow.add_conditional_edges(
    "supervisor",
    lambda x: x["next"],
    {
        "price_agent": "price_agent",
        "consultation_agent": "consultation_agent",
        "human_fallback": "human_fallback",
    }
)

# ê° ì—ì´ì „íŠ¸ì—ì„œ ENDë¡œ
workflow.add_edge("price_agent", END)
workflow.add_edge("consultation_agent", END)
workflow.add_edge("human_fallback", END)

# ì‹œì‘ì 
workflow.set_entry_point("supervisor")

# ì»´íŒŒì¼
app = workflow.compile()

# --- 9) ì‹œê°í™” í•¨ìˆ˜ ---
def visualize_graph():
    """ê·¸ë˜í”„ êµ¬ì¡° ì‹œê°í™”"""
    if not VISUALIZATION_AVAILABLE:
        print("âŒ matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì‹œê°í™”ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ì„¤ì¹˜: pip install matplotlib")
        return
    
    try:
        # LangGraph ë‚´ì¥ ì‹œê°í™”
        img_data = app.get_graph().draw_mermaid_png()
        
        # íŒŒì¼ë¡œ ì €ì¥
        with open("perfume_bot_graph.png", "wb") as f:
            f.write(img_data)
        print("âœ… ê·¸ë˜í”„ê°€ 'perfume_bot_graph.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"âŒ ì‹œê°í™” ì˜¤ë¥˜: {e}")
        print("ëŒ€ì‹  í…ìŠ¤íŠ¸ë¡œ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤:")
        print_graph_structure()

def print_graph_structure():
    """í…ìŠ¤íŠ¸ë¡œ ê·¸ë˜í”„ êµ¬ì¡° ì¶œë ¥"""
    print("""
    ğŸŒŸ í–¥ìˆ˜ ë´‡ ê·¸ë˜í”„ êµ¬ì¡°:
    
    [ì‚¬ìš©ì ì…ë ¥] 
           â†“
    ğŸ“‹ Supervisor 
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“             â†“              â†“
ğŸ’° Price        ğŸŒ¸ Consultation  â“ Human
  Agent           Agent          Fallback
(price_tool)    (ìƒë‹´ ì „ë¬¸)      (ê¸°íƒ€/ëª¨í˜¸)
    â†“             â†“              â†“
   END           END            END
    """)

def show_graph_info():
    """ê·¸ë˜í”„ ì •ë³´ ì¶œë ¥"""
    print("ğŸ“Š ê·¸ë˜í”„ ì •ë³´:")
    print(f"ë…¸ë“œ ìˆ˜: {len(app.get_graph().nodes)}")
    print(f"ì—£ì§€ ìˆ˜: {len(app.get_graph().edges)}")
    print("ë…¸ë“œ ëª©ë¡:", list(app.get_graph().nodes.keys()))
    print_graph_structure()

# --- 9) í¸ì˜ í•¨ìˆ˜ ---
def ask_perfume_bot(question: str) -> str:
    """ê°„ë‹¨í•œ ì§ˆë¬¸-ë‹µë³€ ì¸í„°í˜ì´ìŠ¤"""
    try:
        result = app.invoke({
            "messages": [HumanMessage(content=question)]
        })
        
        # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ì¶”ì¶œ
        messages = result.get("messages", [])
        for msg in reversed(messages):
            if hasattr(msg, 'content') and msg.content and msg.__class__.__name__ != 'HumanMessage':
                return msg.content
        
        return "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}"

# --- 10) í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ---
def run_interactive_test():
    """ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ëª¨ë“œ"""
    print("ğŸŒ¸ í–¥ìˆ˜ ì „ë¬¸ê°€ AI ì±—ë´‡ (ì¢…ë£Œ: 'quit' ì…ë ¥)")
    print("=" * 50)
    
    while True:
        user_input = input("\nğŸ’¬ ì§ˆë¬¸: ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
            print("ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break
            
        if not user_input:
            continue
            
        print("ğŸ¤– ìƒê° ì¤‘...")
        answer = ask_perfume_bot(user_input)
        print(f"\nâœ¨ ë‹µë³€:\n{answer}")
        print("-" * 50)

def run_batch_test():
    """ë¯¸ë¦¬ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰"""
    print("=== í–¥ìˆ˜ ì „ë¬¸ê°€ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ===")
    
    test_queries = [
        # ê°€ê²© ê´€ë ¨ (price_agentë¡œ ë¼ìš°íŒ…)
        "ìƒ¤ë„¬ ë„˜ë²„5 ê°€ê²© ì•Œë ¤ì¤˜",
        "ë””ì˜¬ ì†Œë°”ì¥¬ ìµœì €ê°€ ì°¾ì•„ì¤˜", 
        "í†°í¬ë“œ ë¸”ë™ ì˜¤í‚¤ë“œ ì–¼ë§ˆì•¼?",
        
        # ìƒë‹´ ê´€ë ¨ (consultation_agentë¡œ ë¼ìš°íŒ…)
        "ì—¬ë¦„ì— ì–´ìš¸ë¦¬ëŠ” ì‹œíŠ¸ëŸ¬ìŠ¤ í–¥ìˆ˜ ì¶”ì²œ",
        "ë¡œë§¨í‹±í•œ í–¥ìˆ˜ ë­ê°€ ì¢‹ì„ê¹Œ?",
        "20ëŒ€ ì—¬ì„±ì—ê²Œ ì–´ìš¸ë¦¬ëŠ” í–¥ìˆ˜",
        
        # ëª¨í˜¸í•˜ê±°ë‚˜ í–¥ìˆ˜ ë¬´ê´€ (human_fallbackìœ¼ë¡œ ë¼ìš°íŒ…)
        "ì—„ë§ˆê°€ ì“°ë˜ í–¥ìˆ˜ ì•Œë ¤ì¤˜",  # ë„ˆë¬´ ëª¨í˜¸í•¨
        "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?",  # í–¥ìˆ˜ ë¬´ê´€
        "ì•ˆë…•í•˜ì„¸ìš”"  # ë¶ˆëª…í™•
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n[{i}/{len(test_queries)}] ğŸ“ ì§ˆë¬¸: {query}")
        answer = ask_perfume_bot(query)
        print(f"âœ… ë‹µë³€: {answer}")
        print("-" * 50)

if __name__ == "__main__":
    print("ğŸŒ¸ í–¥ìˆ˜ ì „ë¬¸ê°€ AI ë´‡")
    print("=" * 50)
    
    print("ì„ íƒí•˜ì„¸ìš”:")
    print("1. ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸")
    print("2. ë°°ì¹˜ í…ŒìŠ¤íŠ¸") 
    print("3. ê·¸ë˜í”„ ì‹œê°í™”")
    print("4. ê·¸ë˜í”„ ì •ë³´ ë³´ê¸°")
    
    choice = input("ì„ íƒ (1-4): ").strip()
    
    if choice == "1":
        run_interactive_test()
    elif choice == "2":
        run_batch_test()
    elif choice == "3":
        visualize_graph()
    elif choice == "4":
        show_graph_info()
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë°°ì¹˜ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        run_batch_test()