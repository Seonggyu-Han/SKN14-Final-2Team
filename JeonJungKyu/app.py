import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from pinecone import Pinecone
from context import AppContext
from config import OPENAI_MODEL, EMBED_MODEL, PINECONE_API_KEY, PINECONE_INDEX, NAVER_CLIENT_ID, NAVER_CLIENT_SECRET
from graph import build_graph
from langchain_core.messages import HumanMessage, AIMessage


TEST_QUERIES = [
"ì…ìƒë¡œë‘ ì—¬ì„±ìš© 50ml ê²¨ìš¸ìš© í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.ê°€ê²©ë„ ì•Œë ¤ì¤˜",
"ë””ì˜¬ EDPë¡œ ê°€ì„ ë°¤(ì•¼ê°„)ì— ì“¸ ë§Œí•œ í–¥ìˆ˜ ìˆì–´?",
"EDPë‘ EDT ì°¨ì´ê°€ ë­ì•¼?",
"íƒ‘ë…¸íŠ¸Â·ë¯¸ë“¤ë…¸íŠ¸Â·ë² ì´ìŠ¤ë…¸íŠ¸ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì´ì•¼?",
"ì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì„ê¹Œ?",
"ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?",
"ìƒ¤ë„¬ ë„˜ë²„5 50ml ê°€ê²© ì•Œë ¤ì¤˜.",
"ë””ì˜¬ ì†Œë°”ì¥¬ ê°€ê²© ì–¼ë§ˆì•¼? ì–´ë””ì„œ ì‚¬ëŠ” ê²Œ ì œì¼ ì‹¸?",
"ì—¬ë¦„ì— ì‹œì›í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜.",
"ë‹¬ë‹¬í•œ í–¥ ì¶”ì²œí•´ì¤˜.",
]




def create_context() -> AppContext:
llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0)
embeddings = OpenAIEmbeddings(model=EMBED_MODEL)
pc = Pinecone(api_key=PINECONE_API_KEY) if PINECONE_API_KEY else None
index = pc.Index(PINECONE_INDEX) if pc and PINECONE_INDEX else None
return AppContext(
llm=llm,
embeddings=embeddings,
pc=pc,
index=index,
naver_client_id=NAVER_CLIENT_ID,
naver_client_secret=NAVER_CLIENT_SECRET,
)




def run_tests(app):
for q in TEST_QUERIES:
print("="*80)
print("Query:", q)
init = {"messages": [HumanMessage(content=q)], "next": None, "router_json": None}
out = app.invoke(init)
ai_msgs = [m for m in out["messages"] if isinstance(m, AIMessage)]
router_raw = ai_msgs[-2].content if len(ai_msgs) >= 2 else "(no router output)"
agent_summary = ai_msgs[-1].content if ai_msgs else "(no agent output)"
print("Router JSON:", router_raw)
print("Agent summary:", agent_summary)




def run_single_query(app, query: str):
print(f"ğŸ” Query: {query}")
print("-" * 50)
init = {"messages": [HumanMessage(content=query)], "next": None, "router_json": None}
out = app.invoke(init)
ai_msgs = [m for m in out["messages"] if isinstance(m, AIMessage)]
if len(ai_msgs) >= 2:
print("ğŸ¤– Router Decision:\n", ai_msgs[-2].content)
print("\nğŸ“ Final Response:\n", ai_msgs[-1].content)
elif len(ai_msgs) == 1:
print("ğŸ“ Response:\n", ai_msgs[-1].content)
else:
print("ğŸš€ Ready. Use run_tests(app) or run_single_query(app, '...')")